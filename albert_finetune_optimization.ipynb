{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "albert_glue_fine_tuning_tutorial",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luanps/albert/blob/master/albert_finetune_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8SJfpgTccDB"
      },
      "source": [
        "\n",
        "<a href=\"https://colab.research.google.com/github/google-research/albert/blob/master/albert_glue_fine_tuning_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHQH4OCHZ9bq",
        "cellView": "form"
      },
      "source": [
        "# @title Copyright 2020 The ALBERT Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkTLZ3I4_7c_"
      },
      "source": [
        "# ALBERT End to End (Fine-tuning + Predicting) with Cloud TPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wtjs1QDb3DX"
      },
      "source": [
        "## Overview\n",
        "\n",
        "ALBERT is \"A Lite\" version of BERT, a popular unsupervised language representation learning algorithm. ALBERT uses parameter-reduction techniques that allow for large-scale configurations, overcome previous memory limitations, and achieve better behavior with respect to model degradation.\n",
        "\n",
        "For a technical description of the algorithm, see our paper:\n",
        "\n",
        "https://arxiv.org/abs/1909.11942\n",
        "\n",
        "Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut\n",
        "\n",
        "This Colab demonstates using a free Colab Cloud TPU to fine-tune GLUE tasks built on top of pretrained ALBERT models and \n",
        "run predictions on tuned model. The colab demonsrates loading pretrained ALBERT models from both [TF Hub](https://www.tensorflow.org/hub) and checkpoints.\n",
        "\n",
        "**Note:**  You will need a GCP (Google Compute Engine) account and a GCS (Google Cloud \n",
        "Storage) bucket for this Colab to run.\n",
        "\n",
        "Please follow the [Google Cloud TPU quickstart](https://cloud.google.com/tpu/docs/quickstart) for how to create GCP account and GCS bucket. You have [$300 free credit](https://cloud.google.com/free/) to get started with any GCP product. You can learn more about Cloud TPU at https://cloud.google.com/tpu/docs.\n",
        "\n",
        "This notebook is hosted on GitHub. To view it in its original repository, after opening the notebook, select **File > View on GitHub**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld-JXlueIuPH"
      },
      "source": [
        "## Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POkof5uHaQ_c"
      },
      "source": [
        "<h3><a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>  &nbsp;&nbsp;Train on TPU</h3>\n",
        "\n",
        "   1. Create a Cloud Storage bucket for your TensorBoard logs at http://console.cloud.google.com/storage and fill in the BUCKET parameter in the \"Parameters\" section below.\n",
        " \n",
        "   1. On the main menu, click Runtime and select **Change runtime type**. Set \"TPU\" as the hardware accelerator.\n",
        "   1. Click Runtime again and select **Runtime > Run All** (Watch out: the \"Colab-only auth for this notebook and the TPU\" cell requires user input). You can also run the cells manually with Shift-ENTER."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdMmwCJFaT8F"
      },
      "source": [
        "### Set up your TPU environment\n",
        "\n",
        "In this section, you perform the following tasks:\n",
        "\n",
        "*   Set up a Colab TPU running environment\n",
        "*   Verify that you are connected to a TPU device\n",
        "*   Upload your credentials to TPU to access your GCS bucket."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "191zq3ZErihP"
      },
      "source": [
        "# TODO(lanzhzh): Add support for 2.x.\n",
        "%tensorflow_version 1.x\n",
        "import os\n",
        "import pprint\n",
        "import json\n",
        "import tensorflow as tf\n",
        "\n",
        "assert \"COLAB_TPU_ADDR\" in os.environ, \"ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!\"\n",
        "TPU_ADDRESS = \"grpc://\" + os.environ[\"COLAB_TPU_ADDR\"] \n",
        "TPU_TOPOLOGY = \"2x2\"\n",
        "print(\"TPU address is\", TPU_ADDRESS)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "    # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUBP35oCDmbF"
      },
      "source": [
        "### Prepare and import ALBERT modules\n",
        "​\n",
        "With your environment configured, you can now prepare and import the ALBERT modules. The following step clones the source code from GitHub."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wzwke0sxS6W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "code",
        "outputId": "4e09f611-aef2-429a-ce1b-9c920d76d346"
      },
      "source": [
        "#TODO(lanzhzh): Add pip support\n",
        "import sys\n",
        "\n",
        "!test -d albert || git clone https://github.com/google-research/albert albert\n",
        "if not 'albert' in sys.path:\n",
        "  sys.path += ['albert']\n",
        "  \n",
        "!pip install sentencepiece\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'albert'...\n",
            "remote: Enumerating objects: 367, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 367 (delta 5), reused 6 (delta 3), pack-reused 353\u001b[K\n",
            "Receiving objects: 100% (367/367), 262.23 KiB | 3.50 MiB/s, done.\n",
            "Resolving deltas: 100% (237/237), done.\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRu1aKO1D7-Z"
      },
      "source": [
        "### Prepare for training\n",
        "\n",
        "This next section of code performs the following tasks:\n",
        "\n",
        "*  Specify GS bucket, create output directory for model checkpoints and eval results.\n",
        "*  Specify task and download training data.\n",
        "*  Specify ALBERT pretrained model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download GLUE data\n",
        "!git clone https://github.com/nyu-mll/GLUE-baselines download_glue\n",
        "\n",
        "GLUE_DIR='glue_data'\n",
        "!python download_glue/download_glue_data.py --data_dir $GLUE_DIR --tasks all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svpsMNG-vuko",
        "outputId": "efd19c83-68e5-4ce8-ac53-1ef53dc927e6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'download_glue'...\n",
            "remote: Enumerating objects: 891, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 891 (delta 1), reused 2 (delta 0), pack-reused 886\u001b[K\n",
            "Receiving objects: 100% (891/891), 1.48 MiB | 9.17 MiB/s, done.\n",
            "Resolving deltas: 100% (610/610), done.\n",
            "Downloading and extracting CoLA...\n",
            "\tCompleted!\n",
            "Downloading and extracting SST...\n",
            "\tCompleted!\n",
            "Processing MRPC...\n",
            "\tError downloading standard development IDs for MRPC. You will need to manually split your data.\n",
            "Downloading and extracting QQP...\n",
            "\tCompleted!\n",
            "Downloading and extracting STS...\n",
            "\tCompleted!\n",
            "Downloading and extracting MNLI...\n",
            "\tNote (12/10/20): This script no longer downloads SNLI. You will need to manually download and format the data to use SNLI.\n",
            "\tCompleted!\n",
            "Downloading and extracting QNLI...\n",
            "\tCompleted!\n",
            "Downloading and extracting RTE...\n",
            "\tCompleted!\n",
            "Downloading and extracting WNLI...\n",
            "\tCompleted!\n",
            "Downloading and extracting diagnostic...\n",
            "\tCompleted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYkaAlJNfhul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "42d23ef4-2a85-46ad-d2b6-2dfe1db9c48f"
      },
      "source": [
        "# Please find the full list of tasks and their fintuning hyperparameters\n",
        "# here https://github.com/google-research/albert/blob/master/run_glue.sh\n",
        "\n",
        "BUCKET = \"luanps\" #@param { type: \"string\" }\n",
        "TASK = 'RTE' #@param {type:\"string\"}\n",
        "# Available pretrained model checkpoints:\n",
        "#   base, large, xlarge, xxlarge\n",
        "ALBERT_MODEL = 'base' #@param {type:\"string\"}\n",
        "\n",
        "TASK_DATA_DIR = 'glue_data'\n",
        "\n",
        "BASE_DIR = \"gs://\" + BUCKET\n",
        "if not BASE_DIR or BASE_DIR == \"gs://\":\n",
        "  raise ValueError(\"You must enter a BUCKET.\")\n",
        "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
        "MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n",
        "OUTPUT_DIR = 'gs://{}/albert-tfhub/models/{}'.format(BUCKET, TASK)\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
        "\n",
        "# Download glue data.\n",
        "#! test -d download_glue_repo || git clone https://gist.github.com/60c2bdb54d156a41194446737ce03e2e.git download_glue_repo\n",
        "#!python download_glue_repo/download_glue_data.py --data_dir=$TASK_DATA_DIR --tasks=$TASK\n",
        "#print('***** Task data directory: {} *****'.format(TASK_DATA_DIR))\n",
        "\n",
        "ALBERT_MODEL_HUB = 'https://tfhub.dev/google/albert_' + ALBERT_MODEL + '/3'"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Model output directory: gs://luanps/albert-tfhub/models/RTE *****\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hcpfl4N2EdOk"
      },
      "source": [
        "Now let's run the fine-tuning scripts. If you use the default MRPC task, this should be finished in around 10 mintues and you will get an accuracy of around 86.5."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install Optuna optimzation lib\n",
        "!pip install optuna"
      ],
      "metadata": {
        "id": "WkVoRs_SD0KU",
        "outputId": "4e88d7e1-05b1-47ee-8638-6bf09de4f41b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.1.6 alembic-1.7.5 autopage-0.4.0 cliff-3.10.0 cmaes-0.8.2 cmd2-2.3.3 colorlog-6.6.0 optuna-2.10.0 pbr-5.8.0 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna"
      ],
      "metadata": {
        "id": "lJsGSNqcI4gV"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_last_acc_from_file(result_file):\n",
        "    f = open(result_file,'r')\n",
        "    results = f.readlines()\n",
        "    result_dict = dict()\n",
        "    for r in results:\n",
        "        if 'eval_accuracy' in r:\n",
        "            k,v = r.split(' = ')\n",
        "    return float(v)"
      ],
      "metadata": {
        "id": "iOJRxUusF-mH"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    # hyperparameter setting\n",
        "    warmup_steps = trial.suggest_int('warmup_steps', 5,15,5)#100, 500,100)\n",
        "    train_steps = trial.suggest_int('train_steps', 10,100,10) #400, 2000,100)\n",
        "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 5e5)\n",
        "    batch_size = trial.suggest_int('batch_size', 16, 128,16)\n",
        "\n",
        "    it = 0\n",
        "    OUTPUT_TMP = f'{OUTPUT_DIR}/{it}'\n",
        "    os.environ['TFHUB_CACHE_DIR'] = OUTPUT_TMP\n",
        "\n",
        "    !python -m albert.run_classifier \\\n",
        "            --data_dir=\"glue_data/\" \\\n",
        "            --output_dir=$OUTPUT_TMP \\\n",
        "            --albert_hub_module_handle=$ALBERT_MODEL_HUB \\\n",
        "            --spm_model_file=\"from_tf_hub\" \\\n",
        "            --do_train=True \\\n",
        "            --do_eval=True \\\n",
        "            --do_predict=False \\\n",
        "            --max_seq_length=512 \\\n",
        "            --optimizer=adamw \\\n",
        "            --task_name=$TASK \\\n",
        "            --warmup_step=$warmup_steps \\\n",
        "            --learning_rate=$learning_rate \\\n",
        "            --train_step=$train_steps \\\n",
        "            --save_checkpoints_steps=100 \\\n",
        "            --train_batch_size=$batch_size\\\n",
        "            --tpu_name=$TPU_ADDRESS \\\n",
        "            --use_tpu=True\n",
        "\n",
        "    #Download results\n",
        "    !gsutil cp $OUTPUT_DIR/eval_results.txt eval_results_$it.txt\n",
        "    model_acc = get_last_acc_from_file(f'eval_results_{it}.txt')\n",
        "    it += 1\n",
        "    return model_acc"
      ],
      "metadata": {
        "id": "1KfYFZIYEGUA"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=2)"
      ],
      "metadata": {
        "id": "WeHjYq30Ix2X",
        "outputId": "75ddca13-d905-4d4f-8987-ae5d52b21ab0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-01-09 00:05:20,051]\u001b[0m A new study created in memory with name: no-name-67401850-6d40-4f08-8ef7-62c195d3258e\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mA saída de streaming foi truncada nas últimas 5000 linhas.\u001b[0m\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:54.981165 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:54.982515 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:54.983945 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:54.985417 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:54.986870 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:54.988295 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:54.990252 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:54.991676 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:54.993067 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:54.994159 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:54.995067 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:54.996133 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:54.997411 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:54.998493 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:54.999404 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.000591 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.001600 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.002468 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.003437 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.004533 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.005490 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.006299 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.007151 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.008064 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.009069 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.010093 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.011018 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.011942 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.012851 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.013755 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.014697 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.015614 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.016492 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.017493 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.018440 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.019326 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.020224 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.021058 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.022017 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.022924 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.023800 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.024850 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.025815 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.026894 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.027954 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.028877 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.029759 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.030610 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.031470 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.032547 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.033551 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.034473 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.035651 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.036700 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.037668 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.038579 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.039403 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.040257 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.041428 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.042525 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.043378 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.044206 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.045129 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.046052 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.047132 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.048148 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.049239 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.050286 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.051263 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.052219 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.053375 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.054362 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.055192 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.056031 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.056886 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.057896 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.058793 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.059848 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.060735 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.061602 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.062501 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.063390 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.064328 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.067164 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.068149 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.069116 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.070006 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.070962 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.072676 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.074282 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.075445 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.076364 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.077210 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.078140 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.079066 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.080020 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.080983 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.081865 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.082716 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.083624 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.084593 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.085533 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.086550 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.087494 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.088419 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.089354 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.090286 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.091171 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.092081 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.093021 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.093935 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.094844 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.095740 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.096696 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.097538 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.098393 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.099225 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.100057 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.101041 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.102047 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.102949 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.103830 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.104696 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.105611 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.106508 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.107562 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.108576 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.109668 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.110686 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.111606 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.112482 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.113467 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.114449 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.115374 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.116227 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.117296 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.118301 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.119204 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.120096 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.121160 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.122175 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.123070 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.123962 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.124860 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.125739 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.126744 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.127698 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.128589 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.129512 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.130378 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.131388 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.132364 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.133236 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.134113 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.134942 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.135977 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.137031 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.138057 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.139021 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.139893 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.140739 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.141734 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.142702 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.143612 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.144493 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.145320 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.146143 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.146995 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.147847 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.148734 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.149613 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.150456 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.151298 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.152163 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.153033 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.153904 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.154757 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.155636 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.156531 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.157426 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.158334 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.159246 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.160071 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.161017 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.162163 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.163235 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.164183 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.165156 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.166067 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.167059 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.169773 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.172029 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.173581 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.175001 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.176440 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.178332 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.179986 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.181728 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.183167 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.185464 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.187186 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.188509 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.189297 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.190374 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.191694 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.193058 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.194092 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.195114 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.196164 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.197238 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.198434 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.200079 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.201304 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.202495 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.203628 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.204546 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.205405 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.206244 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.207250 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.208231 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.209362 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.210347 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.211149 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.212004 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.212852 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.213705 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.214683 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.215963 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.216999 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.217819 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.218629 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.219495 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.220263 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.221057 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.221841 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.222705 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.223716 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.224611 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.225793 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.226888 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.227827 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.228683 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.229595 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.230461 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.231245 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.232181 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.233166 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.234046 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.234857 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.235680 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.236687 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.237609 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.238474 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.239256 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.240216 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.241288 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.242199 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.243035 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.243910 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.244808 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.245674 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.246541 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.247551 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.248447 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.249258 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.250124 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.251096 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.252070 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.252976 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.253866 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.254735 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.255609 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.256454 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.257214 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.258049 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.258886 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.259709 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.260784 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.261797 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.262673 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.263629 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.264540 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.265375 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.266341 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.267392 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.268306 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.269156 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.271794 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.272724 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.273862 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.274913 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.275955 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.276888 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.277801 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.278708 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.279571 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.280413 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.281252 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.282292 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.283571 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.284648 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.285578 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.286519 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.287420 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.288247 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.289116 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.289939 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.290781 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.291676 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.292634 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.293702 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.294678 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.295558 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.296461 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.297403 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.298352 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.299260 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.300138 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.301009 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.301871 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.302901 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.303940 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.304885 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.305752 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.306573 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.307579 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.308569 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.309486 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.310370 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.311283 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.312210 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.313125 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.313997 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.314848 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.315902 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.316835 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.317975 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.319004 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.320089 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.321085 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.321999 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.322935 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.323854 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.324941 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.326140 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.327213 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.328171 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.329063 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.329903 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.330746 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.331601 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.332457 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.333502 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.334440 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.335507 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.336681 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.337781 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.338694 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.339546 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.340490 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.341424 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.342648 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.343731 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.344797 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.345740 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.346616 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.347488 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.348403 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.349305 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.350252 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.351140 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.352146 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.353104 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.354166 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.355126 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.355945 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.357018 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.358095 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.358988 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.359810 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.360644 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.361661 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.362563 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.363411 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.364486 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.365498 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.366397 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.367335 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.368208 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.369143 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.370028 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.370994 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.371929 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.374108 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.375229 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.376099 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.377046 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.378065 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.379031 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.379903 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.380748 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.381673 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.382879 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.383850 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.384670 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.385545 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.386517 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.387385 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.388169 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.388968 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.389791 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.390625 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.391597 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.392532 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.393331 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.394380 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.395556 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.396513 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.397530 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.398457 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.399568 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.400521 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.401369 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.402210 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.403249 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.404247 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.405184 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.406061 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.406954 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.407787 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.408585 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.409400 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.410166 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.411001 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.411842 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.412838 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.413728 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.416110 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.417623 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.418934 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.420454 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.422090 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.423609 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.425069 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.426580 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.428121 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.429702 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.431439 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.432994 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.434170 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.435179 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.436076 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.436985 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.437852 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.438691 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.439506 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.440287 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.441181 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.442038 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.442888 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.443761 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.444628 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.445413 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.446256 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.447286 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.448157 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.449023 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.449871 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.450787 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.452031 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.452990 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.454362 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.455219 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.456504 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.457764 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.459502 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.460706 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.461649 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.462544 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.463434 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.464468 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.465594 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.466590 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.467442 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.468270 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.469137 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.469996 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.472065 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.473364 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.475883 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.477438 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.478858 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.480942 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.482507 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.483964 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.485437 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.486892 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.489071 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.491051 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.492021 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.493028 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.494124 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.495121 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.496009 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.496960 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.498014 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.499256 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.500225 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.501053 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.501884 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.502757 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.503599 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.504670 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.505658 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.506560 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.507438 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.508351 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.509222 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.510092 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.510964 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.512001 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.512924 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.514002 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.515141 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.516160 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.517031 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.517865 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.518823 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.519709 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.520527 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.521416 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.522284 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.523179 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.524346 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.525301 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.526114 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.527107 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.528160 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.529118 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.530144 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.531295 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.532243 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.533126 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.533986 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.534891 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.535720 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.536773 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.537886 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.538850 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.539692 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.540552 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.541625 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.542541 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.543425 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.544301 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.545414 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.546564 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.547486 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.548319 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.549208 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.550107 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.551127 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.552222 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.553202 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.554103 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.554986 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.555849 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.556709 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.557791 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.558868 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.559926 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.560832 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.561699 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.562706 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.563619 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.564486 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.565371 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.566215 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.567339 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.568249 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.569208 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.570204 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.571324 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.572390 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.573412 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.574362 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.575325 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.576992 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.578254 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.579121 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.579974 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.580877 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.581731 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.582734 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.583698 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.584609 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.585527 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.586508 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.587612 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.588595 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.589486 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.590377 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.591226 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.592130 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.592997 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.594000 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.594988 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.595876 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.597019 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.598073 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.598944 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.599798 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.600704 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.601663 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.602684 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.603721 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.604704 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.605684 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.606666 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.607576 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.608446 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.609300 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.610198 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.611231 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.612194 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.613075 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.613990 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.614833 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.615747 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.616673 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.617536 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.618627 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.619643 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.620523 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.621385 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.622234 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.623122 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.624039 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.625113 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.626078 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.626938 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.627769 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.628774 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.629772 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.630670 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.631523 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.632383 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.633273 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.634171 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.635085 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.635988 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.636950 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.637969 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.638981 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.639983 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.641052 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.642064 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.643095 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.644128 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.645083 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.645969 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.646801 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.647635 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.648501 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.649337 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.650175 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.651240 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.652230 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.653177 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.654268 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.655213 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.656071 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.657041 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.657940 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.658783 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.659646 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.660667 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.661863 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.663010 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.663949 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.665028 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.666001 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.666909 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.667923 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.669042 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.670169 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.671106 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.672066 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.673020 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.674029 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.675026 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.676032 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.676929 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.677806 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.679105 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.680408 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.681651 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.682942 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.684632 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.686094 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.687649 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.689040 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.690412 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.691802 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.693330 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.696866 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.698299 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.699619 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.701225 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.702659 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.704062 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.705503 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.707364 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.709660 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.710888 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.711964 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.712853 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.713801 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.714721 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.715635 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.716530 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.717408 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.718246 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.719105 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.720247 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.721225 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.722064 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.722964 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.723972 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.724952 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.725800 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.726638 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.727491 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.728370 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.729220 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.730254 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.731256 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.732493 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.733805 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.734886 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.735785 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.736729 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.737593 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.738508 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.739471 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.740524 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.741518 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.742476 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.743367 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.744219 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.745124 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.746043 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.747112 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.748070 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.749262 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.750449 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.751446 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.752592 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.753594 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.754707 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.755746 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.757105 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.758466 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.759587 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.760643 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.761667 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.762537 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.763531 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.764662 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.765777 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.767046 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.768139 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.769033 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.770128 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.771117 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.771943 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.772771 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.773799 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.774955 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.775928 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.776848 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.777809 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.778684 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.779567 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.780475 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.781350 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.782375 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.783336 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.784193 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.785223 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.786196 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.787143 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.788459 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.789639 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.790565 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.791662 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.792828 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.793887 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.794845 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.795874 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.796760 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.797626 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.798663 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.799733 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.800659 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.801583 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.802627 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.803615 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.804822 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.805861 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.806750 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.807715 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.808761 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.809945 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.810973 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.811879 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.812838 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.813750 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.814597 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.815545 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.816638 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.817599 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.818512 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.819677 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.820744 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.821642 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.822535 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.823565 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.824651 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.825799 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.826782 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.827840 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.828809 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.829653 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.830546 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.831527 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.832466 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.833373 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.834397 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.835341 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.836242 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.837322 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.838359 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.839436 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.840371 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.841488 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.842479 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.843360 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.844456 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.845421 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.846265 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.847329 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.848467 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.849438 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.850244 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.851156 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.852051 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.853109 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.854024 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.855068 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.856047 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.856854 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.857748 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.858725 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.859851 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.861120 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.862256 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.863183 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.864210 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.865377 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.866488 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.868015 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.869656 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.871023 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.872287 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.873466 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.874424 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.875336 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.876333 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.877249 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.878115 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.878966 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.879973 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.880947 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.881835 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.882737 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.884034 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.885525 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.886913 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.888997 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.890419 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.891892 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.893258 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.894661 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.896115 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.897471 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.898863 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.900353 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.901826 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.903411 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.904437 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.905360 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.906220 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.907121 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.907967 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.908867 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.909743 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.910822 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.911895 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.912791 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.913790 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.914724 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.915868 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.917153 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.918202 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.919098 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.920181 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.921515 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.922457 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.923362 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.924464 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.925520 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.926505 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.927402 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.928438 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.929409 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.930301 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.931237 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.932133 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.933092 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.934052 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.934959 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.935797 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.936619 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.937746 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.939902 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.941607 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.943135 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.944064 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.945210 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.946268 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.947274 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.948882 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.950117 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.951071 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.952044 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.952953 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.953845 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.954948 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.955877 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.956752 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.957746 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.958682 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.959560 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.960532 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.961468 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.962299 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.963124 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.964139 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.965099 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.966011 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.966912 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.967948 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.969216 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.970247 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.971137 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.972184 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.973109 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.974226 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.975249 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.976122 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.976999 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.977879 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.978943 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.980201 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.981454 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.982436 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.983302 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.984155 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.985027 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.985885 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.986745 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.987613 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.988558 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.989904 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.990952 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.991837 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.992828 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.993764 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.996457 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.997642 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:55.998912 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.000030 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.000998 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.002074 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.002960 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.003998 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.004938 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.006006 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.006982 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.008000 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.008973 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.009847 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.010693 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.011528 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.012556 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.013707 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.014717 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.015731 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.016653 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.017637 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.018553 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.019583 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.020844 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.021896 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.022825 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.023687 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.024950 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.026055 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.026900 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.027710 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.028560 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.029598 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.030545 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.031618 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.032584 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.033500 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.034440 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.035245 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.036277 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.037233 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.038585 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.039718 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.040714 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.041750 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.042883 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.043797 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.044705 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.045747 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.046737 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.047646 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.048568 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.049632 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.050599 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.051464 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.052414 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.053327 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.054198 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.055046 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.055865 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.056749 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.057819 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.058810 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.059768 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.060677 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.061568 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.062393 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.063244 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.064147 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.065203 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.066188 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.067090 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.068103 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.069054 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.070149 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.071152 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.074447 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.075374 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.076286 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.077214 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.078172 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.079265 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.080452 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.081435 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.082271 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.083154 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.084189 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.085167 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.086059 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.086942 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.087825 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.088933 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.089935 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.090766 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.091634 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.092607 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.093693 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.094632 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.095653 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.097809 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.099694 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.101114 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.102690 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.104238 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.106019 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.107839 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.109284 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.110441 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.111805 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.113149 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.114596 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.115918 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.117469 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.118875 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.120235 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.122271 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.123248 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.124115 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.125083 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.126206 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.127384 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.128567 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.129561 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.130444 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.131524 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.132529 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.133402 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.134370 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.135432 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.136415 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.137425 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.138339 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.139410 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.140390 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.141183 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.142029 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.142932 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.144050 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.145000 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.145958 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.146898 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.147819 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.148764 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.149712 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.150569 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.151429 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.152329 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.153226 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.154069 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.154922 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.155926 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.156920 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.157789 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.158625 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.159689 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.160791 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.161740 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.162604 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.163539 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.164525 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.165422 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.166434 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.167490 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.168424 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.169281 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.170165 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.171068 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.172256 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.173230 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.174070 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.174975 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.175847 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.176672 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.177553 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.178450 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.179378 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.180257 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.181597 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.183217 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.184550 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.185723 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.187054 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.188437 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.190137 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.191683 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.192779 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.193732 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.194781 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.195843 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.196757 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.197808 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.198708 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.201505 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.202724 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.203715 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.204657 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.205738 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.206742 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.207699 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.208593 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.209461 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.210297 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.211208 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.212131 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.213036 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.213955 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.214829 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.215704 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.216896 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.218058 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.219017 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.219894 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.220839 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.221708 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.222722 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.223651 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.224543 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.225441 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.226385 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.227300 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.228189 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.229283 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.230463 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.231661 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.232895 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.233880 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.234920 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.235858 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.236754 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.237680 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.238597 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.239499 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.240396 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.241213 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.242081 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.243002 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.243964 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.244919 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.245939 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.246880 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.247801 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.248661 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.249498 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.250323 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.251172 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.252052 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.252925 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.253821 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.254713 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.255635 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.256559 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.257445 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.258466 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.259548 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.260738 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.261993 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.263033 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.263930 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.264836 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.265682 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.266521 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.267367 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.268211 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.269088 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.270109 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.271180 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.272178 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.273053 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.274082 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.275052 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.276154 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.277163 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.278268 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.279261 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.280270 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.281183 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.282053 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.282874 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.283761 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.284710 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.285742 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.286669 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.287619 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.288719 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.289678 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.290510 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.291371 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.292185 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.293089 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.294020 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.294983 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.296134 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.297179 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.298087 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.299111 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.300533 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.302270 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.304805 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.306641 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.308129 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.309584 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.311032 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.312450 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.313821 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.315100 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.316666 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.318145 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.319558 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.320907 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.322274 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.324009 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.325425 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.326688 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.328049 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.329267 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.330375 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.331273 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.332351 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.333271 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.334182 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.335059 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.335955 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.336828 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.337711 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.338601 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.339504 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.340466 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.341395 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.342360 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.343679 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.344747 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.345690 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.346595 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.347470 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.348379 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.349280 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.350238 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.351296 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.352423 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.353468 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.354363 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.355392 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.356429 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.357372 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.358238 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.359095 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.360007 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.360880 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.361765 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.362618 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.363510 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.364447 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.365274 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.366166 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.367088 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.368129 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.369090 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.369987 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.370880 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.371701 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.372619 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.373834 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.374951 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.375903 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.376820 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.377773 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.378681 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.379582 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.380544 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.381442 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.382335 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.383275 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.384378 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.385334 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.386176 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.387176 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.388278 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.389224 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.390117 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.390971 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.391805 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.392663 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.393540 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.394393 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.395282 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.396166 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.397127 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.398046 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.398923 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.399992 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.401055 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.402047 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.402981 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.404739 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.406574 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.407496 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.408624 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.409631 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.410671 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.411586 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.412446 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.413266 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.414393 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.415554 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.416662 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.417569 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.418494 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.419363 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.420414 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.421385 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.422242 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.423086 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.423947 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.424916 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.426266 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.427725 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.428714 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.429803 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.431099 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.432647 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.434053 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.436037 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.437412 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.438265 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.439903 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.441586 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.443357 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.444942 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.446409 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.447865 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.449340 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.450696 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.452129 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.453948 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.455584 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.456531 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.457646 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.458712 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.459764 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.460848 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.461897 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.462893 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.463805 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.464706 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.465597 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.466451 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.467388 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.468258 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.469187 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.470270 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.471253 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.472414 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.473324 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.474268 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.475214 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.476165 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.477091 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.478012 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.478916 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.479782 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.480705 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.481620 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.482494 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.483608 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.484653 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.485553 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.486417 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.487328 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.488220 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.489227 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.490196 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.491099 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.491967 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.493126 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.494197 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.495150 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.496017 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.496928 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.497824 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.498749 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.499723 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.500794 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.501926 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.502952 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.503838 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.504735 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.506175 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.509261 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.510795 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.512145 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.513568 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.514977 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.516483 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.517914 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.519120 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.520202 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.521507 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.522851 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.524239 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.525908 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.527859 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.529547 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.531415 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.533157 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.534618 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.535828 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.537173 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.538091 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.538990 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.539896 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.541132 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.542259 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.543438 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.544704 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.545745 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.546653 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.547690 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.548682 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.549563 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.550408 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.551577 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.552672 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.553640 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.554465 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.555332 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.556199 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.557083 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.558035 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.558917 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.559769 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.560688 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.561557 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.562438 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.563459 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.564453 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.565304 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.566138 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.566978 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.567854 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.568741 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.569627 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.570513 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.571506 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.572409 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.573275 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.574222 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.575252 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.576449 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.577384 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.578286 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.579293 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.580475 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.581449 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.582438 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.583429 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.584299 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.585179 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.586154 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.587383 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.588352 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.589168 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.590043 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.591028 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.591966 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.592995 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.594038 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.594977 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.595802 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.597142 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.598225 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.599084 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.599948 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.600805 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.601705 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.602582 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.603456 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.604344 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.605222 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.606108 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.606962 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.607935 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.608965 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.611909 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.613221 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.614437 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.615486 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.616358 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.617207 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.618077 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.619005 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.619937 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.620880 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.621784 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.622681 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.623715 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.624654 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.625512 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.626361 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.627201 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.628074 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.629006 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.629899 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.630765 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.631667 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.632564 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.633479 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.634384 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.635194 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.636025 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.636881 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.637712 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.638568 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.639448 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.640326 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.641229 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.642256 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.643483 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.644529 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.645496 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.646391 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.647267 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.648165 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.649224 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.650219 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.651075 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.652075 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.653052 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.653959 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.654982 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.655942 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.656890 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.657797 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.658778 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.659665 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.660553 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.661712 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.662742 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.663653 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.665257 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.666821 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.667771 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.668926 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.669947 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.671272 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.672479 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.673891 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.675162 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.676101 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.677045 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.677937 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.678768 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.679806 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.680861 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.681949 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.682937 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.683800 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.684756 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.685722 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.686583 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.687402 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.688292 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.689229 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.690442 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.691501 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.692402 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.693268 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.694153 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.695022 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.695907 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.696803 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.697824 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.698911 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.699884 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.700779 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.701715 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.702610 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.703520 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.704377 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.705359 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.706290 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.707139 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.707957 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.708902 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.710173 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.711450 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.713869 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.715205 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.716708 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.718299 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.719798 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.721366 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.723088 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.724580 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.725697 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.727047 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.728476 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.729814 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.731226 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.732621 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.733928 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.734907 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.735959 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.736981 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.737885 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.738780 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.739726 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.740618 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.741506 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.742342 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.743393 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.744475 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.745383 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.746269 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.747096 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.748220 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.749253 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.750299 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.751255 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.752252 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.753554 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.754616 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.755715 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.756706 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.757587 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.758445 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.759289 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.760198 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.761023 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.761836 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.762668 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.763603 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.764581 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.765461 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.766437 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.767469 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.768410 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.769373 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.770284 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.771189 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.772090 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.775639 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.776846 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.777826 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.778763 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.779583 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.780434 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.781323 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.782276 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.783201 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.784107 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.785212 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.786286 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.787203 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.788072 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.788929 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.789801 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.790693 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.791606 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.792579 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.793479 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.794361 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.795233 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.796123 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.797031 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.798022 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.798970 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.799792 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.800713 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.801666 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.802557 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.803406 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.804259 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.805303 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.806275 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.807130 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.807955 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.808826 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.809926 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.811028 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.811948 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.812855 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.815054 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.816642 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.817652 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.818856 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.819913 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.820825 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.821724 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.822647 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.823791 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.824761 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.825600 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.826489 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.827441 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.828500 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.829691 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.830704 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.831542 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.832388 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.833209 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.834118 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.834959 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.835839 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.836717 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.837756 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.838898 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.839933 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.841009 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.842025 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.842921 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.843807 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.844701 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.845614 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.846538 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.847438 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.848422 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.849346 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.850212 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.851207 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.852186 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.853246 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.854213 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.855085 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.856114 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.857075 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.857951 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.858839 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.859718 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.860631 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.861519 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.862352 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.863223 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.864514 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.865600 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.866582 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.867497 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.868436 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.869464 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.870360 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.871160 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.872037 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.872933 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.873871 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.874789 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.875713 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.876564 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.877414 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.878256 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.879109 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.880012 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.881136 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.882140 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.883018 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.883908 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.884817 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.885725 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.886588 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.887444 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.888353 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.889234 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.890066 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.891104 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.892393 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.893427 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.894500 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.895501 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.896544 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.897571 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.898532 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.899513 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.900465 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.901364 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.902230 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.903097 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.903953 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.904837 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.905925 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.906937 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.907905 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.908780 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.909640 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.910533 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.911424 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.912606 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.917985 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.919603 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.921010 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.922352 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.923763 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.925493 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.927489 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.929125 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.930897 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.932542 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.934013 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.935389 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.936561 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.938146 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.939831 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.941342 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.942755 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.944155 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.946182 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.947319 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.948225 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.949151 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.950086 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.951155 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.952203 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.953129 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.954252 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.955396 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.956394 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.957466 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.958446 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.959374 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.960261 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.961329 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.962526 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.963629 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.964587 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.965426 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.966303 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.967188 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.968051 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.968894 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.969763 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.970610 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.971422 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.972483 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.973484 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.974534 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.975464 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.976364 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.977261 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.978138 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.979007 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.980003 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.980909 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.981946 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.982962 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.984127 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.985154 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.985994 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.986890 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.987771 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.988799 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.989769 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.990654 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.991616 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.992536 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.993635 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.994636 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.995448 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.996413 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.997293 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.998163 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.999024 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:56.999967 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.000868 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.001772 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.002948 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.003983 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.004906 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.005797 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.006855 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.007820 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.008692 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.009642 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.010623 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.011522 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.012403 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.013294 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.014192 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.015073 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.016132 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.017808 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.019819 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.020927 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.021886 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.022756 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.023665 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.024813 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.025799 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.026720 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.027582 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.028464 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.029350 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.030410 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.031431 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.032386 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.033278 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.034117 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.035150 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.036186 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.037128 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.038058 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.039163 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.040371 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.041481 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.042428 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.043265 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.044353 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.045400 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.046502 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.047520 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.048409 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.049292 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.050208 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.051111 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.052076 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.053056 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.053971 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.054827 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.055818 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.056689 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.057542 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.058435 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.059302 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.060135 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.061076 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.061983 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.062876 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.063899 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.064945 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.065951 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.066863 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.067711 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.068719 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.069610 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.070553 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.072082 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.074131 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.075281 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.076353 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.077400 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.078325 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.079183 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.080202 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.081116 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.082052 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.083073 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.084057 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.084936 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.085894 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.087071 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.088232 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.089374 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.090303 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.091295 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.092275 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.093303 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.094284 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.095160 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.096058 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.097136 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.098094 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.098958 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.099825 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.100669 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.101703 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.102685 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.103707 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.104696 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.105528 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.106346 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.107214 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.108156 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.109033 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.109942 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.110836 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.111787 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.112704 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.113573 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.114485 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.115604 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.116639 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.117799 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.118809 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.121021 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.123198 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.124718 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.126114 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.127526 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.128969 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.130342 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.131729 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.133121 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.134558 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.136053 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.137465 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.138553 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.139670 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.140770 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.142138 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.143622 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.145032 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.146867 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.148589 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.150130 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.151600 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.152620 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.153594 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.154585 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.155557 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.156403 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.157284 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.158230 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.159289 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.160264 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.161144 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.162017 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.162884 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.163987 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.165163 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.166139 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.167065 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.167946 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.168777 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.169731 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.171091 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.172977 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.174491 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.175660 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.176885 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.178230 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.179765 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.181146 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.182548 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.183871 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.185200 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.186756 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.187712 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.188618 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.189576 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.190755 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.191958 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.193228 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.194427 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.195358 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.196424 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.197404 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.198293 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.199237 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.200092 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.201131 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.202240 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.203267 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.204188 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.205089 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.205921 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.206727 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.207880 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.208886 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.209795 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.210695 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.211595 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.212513 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.213436 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.214328 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.215247 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.216139 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.217254 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.218259 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.219119 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.219979 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.220794 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.221609 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.223061 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.224981 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.225932 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.226843 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.227716 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.228608 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.229514 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.230601 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.231768 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.232797 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.233869 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.234776 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.235620 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.236559 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.237443 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.238380 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.239395 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.240399 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.241514 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.242514 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.243463 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.244451 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.245352 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.246207 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.247334 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.248355 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.249243 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.250146 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.250989 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.251859 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.252761 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.253686 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.254531 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.255328 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.256164 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.257103 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.258134 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.259397 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.260510 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.261441 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.262341 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.263187 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.264240 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.265244 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.266409 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.267481 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.268437 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.269289 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.270204 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.271087 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.272002 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.273197 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.274222 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.275227 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.276280 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.277200 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.278060 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.278930 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.279968 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.280957 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.281848 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.282704 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.283694 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.284639 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.285630 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.286534 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.287371 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.288206 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.289058 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.289876 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.290699 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.291781 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.292736 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.293567 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.294425 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.295326 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.296214 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.297101 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.298128 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.299072 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.300019 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.300935 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.301933 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.302854 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.303710 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.304687 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.305603 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.306505 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.307578 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.308533 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.309334 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.310263 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.311220 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.312041 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.312876 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.313751 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.314718 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.315605 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.316409 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.317400 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.318241 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.319138 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.320148 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.321066 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.322051 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.323189 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.325025 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.326469 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.327947 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.330156 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.331542 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.333035 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.334599 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.336007 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.337335 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.338634 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.340034 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.341431 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.342756 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.344108 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.345406 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.347166 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.348821 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.350208 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.351801 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.353333 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.354555 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.355428 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.356279 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.357208 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.358334 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.359341 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.360189 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.361171 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.362185 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.363066 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.363949 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.364820 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.365862 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.366802 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.367672 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.368546 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.369451 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.370496 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.371445 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.372271 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.373182 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.374274 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.375105 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.375994 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.376893 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.377843 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.378721 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.379597 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.380494 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.381421 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.382276 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.383211 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.384096 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.385005 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.386071 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.387092 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.388011 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.388856 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.389706 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.390555 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.391628 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.392668 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.393557 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.394449 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.395543 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.396518 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.397436 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.398294 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.399402 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.400359 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.401331 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.402238 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.403053 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.403899 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.404728 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.405591 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.406692 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.407892 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.408912 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.409877 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.410753 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.411713 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.412620 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.413473 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.414586 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.415792 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.416908 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.417824 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.418681 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.419644 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.420550 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.421584 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.422609 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.423576 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.424594 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.425661 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.426640 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.427537 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.428559 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.431239 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.432343 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.433337 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.434332 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.435231 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.436071 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.437160 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.438181 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.439253 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 00:05:57.440210 139751079724928 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:***** Running training *****\n",
            "I0109 00:05:57.949476 139751079724928 run_classifier.py:315] ***** Running training *****\n",
            "INFO:tensorflow:  Num examples = 2490\n",
            "I0109 00:05:57.949701 139751079724928 run_classifier.py:316]   Num examples = 2490\n",
            "INFO:tensorflow:  Batch size = 112\n",
            "I0109 00:05:57.949790 139751079724928 run_classifier.py:317]   Batch size = 112\n",
            "INFO:tensorflow:  Num steps = 70\n",
            "I0109 00:05:57.949856 139751079724928 run_classifier.py:318]   Num steps = 70\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.76.183.170:8470) for TPU system metadata.\n",
            "I0109 00:05:58.213287 139751079724928 tpu_system_metadata.py:78] Querying Tensorflow master (grpc://10.76.183.170:8470) for TPU system metadata.\n",
            "2022-01-09 00:05:58.214413: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:370] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "I0109 00:05:58.227434 139751079724928 tpu_system_metadata.py:148] Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "I0109 00:05:58.227642 139751079724928 tpu_system_metadata.py:149] *** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "I0109 00:05:58.227717 139751079724928 tpu_system_metadata.py:150] *** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "I0109 00:05:58.227774 139751079724928 tpu_system_metadata.py:152] *** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 11427571705680393491)\n",
            "I0109 00:05:58.227827 139751079724928 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 11427571705680393491)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 11027356195149920114)\n",
            "I0109 00:05:58.228035 139751079724928 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 11027356195149920114)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 9365630759094707857)\n",
            "I0109 00:05:58.228090 139751079724928 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 9365630759094707857)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 7989586621220768446)\n",
            "I0109 00:05:58.228142 139751079724928 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 7989586621220768446)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 9785832277138233337)\n",
            "I0109 00:05:58.228193 139751079724928 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 9785832277138233337)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 9613850914372366153)\n",
            "I0109 00:05:58.228244 139751079724928 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 9613850914372366153)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 7293297392476955861)\n",
            "I0109 00:05:58.228294 139751079724928 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 7293297392476955861)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 6142064186121730076)\n",
            "I0109 00:05:58.228403 139751079724928 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 6142064186121730076)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 3940765502806562279)\n",
            "I0109 00:05:58.228499 139751079724928 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 3940765502806562279)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 5185886070249345043)\n",
            "I0109 00:05:58.228582 139751079724928 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 5185886070249345043)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 18302436322667190563)\n",
            "I0109 00:05:58.228664 139751079724928 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 18302436322667190563)\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "W0109 00:05:58.233820 139751079724928 deprecation.py:506] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0109 00:05:58.234334 139751079724928 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0109 00:05:58.252840 139751079724928 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /content/albert/classifier_utils.py:744: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "W0109 00:05:58.271730 139751079724928 deprecation.py:323] From /content/albert/classifier_utils.py:744: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "W0109 00:05:58.271977 139751079724928 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "WARNING:tensorflow:Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f19db13f050> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "W0109 00:05:58.284077 139751079724928 ag_logging.py:146] Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f19db13f050> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:From /content/albert/classifier_utils.py:721: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0109 00:05:58.287627 139751079724928 deprecation.py:323] From /content/albert/classifier_utils.py:721: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:*** Features ***\n",
            "I0109 00:05:58.362620 139751079724928 classifier_utils.py:824] *** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (14, 512)\n",
            "I0109 00:05:58.362867 139751079724928 classifier_utils.py:826]   name = input_ids, shape = (14, 512)\n",
            "INFO:tensorflow:  name = input_mask, shape = (14, 512)\n",
            "I0109 00:05:58.362958 139751079724928 classifier_utils.py:826]   name = input_mask, shape = (14, 512)\n",
            "INFO:tensorflow:  name = is_real_example, shape = (14,)\n",
            "I0109 00:05:58.363025 139751079724928 classifier_utils.py:826]   name = is_real_example, shape = (14,)\n",
            "INFO:tensorflow:  name = label_ids, shape = (14,)\n",
            "I0109 00:05:58.363084 139751079724928 classifier_utils.py:826]   name = label_ids, shape = (14,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (14, 512)\n",
            "I0109 00:05:58.363143 139751079724928 classifier_utils.py:826]   name = segment_ids, shape = (14, 512)\n",
            "INFO:tensorflow:creating model from hub_module: https://tfhub.dev/google/albert_base/3\n",
            "I0109 00:05:58.364047 139751079724928 fine_tuning_utils.py:65] creating model from hub_module: https://tfhub.dev/google/albert_base/3\n",
            "E0109 00:06:03.051517 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/input_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.052161 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/input_mask) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.053172 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/segment_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.053551 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/mlm_positions) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.057155 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/word_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.064069 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/token_type_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.070220 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/position_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.075205 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.076353 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.084239 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/embedding_hidden_mapping_in/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.085444 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/embedding_hidden_mapping_in/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.096337 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.098034 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.106997 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.108786 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.117849 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.119490 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.137711 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.139358 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.145334 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.146499 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.152839 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.154419 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.164993 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.166160 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.171540 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.172638 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.907208 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.908462 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.915466 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.916651 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.920637 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.921801 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 00:06:03.926058 139751079724928 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/output_bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "I0109 00:06:04.036766 139751079724928 saver.py:1503] Saver not created because there are no variables in the graph to restore\n",
            "WARNING:tensorflow:From /content/albert/classifier_utils.py:794: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0109 00:06:04.160578 139751079724928 deprecation.py:506] From /content/albert/classifier_utils.py:794: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "I0109 00:06:04.196088 139751079724928 classifier_utils.py:861] **** Trainable Variables ****\n",
            "INFO:tensorflow:  name = module/bert/embeddings/word_embeddings:0, shape = (30000, 128)\n",
            "I0109 00:06:04.196302 139751079724928 classifier_utils.py:867]   name = module/bert/embeddings/word_embeddings:0, shape = (30000, 128)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/token_type_embeddings:0, shape = (2, 128)\n",
            "I0109 00:06:04.196427 139751079724928 classifier_utils.py:867]   name = module/bert/embeddings/token_type_embeddings:0, shape = (2, 128)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/position_embeddings:0, shape = (512, 128)\n",
            "I0109 00:06:04.196504 139751079724928 classifier_utils.py:867]   name = module/bert/embeddings/position_embeddings:0, shape = (512, 128)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/LayerNorm/beta:0, shape = (128,)\n",
            "I0109 00:06:04.196574 139751079724928 classifier_utils.py:867]   name = module/bert/embeddings/LayerNorm/beta:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/LayerNorm/gamma:0, shape = (128,)\n",
            "I0109 00:06:04.196640 139751079724928 classifier_utils.py:867]   name = module/bert/embeddings/LayerNorm/gamma:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/embedding_hidden_mapping_in/kernel:0, shape = (128, 768)\n",
            "I0109 00:06:04.196704 139751079724928 classifier_utils.py:867]   name = module/bert/encoder/embedding_hidden_mapping_in/kernel:0, shape = (128, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/embedding_hidden_mapping_in/bias:0, shape = (768,)\n",
            "I0109 00:06:04.196771 139751079724928 classifier_utils.py:867]   name = module/bert/encoder/embedding_hidden_mapping_in/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel:0, shape = (768, 768)\n",
            "I0109 00:06:04.196833 139751079724928 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias:0, shape = (768,)\n",
            "I0109 00:06:04.196900 139751079724928 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel:0, shape = (768, 768)\n",
            "I0109 00:06:04.196962 139751079724928 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias:0, shape = (768,)\n",
            "I0109 00:06:04.197038 139751079724928 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel:0, shape = (768, 768)\n",
            "I0109 00:06:04.197101 139751079724928 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias:0, shape = (768,)\n",
            "I0109 00:06:04.197166 139751079724928 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel:0, shape = (768, 768)\n",
            "I0109 00:06:04.197227 139751079724928 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias:0, shape = (768,)\n",
            "I0109 00:06:04.197293 139751079724928 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta:0, shape = (768,)\n",
            "I0109 00:06:04.197365 139751079724928 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma:0, shape = (768,)\n",
            "I0109 00:06:04.197427 139751079724928 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0109 00:06:04.197487 139751079724928 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0109 00:06:04.197552 139751079724928 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0109 00:06:04.197613 139751079724928 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias:0, shape = (768,)\n",
            "I0109 00:06:04.197677 139751079724928 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta:0, shape = (768,)\n",
            "I0109 00:06:04.197737 139751079724928 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma:0, shape = (768,)\n",
            "I0109 00:06:04.197796 139751079724928 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "I0109 00:06:04.197856 139751079724928 classifier_utils.py:867]   name = module/bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/pooler/dense/bias:0, shape = (768,)\n",
            "I0109 00:06:04.197920 139751079724928 classifier_utils.py:867]   name = module/bert/pooler/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/dense/kernel:0, shape = (768, 128)\n",
            "I0109 00:06:04.197986 139751079724928 classifier_utils.py:867]   name = module/cls/predictions/transform/dense/kernel:0, shape = (768, 128)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/dense/bias:0, shape = (128,)\n",
            "I0109 00:06:04.198052 139751079724928 classifier_utils.py:867]   name = module/cls/predictions/transform/dense/bias:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/LayerNorm/beta:0, shape = (128,)\n",
            "I0109 00:06:04.198113 139751079724928 classifier_utils.py:867]   name = module/cls/predictions/transform/LayerNorm/beta:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/LayerNorm/gamma:0, shape = (128,)\n",
            "I0109 00:06:04.198174 139751079724928 classifier_utils.py:867]   name = module/cls/predictions/transform/LayerNorm/gamma:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/output_bias:0, shape = (30000,)\n",
            "I0109 00:06:04.198234 139751079724928 classifier_utils.py:867]   name = module/cls/predictions/output_bias:0, shape = (30000,)\n",
            "INFO:tensorflow:  name = output_weights:0, shape = (2, 768)\n",
            "I0109 00:06:04.198294 139751079724928 classifier_utils.py:867]   name = output_weights:0, shape = (2, 768)\n",
            "INFO:tensorflow:  name = output_bias:0, shape = (2,)\n",
            "I0109 00:06:04.198370 139751079724928 classifier_utils.py:867]   name = output_bias:0, shape = (2,)\n",
            "INFO:tensorflow:++++++ warmup starts at step 0, for 15 steps ++++++\n",
            "I0109 00:06:04.210523 139751079724928 optimization.py:51] ++++++ warmup starts at step 0, for 15 steps ++++++\n",
            "INFO:tensorflow:using adamw\n",
            "I0109 00:06:04.222584 139751079724928 optimization.py:75] using adamw\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0109 00:06:04.444529 139751079724928 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0109 00:06:09.825243 139751079724928 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0109 00:06:09.894377 139751079724928 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "I0109 00:06:13.165131 139751079724928 tpu_estimator.py:506] TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0109 00:06:13.384435 139751079724928 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0109 00:06:19.905769 139751079724928 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0109 00:06:20.458747 139751079724928 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into gs://luanps/albert-tfhub/models/RTE/0/model.ckpt.\n",
            "I0109 00:06:28.577178 139751079724928 basic_session_run_hooks.py:606] Saving checkpoints for 0 into gs://luanps/albert-tfhub/models/RTE/0/model.ckpt.\n",
            "INFO:tensorflow:gs://luanps/albert-tfhub/models/RTE/0/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.\n",
            "I0109 00:06:37.153558 139751079724928 checkpoint_management.py:95] gs://luanps/albert-tfhub/models/RTE/0/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:751: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "W0109 00:06:41.397789 139751079724928 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:751: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "I0109 00:06:42.561999 139751079724928 util.py:98] Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "I0109 00:06:42.562469 139751079724928 session_support.py:332] Installing graceful shutdown hook.\n",
            "2022-01-09 00:06:42.563095: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:370] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "I0109 00:06:42.568634 139751079724928 session_support.py:82] Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "I0109 00:06:42.570617 139751079724928 session_support.py:105] Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Init TPU system\n",
            "I0109 00:06:42.575068 139751079724928 tpu_estimator.py:567] Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 10 seconds\n",
            "I0109 00:06:53.267638 139751079724928 tpu_estimator.py:576] Initialized TPU in 10 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "I0109 00:06:53.268375 139748948412160 tpu_estimator.py:521] Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "I0109 00:06:53.268720 139748940019456 tpu_estimator.py:540] Starting outfeed thread controller.\n",
            "INFO:tensorflow:Enqueue next (70) batch(es) of data to infeed.\n",
            "I0109 00:06:53.819429 139751079724928 tpu_estimator.py:600] Enqueue next (70) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (70) batch(es) of data from outfeed.\n",
            "I0109 00:06:53.819765 139751079724928 tpu_estimator.py:604] Dequeue next (70) batch(es) of data from outfeed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8qXPxv8-kBO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f917d7df-71f2-4085-871f-0d073ddeab65"
      },
      "source": [
        "#os.environ['TFHUB_CACHE_DIR'] = OUTPUT_DIR\n",
        "!python -m albert.run_classifier \\\n",
        "  --data_dir=\"glue_data/\" \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --albert_hub_module_handle=$ALBERT_MODEL_HUB \\\n",
        "  --spm_model_file=\"from_tf_hub\" \\\n",
        "  --do_train=False \\\n",
        "  --do_eval=True \\\n",
        "  --do_predict=False \\\n",
        "  --max_seq_length=512 \\\n",
        "  --optimizer=adamw \\\n",
        "  --task_name=$TASK \\\n",
        "  --warmup_step=200 \\\n",
        "  --learning_rate=2e-5 \\\n",
        "  --train_step=800 \\\n",
        "  --save_checkpoints_steps=100 \\\n",
        "  --train_batch_size=32 \\\n",
        "  --tpu_name=$TPU_ADDRESS \\\n",
        "  --use_tpu=True "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: warning: here-document at line 0 delimited by end-of-file (wanted `RTE-0')\n",
            "I0108 23:42:47.405474 139785188919168 resolver.py:106] Using gs://luanps/albert-tfhub/models/RTE to cache modules.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "I0108 23:42:51.450412 139785188919168 saver.py:1503] Saver not created because there are no variables in the graph to restore\n",
            "2022-01-08 23:42:51.545013: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2022-01-08 23:42:51.558954: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2022-01-08 23:42:51.559011: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (b4f57ba9d735): /proc/driver/nvidia/version does not exist\n",
            "2022-01-08 23:42:51.564773: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2022-01-08 23:42:51.565019: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d5537c3b80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-01-08 23:42:51.565057: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "INFO:tensorflow:loading sentence piece model\n",
            "I0108 23:42:51.894387 139785188919168 tokenization.py:188] loading sentence piece model\n",
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f21d3a1eb90>) includes params argument, but params are not passed to Estimator.\n",
            "W0108 23:42:53.474712 139785188919168 estimator.py:1994] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f21d3a1eb90>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://luanps/albert-tfhub/models/RTE', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.76.183.170:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 0, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f21cc38c210>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.76.183.170:8470', '_evaluation_master': 'grpc://10.76.183.170:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f21d37c9650>}\n",
            "I0108 23:42:53.475557 139785188919168 estimator.py:212] Using config: {'_model_dir': 'gs://luanps/albert-tfhub/models/RTE', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.76.183.170:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 0, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f21cc38c210>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.76.183.170:8470', '_evaluation_master': 'grpc://10.76.183.170:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f21d37c9650>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "I0108 23:42:53.475822 139785188919168 tpu_context.py:220] _TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:***** Running evaluation *****\n",
            "I0108 23:42:53.629089 139785188919168 run_classifier.py:350] ***** Running evaluation *****\n",
            "INFO:tensorflow:  Num examples = 280 (277 actual, 3 padding)\n",
            "I0108 23:42:53.629420 139785188919168 run_classifier.py:353]   Num examples = 280 (277 actual, 3 padding)\n",
            "INFO:tensorflow:  Batch size = 8\n",
            "I0108 23:42:53.629559 139785188919168 run_classifier.py:354]   Batch size = 8\n",
            "INFO:tensorflow:Best trial info: Step: 800, Best Value Step: 600, Best Value: 0.7617328763008118\n",
            "I0108 23:42:54.119386 139785188919168 run_classifier.py:391] Best trial info: Step: 800, Best Value Step: 600, Best Value: 0.7617328763008118\n",
            "INFO:tensorflow:saving model.ckpt-600.meta to model.ckpt-best.meta\n",
            "I0108 23:42:54.119800 139785188919168 run_classifier.py:473] saving model.ckpt-600.meta to model.ckpt-best.meta\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/albert/run_classifier.py\", line 558, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 303, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 251, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/albert/run_classifier.py\", line 477, in main\n",
            "    overwrite=True)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/lib/io/file_io.py\", line 519, in rename_v2\n",
            "    compat.as_bytes(src), compat.as_bytes(dst), overwrite)\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: Error executing an HTTP request: HTTP response code 404 with body '{\n",
            "  \"error\": {\n",
            "    \"code\": 404,\n",
            "    \"message\": \"No such object: luanps/albert-tfhub/models/RTE/model.ckpt-600.meta\",\n",
            "    \"errors\": [\n",
            "      {\n",
            "        \"message\": \"No such object: luanps/albert-tfhub/models/RTE/model.ckpt-600.meta\",\n",
            "        \"domain\": \"global\",\n",
            "        \"reason\": \"notFound\"\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "'\n",
            "\t when renaming gs://luanps/albert-tfhub/models/RTE/model.ckpt-600.meta to gs://luanps/albert-tfhub/models/RTE/model.ckpt-best.meta\n"
          ]
        }
      ]
    }
  ]
}