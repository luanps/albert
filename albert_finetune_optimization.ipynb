{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "albert_glue_fine_tuning_tutorial",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8SJfpgTccDB"
      },
      "source": [
        "\n",
        "<a href=\"https://colab.research.google.com/github/luanps/albert/blob/master/albert_finetune_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHQH4OCHZ9bq",
        "cellView": "form"
      },
      "source": [
        "# @title Copyright 2020 The ALBERT Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkTLZ3I4_7c_"
      },
      "source": [
        "# ALBERT End to End (Fine-tuning + Predicting) with Cloud TPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wtjs1QDb3DX"
      },
      "source": [
        "## Overview\n",
        "\n",
        "ALBERT is \"A Lite\" version of BERT, a popular unsupervised language representation learning algorithm. ALBERT uses parameter-reduction techniques that allow for large-scale configurations, overcome previous memory limitations, and achieve better behavior with respect to model degradation.\n",
        "\n",
        "For a technical description of the algorithm, see our paper:\n",
        "\n",
        "https://arxiv.org/abs/1909.11942\n",
        "\n",
        "Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut\n",
        "\n",
        "This Colab demonstates using a free Colab Cloud TPU to fine-tune GLUE tasks built on top of pretrained ALBERT models and \n",
        "run predictions on tuned model. The colab demonsrates loading pretrained ALBERT models from both [TF Hub](https://www.tensorflow.org/hub) and checkpoints.\n",
        "\n",
        "**Note:**  You will need a GCP (Google Compute Engine) account and a GCS (Google Cloud \n",
        "Storage) bucket for this Colab to run.\n",
        "\n",
        "Please follow the [Google Cloud TPU quickstart](https://cloud.google.com/tpu/docs/quickstart) for how to create GCP account and GCS bucket. You have [$300 free credit](https://cloud.google.com/free/) to get started with any GCP product. You can learn more about Cloud TPU at https://cloud.google.com/tpu/docs.\n",
        "\n",
        "This notebook is hosted on GitHub. To view it in its original repository, after opening the notebook, select **File > View on GitHub**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld-JXlueIuPH"
      },
      "source": [
        "### Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POkof5uHaQ_c"
      },
      "source": [
        "<h3><a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>  &nbsp;&nbsp;Train on TPU</h3>\n",
        "\n",
        "   1. Create a Cloud Storage bucket for your TensorBoard logs at http://console.cloud.google.com/storage and fill in the BUCKET parameter in the \"Parameters\" section below.\n",
        " \n",
        "   1. On the main menu, click Runtime and select **Change runtime type**. Set \"TPU\" as the hardware accelerator.\n",
        "   1. Click Runtime again and select **Runtime > Run All** (Watch out: the \"Colab-only auth for this notebook and the TPU\" cell requires user input). You can also run the cells manually with Shift-ENTER."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdMmwCJFaT8F"
      },
      "source": [
        "### Set up your TPU environment\n",
        "\n",
        "In this section, you perform the following tasks:\n",
        "\n",
        "*   Set up a Colab TPU running environment\n",
        "*   Verify that you are connected to a TPU device\n",
        "*   Upload your credentials to TPU to access your GCS bucket."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "191zq3ZErihP",
        "outputId": "f5129ec3-49e2-4f6b-a1d6-5d82baefdac7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TODO(lanzhzh): Add support for 2.x.\n",
        "%tensorflow_version 1.x\n",
        "import os\n",
        "import pprint\n",
        "import json\n",
        "import tensorflow as tf\n",
        "\n",
        "assert \"COLAB_TPU_ADDR\" in os.environ, \"ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!\"\n",
        "TPU_ADDRESS = \"grpc://\" + os.environ[\"COLAB_TPU_ADDR\"] \n",
        "TPU_TOPOLOGY = \"2x2\"\n",
        "print(\"TPU address is\", TPU_ADDRESS)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "    # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "TPU address is grpc://10.109.125.66:8470\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 2409099261969407911),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 1549954337002144741),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 5510839357321454835),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 873393571816079649),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 9117514880373904260),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 12704941682957268373),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 10623130967391006998),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 17893873024629234993),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 9214549767924212172),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 6427061617775819593),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 2138631231408532535)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUBP35oCDmbF"
      },
      "source": [
        "### Prepare and import ALBERT modules\n",
        "​\n",
        "With your environment configured, you can now prepare and import the ALBERT modules. The following step clones the source code from GitHub."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wzwke0sxS6W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "code",
        "outputId": "6da2f095-81a0-4a4c-e4b3-5c102df7ddc4"
      },
      "source": [
        "import sys\n",
        "\n",
        "!test -d albert || git clone https://github.com/google-research/albert albert\n",
        "if not 'albert' in sys.path:\n",
        "  sys.path += ['albert']\n",
        "  \n",
        "!pip install sentencepiece\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'albert'...\n",
            "remote: Enumerating objects: 367, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 367 (delta 5), reused 6 (delta 3), pack-reused 353\u001b[K\n",
            "Receiving objects: 100% (367/367), 262.46 KiB | 3.50 MiB/s, done.\n",
            "Resolving deltas: 100% (237/237), done.\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRu1aKO1D7-Z"
      },
      "source": [
        "## Prepare for training\n",
        "\n",
        "This next section of code performs the following tasks:\n",
        "\n",
        "*  Specify GS bucket, create output directory for model checkpoints and eval results.\n",
        "*  Specify task and download training data.\n",
        "*  Specify ALBERT pretrained model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download GLUE data\n",
        "!git clone https://github.com/nyu-mll/GLUE-baselines download_glue\n",
        "\n",
        "GLUE_DIR='glue_data'\n",
        "!python download_glue/download_glue_data.py --data_dir $GLUE_DIR --tasks all"
      ],
      "metadata": {
        "id": "svpsMNG-vuko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYkaAlJNfhul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "ce1ec587-4156-48c2-e587-27d6c207203b"
      },
      "source": [
        "# Please find the full list of tasks and their fintuning hyperparameters\n",
        "# here https://github.com/google-research/albert/blob/master/run_glue.sh\n",
        "\n",
        "BUCKET = \"luanps\" #@param { type: \"string\" }\n",
        "TASK = 'RTE' #@param {type:\"string\"}\n",
        "# Available pretrained model checkpoints:\n",
        "#   base, large, xlarge, xxlarge\n",
        "ALBERT_MODEL = 'base' #@param {type:\"string\"}\n",
        "\n",
        "TASK_DATA_DIR = 'glue_data'\n",
        "\n",
        "BASE_DIR = \"gs://\" + BUCKET\n",
        "if not BASE_DIR or BASE_DIR == \"gs://\":\n",
        "  raise ValueError(\"You must enter a BUCKET.\")\n",
        "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
        "MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n",
        "OUTPUT_DIR = 'gs://{}/albert-tfhub/models/{}'.format(BUCKET, TASK)\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
        "\n",
        "# Download glue data.\n",
        "#! test -d download_glue_repo || git clone https://gist.github.com/60c2bdb54d156a41194446737ce03e2e.git download_glue_repo\n",
        "#!python download_glue_repo/download_glue_data.py --data_dir=$TASK_DATA_DIR --tasks=$TASK\n",
        "#print('***** Task data directory: {} *****'.format(TASK_DATA_DIR))\n",
        "\n",
        "ALBERT_MODEL_HUB = 'https://tfhub.dev/google/albert_' + ALBERT_MODEL + '/3'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Model output directory: gs://luanps/albert-tfhub/models/RTE *****\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hcpfl4N2EdOk"
      },
      "source": [
        "Now let's run the fine-tuning scripts. If you use the default MRPC task, this should be finished in around 10 mintues and you will get an accuracy of around 86.5."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choose hyperparameters using [Optuna](https://optuna.readthedocs.io/en/stable/index.html)"
      ],
      "metadata": {
        "id": "4v1sCZqXK36L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install Optuna optimzation lib\n",
        "!pip install optuna"
      ],
      "metadata": {
        "id": "WkVoRs_SD0KU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import uuid"
      ],
      "metadata": {
        "id": "lJsGSNqcI4gV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_last_acc_from_file(result_file):\n",
        "    f = open(result_file,'r')\n",
        "    results = f.readlines()\n",
        "    result_dict = dict()\n",
        "    for r in results:\n",
        "        if 'eval_accuracy' in r:\n",
        "            k,v = r.split(' = ')\n",
        "    return float(v)"
      ],
      "metadata": {
        "id": "iOJRxUusF-mH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "\n",
        "    #hyperparameter setting: RTE task\n",
        "    warmup_steps = trial.suggest_int('warmup_steps', 100, 500,100)\n",
        "    train_steps = trial.suggest_int('train_steps', 400, 2000,100)\n",
        "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 5e-5)\n",
        "    batch_size = trial.suggest_int('batch_size', 16, 128,16)\n",
        "\n",
        "    #Tmp config\n",
        "    id = str(uuid.uuid4()).split('-')[0]\n",
        "    OUTPUT_TMP = f'{OUTPUT_DIR}/{id}'\n",
        "    os.environ['TFHUB_CACHE_DIR'] = OUTPUT_TMP\n",
        "\n",
        "    !python -m albert.run_classifier \\\n",
        "            --data_dir=\"glue_data/\" \\\n",
        "            --output_dir=$OUTPUT_TMP \\\n",
        "            --albert_hub_module_handle=$ALBERT_MODEL_HUB \\\n",
        "            --spm_model_file=\"from_tf_hub\" \\\n",
        "            --do_train=True \\\n",
        "            --do_eval=True \\\n",
        "            --do_predict=False \\\n",
        "            --max_seq_length=512 \\\n",
        "            --optimizer=adamw \\\n",
        "            --task_name=$TASK \\\n",
        "            --warmup_step=$warmup_steps \\\n",
        "            --learning_rate=$learning_rate \\\n",
        "            --train_step=$train_steps \\\n",
        "            --save_checkpoints_steps=100 \\\n",
        "            --train_batch_size=$batch_size\\\n",
        "            --tpu_name=$TPU_ADDRESS \\\n",
        "            --use_tpu=True\n",
        "\n",
        "    #Download results and load model accuracy\n",
        "    !mkdir $id\n",
        "    !gsutil cp $OUTPUT_TMP/eval_results.txt $id\n",
        "    model_acc = get_last_acc_from_file(f'{id}/eval_results.txt')\n",
        "    return model_acc"
      ],
      "metadata": {
        "id": "1KfYFZIYEGUA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run Optuna optimization\n",
        "study = optuna.create_study(direction='maximize',study_name=TASK)\n",
        "study.optimize(objective, n_trials=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeHjYq30Ix2X",
        "outputId": "79fd93f8-1da6-48f8-b385-b0d5cd7c974e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:13:32.819691 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:13:32.820758 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:13:32.821714 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:13:32.822740 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:13:32.823855 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:13:32.824859 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:13:32.825774 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:13:32.826822 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:13:32.827864 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:13:32.828953 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:13:32.829945 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:13:32.830961 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:13:32.831892 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:13:32.832744 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:13:32.833865 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:13:32.834908 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:13:32.835997 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:13:32.836968 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:***** Running training *****\n",
            "I0109 12:13:33.433225 140581979633536 run_classifier.py:315] ***** Running training *****\n",
            "INFO:tensorflow:  Num examples = 2490\n",
            "I0109 12:13:33.433519 140581979633536 run_classifier.py:316]   Num examples = 2490\n",
            "INFO:tensorflow:  Batch size = 128\n",
            "I0109 12:13:33.433668 140581979633536 run_classifier.py:317]   Batch size = 128\n",
            "INFO:tensorflow:  Num steps = 50\n",
            "I0109 12:13:33.433770 140581979633536 run_classifier.py:318]   Num steps = 50\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.109.125.66:8470) for TPU system metadata.\n",
            "I0109 12:13:33.702990 140581979633536 tpu_system_metadata.py:78] Querying Tensorflow master (grpc://10.109.125.66:8470) for TPU system metadata.\n",
            "2022-01-09 12:13:33.704484: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:370] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "I0109 12:13:33.718057 140581979633536 tpu_system_metadata.py:148] Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "I0109 12:13:33.718311 140581979633536 tpu_system_metadata.py:149] *** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "I0109 12:13:33.718420 140581979633536 tpu_system_metadata.py:150] *** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "I0109 12:13:33.718507 140581979633536 tpu_system_metadata.py:152] *** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2409099261969407911)\n",
            "I0109 12:13:33.718588 140581979633536 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2409099261969407911)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 5510839357321454835)\n",
            "I0109 12:13:33.718880 140581979633536 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 5510839357321454835)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 873393571816079649)\n",
            "I0109 12:13:33.718967 140581979633536 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 873393571816079649)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 9117514880373904260)\n",
            "I0109 12:13:33.719056 140581979633536 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 9117514880373904260)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 12704941682957268373)\n",
            "I0109 12:13:33.719138 140581979633536 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 12704941682957268373)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 10623130967391006998)\n",
            "I0109 12:13:33.719218 140581979633536 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 10623130967391006998)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 17893873024629234993)\n",
            "I0109 12:13:33.719304 140581979633536 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 17893873024629234993)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 9214549767924212172)\n",
            "I0109 12:13:33.719384 140581979633536 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 9214549767924212172)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 6427061617775819593)\n",
            "I0109 12:13:33.719464 140581979633536 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 6427061617775819593)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 2138631231408532535)\n",
            "I0109 12:13:33.719542 140581979633536 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 2138631231408532535)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 1549954337002144741)\n",
            "I0109 12:13:33.719644 140581979633536 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 1549954337002144741)\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "W0109 12:13:33.729676 140581979633536 deprecation.py:506] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0109 12:13:33.730422 140581979633536 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0109 12:13:33.743513 140581979633536 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /content/albert/classifier_utils.py:744: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "W0109 12:13:33.766099 140581979633536 deprecation.py:323] From /content/albert/classifier_utils.py:744: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "W0109 12:13:33.766397 140581979633536 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "WARNING:tensorflow:Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fdb57782f80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "W0109 12:13:33.778847 140581979633536 ag_logging.py:146] Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fdb57782f80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:From /content/albert/classifier_utils.py:721: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0109 12:13:33.788411 140581979633536 deprecation.py:323] From /content/albert/classifier_utils.py:721: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:*** Features ***\n",
            "I0109 12:13:33.861853 140581979633536 classifier_utils.py:824] *** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (16, 512)\n",
            "I0109 12:13:33.862135 140581979633536 classifier_utils.py:826]   name = input_ids, shape = (16, 512)\n",
            "INFO:tensorflow:  name = input_mask, shape = (16, 512)\n",
            "I0109 12:13:33.862252 140581979633536 classifier_utils.py:826]   name = input_mask, shape = (16, 512)\n",
            "INFO:tensorflow:  name = is_real_example, shape = (16,)\n",
            "I0109 12:13:33.862348 140581979633536 classifier_utils.py:826]   name = is_real_example, shape = (16,)\n",
            "INFO:tensorflow:  name = label_ids, shape = (16,)\n",
            "I0109 12:13:33.862452 140581979633536 classifier_utils.py:826]   name = label_ids, shape = (16,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (16, 512)\n",
            "I0109 12:13:33.862553 140581979633536 classifier_utils.py:826]   name = segment_ids, shape = (16, 512)\n",
            "INFO:tensorflow:creating model from hub_module: https://tfhub.dev/google/albert_base/3\n",
            "I0109 12:13:33.863482 140581979633536 fine_tuning_utils.py:65] creating model from hub_module: https://tfhub.dev/google/albert_base/3\n",
            "E0109 12:13:38.196300 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/input_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:38.196967 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/input_mask) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:38.198031 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/segment_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:38.198416 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/mlm_positions) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:38.201919 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/word_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:38.208097 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/token_type_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:38.214258 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/position_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:38.217283 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:38.218471 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:38.226345 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/embedding_hidden_mapping_in/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:38.227489 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/embedding_hidden_mapping_in/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:38.238079 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:38.239909 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:38.249492 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:38.251251 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:38.260359 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:38.262130 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:38.280758 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:38.282660 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:38.288717 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:38.289988 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:38.296553 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:38.298155 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:38.307913 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:38.309152 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:38.314445 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:38.315577 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:39.038372 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:39.040494 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:39.053581 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:39.054900 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:39.060625 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:39.062132 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:13:39.066902 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/output_bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "I0109 12:13:39.171106 140581979633536 saver.py:1503] Saver not created because there are no variables in the graph to restore\n",
            "WARNING:tensorflow:From /content/albert/classifier_utils.py:794: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0109 12:13:39.302947 140581979633536 deprecation.py:506] From /content/albert/classifier_utils.py:794: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "I0109 12:13:39.331990 140581979633536 classifier_utils.py:861] **** Trainable Variables ****\n",
            "INFO:tensorflow:  name = module/bert/embeddings/word_embeddings:0, shape = (30000, 128)\n",
            "I0109 12:13:39.332218 140581979633536 classifier_utils.py:867]   name = module/bert/embeddings/word_embeddings:0, shape = (30000, 128)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/token_type_embeddings:0, shape = (2, 128)\n",
            "I0109 12:13:39.332324 140581979633536 classifier_utils.py:867]   name = module/bert/embeddings/token_type_embeddings:0, shape = (2, 128)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/position_embeddings:0, shape = (512, 128)\n",
            "I0109 12:13:39.332402 140581979633536 classifier_utils.py:867]   name = module/bert/embeddings/position_embeddings:0, shape = (512, 128)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/LayerNorm/beta:0, shape = (128,)\n",
            "I0109 12:13:39.332474 140581979633536 classifier_utils.py:867]   name = module/bert/embeddings/LayerNorm/beta:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/LayerNorm/gamma:0, shape = (128,)\n",
            "I0109 12:13:39.332540 140581979633536 classifier_utils.py:867]   name = module/bert/embeddings/LayerNorm/gamma:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/embedding_hidden_mapping_in/kernel:0, shape = (128, 768)\n",
            "I0109 12:13:39.332633 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/embedding_hidden_mapping_in/kernel:0, shape = (128, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/embedding_hidden_mapping_in/bias:0, shape = (768,)\n",
            "I0109 12:13:39.332732 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/embedding_hidden_mapping_in/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel:0, shape = (768, 768)\n",
            "I0109 12:13:39.332798 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias:0, shape = (768,)\n",
            "I0109 12:13:39.332874 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel:0, shape = (768, 768)\n",
            "I0109 12:13:39.332939 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias:0, shape = (768,)\n",
            "I0109 12:13:39.333006 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel:0, shape = (768, 768)\n",
            "I0109 12:13:39.333070 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias:0, shape = (768,)\n",
            "I0109 12:13:39.333136 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel:0, shape = (768, 768)\n",
            "I0109 12:13:39.333200 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias:0, shape = (768,)\n",
            "I0109 12:13:39.333266 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta:0, shape = (768,)\n",
            "I0109 12:13:39.333328 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma:0, shape = (768,)\n",
            "I0109 12:13:39.333391 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0109 12:13:39.333451 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0109 12:13:39.333516 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0109 12:13:39.333577 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias:0, shape = (768,)\n",
            "I0109 12:13:39.333657 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta:0, shape = (768,)\n",
            "I0109 12:13:39.333720 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma:0, shape = (768,)\n",
            "I0109 12:13:39.333781 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "I0109 12:13:39.333845 140581979633536 classifier_utils.py:867]   name = module/bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/pooler/dense/bias:0, shape = (768,)\n",
            "I0109 12:13:39.333912 140581979633536 classifier_utils.py:867]   name = module/bert/pooler/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/dense/kernel:0, shape = (768, 128)\n",
            "I0109 12:13:39.333974 140581979633536 classifier_utils.py:867]   name = module/cls/predictions/transform/dense/kernel:0, shape = (768, 128)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/dense/bias:0, shape = (128,)\n",
            "I0109 12:13:39.334038 140581979633536 classifier_utils.py:867]   name = module/cls/predictions/transform/dense/bias:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/LayerNorm/beta:0, shape = (128,)\n",
            "I0109 12:13:39.334100 140581979633536 classifier_utils.py:867]   name = module/cls/predictions/transform/LayerNorm/beta:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/LayerNorm/gamma:0, shape = (128,)\n",
            "I0109 12:13:39.334160 140581979633536 classifier_utils.py:867]   name = module/cls/predictions/transform/LayerNorm/gamma:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/output_bias:0, shape = (30000,)\n",
            "I0109 12:13:39.334220 140581979633536 classifier_utils.py:867]   name = module/cls/predictions/output_bias:0, shape = (30000,)\n",
            "INFO:tensorflow:  name = output_weights:0, shape = (2, 768)\n",
            "I0109 12:13:39.334281 140581979633536 classifier_utils.py:867]   name = output_weights:0, shape = (2, 768)\n",
            "INFO:tensorflow:  name = output_bias:0, shape = (2,)\n",
            "I0109 12:13:39.334347 140581979633536 classifier_utils.py:867]   name = output_bias:0, shape = (2,)\n",
            "INFO:tensorflow:++++++ warmup starts at step 0, for 5 steps ++++++\n",
            "I0109 12:13:39.347067 140581979633536 optimization.py:51] ++++++ warmup starts at step 0, for 5 steps ++++++\n",
            "INFO:tensorflow:using adamw\n",
            "I0109 12:13:39.360962 140581979633536 optimization.py:75] using adamw\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0109 12:13:39.639619 140581979633536 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0109 12:13:45.043061 140581979633536 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0109 12:13:45.113287 140581979633536 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "I0109 12:13:48.349229 140581979633536 tpu_estimator.py:506] TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0109 12:13:48.593628 140581979633536 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0109 12:13:55.126081 140581979633536 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0109 12:13:55.480996 140581979633536 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into gs://luanps/albert-tfhub/models/RTE/09be5328/model.ckpt.\n",
            "I0109 12:14:03.526586 140581979633536 basic_session_run_hooks.py:606] Saving checkpoints for 0 into gs://luanps/albert-tfhub/models/RTE/09be5328/model.ckpt.\n",
            "INFO:tensorflow:gs://luanps/albert-tfhub/models/RTE/09be5328/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.\n",
            "I0109 12:14:12.589105 140581979633536 checkpoint_management.py:95] gs://luanps/albert-tfhub/models/RTE/09be5328/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:751: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "W0109 12:14:16.865718 140581979633536 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:751: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "I0109 12:14:17.748406 140581979633536 util.py:98] Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "I0109 12:14:17.748880 140581979633536 session_support.py:332] Installing graceful shutdown hook.\n",
            "2022-01-09 12:14:17.749259: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:370] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "I0109 12:14:17.754139 140581979633536 session_support.py:82] Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "I0109 12:14:17.756376 140581979633536 session_support.py:105] Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Init TPU system\n",
            "I0109 12:14:17.760337 140581979633536 tpu_estimator.py:567] Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 13 seconds\n",
            "I0109 12:14:31.677556 140581979633536 tpu_estimator.py:576] Initialized TPU in 13 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "I0109 12:14:31.678437 140579848582912 tpu_estimator.py:521] Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "I0109 12:14:31.678801 140579840190208 tpu_estimator.py:540] Starting outfeed thread controller.\n",
            "INFO:tensorflow:Enqueue next (50) batch(es) of data to infeed.\n",
            "I0109 12:14:32.131584 140581979633536 tpu_estimator.py:600] Enqueue next (50) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (50) batch(es) of data from outfeed.\n",
            "I0109 12:14:32.131937 140581979633536 tpu_estimator.py:604] Dequeue next (50) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "I0109 12:14:48.374766 140579840190208 tpu_estimator.py:279] Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:loss = 0.41519833, step = 50\n",
            "I0109 12:15:12.932928 140581979633536 basic_session_run_hooks.py:262] loss = 0.41519833, step = 50\n",
            "INFO:tensorflow:Saving checkpoints for 50 into gs://luanps/albert-tfhub/models/RTE/09be5328/model.ckpt.\n",
            "I0109 12:15:12.934721 140581979633536 basic_session_run_hooks.py:606] Saving checkpoints for 50 into gs://luanps/albert-tfhub/models/RTE/09be5328/model.ckpt.\n",
            "INFO:tensorflow:gs://luanps/albert-tfhub/models/RTE/09be5328/model.ckpt-50 is not in all_model_checkpoint_paths. Manually adding it.\n",
            "I0109 12:15:22.290886 140581979633536 checkpoint_management.py:95] gs://luanps/albert-tfhub/models/RTE/09be5328/model.ckpt-50 is not in all_model_checkpoint_paths. Manually adding it.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "I0109 12:15:26.988698 140581979633536 tpu_estimator.py:608] Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "I0109 12:15:26.988970 140581979633536 tpu_estimator.py:434] Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "I0109 12:15:26.989127 140579848582912 tpu_estimator.py:429] InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "I0109 12:15:26.989204 140579848582912 tpu_estimator.py:537] Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "I0109 12:15:26.989544 140581979633536 error_handling.py:101] infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "I0109 12:15:26.989691 140581979633536 tpu_estimator.py:612] Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "I0109 12:15:26.989749 140581979633536 tpu_estimator.py:434] Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "I0109 12:15:26.989852 140579840190208 tpu_estimator.py:429] OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "I0109 12:15:26.989911 140579840190208 tpu_estimator.py:551] Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "I0109 12:15:26.990061 140581979633536 error_handling.py:101] outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "I0109 12:15:26.990138 140581979633536 tpu_estimator.py:616] Shutdown TPU system.\n",
            "INFO:tensorflow:Loss for final step: 0.41519833.\n",
            "I0109 12:15:27.743026 140581979633536 estimator.py:371] Loss for final step: 0.41519833.\n",
            "INFO:tensorflow:training_loop marked as finished\n",
            "I0109 12:15:27.743551 140581979633536 error_handling.py:101] training_loop marked as finished\n",
            "INFO:tensorflow:Writing example 0 of 280\n",
            "I0109 12:15:28.031961 140581979633536 classifier_utils.py:671] Writing example 0 of 280\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.032518 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0109 12:15:28.032893 140581979633536 classifier_utils.py:645] *** Example ***\n",
            "INFO:tensorflow:guid: 0\n",
            "I0109 12:15:28.033003 140581979633536 classifier_utils.py:646] guid: 0\n",
            "INFO:tensorflow:tokens: [CLS] ▁dana ▁reeve , ▁the ▁widow ▁of ▁the ▁actor ▁christopher ▁reeve , ▁has ▁died ▁of ▁lung ▁cancer ▁at ▁age ▁44 , ▁according ▁to ▁the ▁christopher ▁reeve ▁foundation . [SEP] ▁christopher ▁reeve ▁had ▁an ▁accident . [SEP]\n",
            "I0109 12:15:28.033120 140581979633536 classifier_utils.py:648] tokens: [CLS] ▁dana ▁reeve , ▁the ▁widow ▁of ▁the ▁actor ▁christopher ▁reeve , ▁has ▁died ▁of ▁lung ▁cancer ▁at ▁age ▁44 , ▁according ▁to ▁the ▁christopher ▁reeve ▁foundation . [SEP] ▁christopher ▁reeve ▁had ▁an ▁accident . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 11478 24604 15 14 5151 16 14 1574 4479 24604 15 63 440 16 9223 2637 35 348 4576 15 496 20 14 4479 24604 1304 9 3 4479 24604 41 40 3351 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:15:28.033435 140581979633536 classifier_utils.py:649] input_ids: 2 11478 24604 15 14 5151 16 14 1574 4479 24604 15 63 440 16 9223 2637 35 348 4576 15 496 20 14 4479 24604 1304 9 3 4479 24604 41 40 3351 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:15:28.033720 140581979633536 classifier_utils.py:650] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:15:28.033944 140581979633536 classifier_utils.py:651] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: not_entailment (id = 1)\n",
            "I0109 12:15:28.034036 140581979633536 classifier_utils.py:652] label: not_entailment (id = 1)\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.035000 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0109 12:15:28.035372 140581979633536 classifier_utils.py:645] *** Example ***\n",
            "INFO:tensorflow:guid: 1\n",
            "I0109 12:15:28.035473 140581979633536 classifier_utils.py:646] guid: 1\n",
            "INFO:tensorflow:tokens: [CLS] ▁yet , ▁we ▁now ▁are ▁discovering ▁that ▁antibiotic s ▁are ▁losing ▁their ▁effectiveness ▁against ▁illness . ▁disease - ca using ▁bacteria ▁are ▁muta ting ▁faster ▁than ▁we ▁can ▁come ▁up ▁with ▁new ▁antibiotic s ▁to ▁fight ▁the ▁new ▁variations . [SEP] ▁bacteria ▁is ▁winning ▁the ▁war ▁against ▁antibiotic s . [SEP]\n",
            "I0109 12:15:28.035608 140581979633536 classifier_utils.py:648] tokens: [CLS] ▁yet , ▁we ▁now ▁are ▁discovering ▁that ▁antibiotic s ▁are ▁losing ▁their ▁effectiveness ▁against ▁illness . ▁disease - ca using ▁bacteria ▁are ▁muta ting ▁faster ▁than ▁we ▁can ▁come ▁up ▁with ▁new ▁antibiotic s ▁to ▁fight ▁the ▁new ▁variations . [SEP] ▁bacteria ▁is ▁winning ▁the ▁war ▁against ▁antibiotic s . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 768 15 95 130 50 15799 30 20017 18 50 2281 66 14115 149 6761 9 2515 8 793 12655 10955 50 22673 1203 4233 119 95 92 340 71 29 78 20017 18 20 1074 14 78 8194 9 3 10955 25 1414 14 176 149 20017 18 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:15:28.035836 140581979633536 classifier_utils.py:649] input_ids: 2 768 15 95 130 50 15799 30 20017 18 50 2281 66 14115 149 6761 9 2515 8 793 12655 10955 50 22673 1203 4233 119 95 92 340 71 29 78 20017 18 20 1074 14 78 8194 9 3 10955 25 1414 14 176 149 20017 18 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:15:28.036047 140581979633536 classifier_utils.py:650] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:15:28.036256 140581979633536 classifier_utils.py:651] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: entailment (id = 0)\n",
            "I0109 12:15:28.036347 140581979633536 classifier_utils.py:652] label: entailment (id = 0)\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.037704 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0109 12:15:28.038209 140581979633536 classifier_utils.py:645] *** Example ***\n",
            "INFO:tensorflow:guid: 2\n",
            "I0109 12:15:28.038317 140581979633536 classifier_utils.py:646] guid: 2\n",
            "INFO:tensorflow:tokens: [CLS] ▁cairo ▁is ▁now ▁home ▁to ▁some ▁15 ▁million ▁people ▁ - ▁a ▁burgeoning ▁population ▁that ▁produces ▁approximately ▁10,000 ▁tonnes ▁of ▁rubbish ▁per ▁day , ▁putting ▁an ▁enormous ▁strain ▁on ▁public ▁services . ▁in ▁the ▁past ▁10 ▁years , ▁the ▁government ▁has ▁tried ▁hard ▁to ▁encourage ▁private ▁investment ▁in ▁the ▁refuse ▁sector , ▁but ▁some ▁estimate ▁4,000 ▁tonnes ▁of ▁waste ▁is ▁left ▁behind ▁every ▁day , ▁fest ering ▁in ▁the ▁heat ▁as ▁it ▁wait s ▁for ▁someone ▁to ▁clear ▁it ▁up . ▁it ▁is ▁often ▁the ▁people ▁in ▁the ▁poor est ▁neighbourhood s ▁that ▁are ▁worst ▁affected . ▁but ▁in ▁some ▁areas ▁they ▁are ▁fighting ▁back . ▁in ▁shu bra , ▁one ▁of ▁the ▁northern ▁districts ▁of ▁the ▁city , ▁the ▁residents ▁have ▁taken ▁to ▁the ▁streets ▁armed ▁with ▁dust pan s ▁and ▁brushes ▁to ▁clean ▁up ▁public ▁areas ▁which ▁have ▁been ▁used ▁as ▁public ▁dump s . [SEP] ▁15 ▁million ▁tonnes ▁of ▁rubbish ▁are ▁produced ▁daily ▁in ▁cairo . [SEP]\n",
            "I0109 12:15:28.038470 140581979633536 classifier_utils.py:648] tokens: [CLS] ▁cairo ▁is ▁now ▁home ▁to ▁some ▁15 ▁million ▁people ▁ - ▁a ▁burgeoning ▁population ▁that ▁produces ▁approximately ▁10,000 ▁tonnes ▁of ▁rubbish ▁per ▁day , ▁putting ▁an ▁enormous ▁strain ▁on ▁public ▁services . ▁in ▁the ▁past ▁10 ▁years , ▁the ▁government ▁has ▁tried ▁hard ▁to ▁encourage ▁private ▁investment ▁in ▁the ▁refuse ▁sector , ▁but ▁some ▁estimate ▁4,000 ▁tonnes ▁of ▁waste ▁is ▁left ▁behind ▁every ▁day , ▁fest ering ▁in ▁the ▁heat ▁as ▁it ▁wait s ▁for ▁someone ▁to ▁clear ▁it ▁up . ▁it ▁is ▁often ▁the ▁people ▁in ▁the ▁poor est ▁neighbourhood s ▁that ▁are ▁worst ▁affected . ▁but ▁in ▁some ▁areas ▁they ▁are ▁fighting ▁back . ▁in ▁shu bra , ▁one ▁of ▁the ▁northern ▁districts ▁of ▁the ▁city , ▁the ▁residents ▁have ▁taken ▁to ▁the ▁streets ▁armed ▁with ▁dust pan s ▁and ▁brushes ▁to ▁clean ▁up ▁public ▁areas ▁which ▁have ▁been ▁used ▁as ▁public ▁dump s . [SEP] ▁15 ▁million ▁tonnes ▁of ▁rubbish ▁are ▁produced ▁daily ▁in ▁cairo . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 11772 25 130 213 20 109 357 507 148 13 8 21 29936 350 30 6700 1357 6693 11485 16 28898 416 208 15 3873 40 7135 8302 27 317 687 9 19 14 640 332 122 15 14 283 63 794 552 20 8333 932 3709 19 14 10198 3172 15 47 109 10243 13845 11485 16 4600 25 225 439 352 208 15 11837 7882 19 14 1737 28 32 1760 18 26 737 20 1207 32 71 9 32 25 478 14 148 19 14 1696 1430 9876 18 30 50 4126 4114 9 47 19 109 924 59 50 1849 97 9 19 5728 2559 15 53 16 14 743 3872 16 14 136 15 14 2175 57 658 20 14 3240 2799 29 4346 3206 18 17 25079 20 2745 71 317 924 56 57 74 147 28 317 11424 18 9 3 357 507 11485 16 28898 50 671 1954 19 11772 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:15:28.053325 140581979633536 classifier_utils.py:649] input_ids: 2 11772 25 130 213 20 109 357 507 148 13 8 21 29936 350 30 6700 1357 6693 11485 16 28898 416 208 15 3873 40 7135 8302 27 317 687 9 19 14 640 332 122 15 14 283 63 794 552 20 8333 932 3709 19 14 10198 3172 15 47 109 10243 13845 11485 16 4600 25 225 439 352 208 15 11837 7882 19 14 1737 28 32 1760 18 26 737 20 1207 32 71 9 32 25 478 14 148 19 14 1696 1430 9876 18 30 50 4126 4114 9 47 19 109 924 59 50 1849 97 9 19 5728 2559 15 53 16 14 743 3872 16 14 136 15 14 2175 57 658 20 14 3240 2799 29 4346 3206 18 17 25079 20 2745 71 317 924 56 57 74 147 28 317 11424 18 9 3 357 507 11485 16 28898 50 671 1954 19 11772 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:15:28.053795 140581979633536 classifier_utils.py:650] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:15:28.054121 140581979633536 classifier_utils.py:651] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: not_entailment (id = 1)\n",
            "I0109 12:15:28.054281 140581979633536 classifier_utils.py:652] label: not_entailment (id = 1)\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.056096 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0109 12:15:28.056566 140581979633536 classifier_utils.py:645] *** Example ***\n",
            "INFO:tensorflow:guid: 3\n",
            "I0109 12:15:28.056683 140581979633536 classifier_utils.py:646] guid: 3\n",
            "INFO:tensorflow:tokens: [CLS] ▁the ▁a mish ▁community ▁in ▁pennsylvania , ▁which ▁numbers ▁about ▁5 5,000 , ▁lives ▁an ▁agrarian ▁lifestyle , ▁shun ning ▁technological ▁advances ▁like ▁electricity ▁and ▁automobile s . ▁and ▁many ▁say ▁their ▁in s ular ▁lifestyle ▁gives ▁them ▁a ▁sense ▁that ▁they ▁are ▁protected ▁from ▁the ▁violence ▁of ▁american ▁society . ▁but ▁as ▁residents ▁gathered ▁near ▁the ▁school , ▁some ▁wearing ▁traditional ▁garb ▁and ▁arriving ▁in ▁horse - drawn ▁bug gies , ▁they ▁said ▁that ▁sense ▁of ▁safety ▁had ▁been ▁shattered . ▁ \" if ▁someone ▁snap s ▁and ▁wants ▁to ▁do ▁something ▁stupid , ▁there ' s ▁no ▁distance ▁that ' s ▁going ▁to ▁stop ▁them , \" ▁said ▁jake ▁king , ▁56 , ▁an ▁a mish ▁lantern ▁maker ▁who ▁knew ▁several ▁families ▁whose ▁children ▁had ▁been ▁shot . [SEP] ▁pennsylvania ▁has ▁the ▁biggest ▁a mish ▁community ▁in ▁the ▁u . s . [SEP]\n",
            "I0109 12:15:28.056834 140581979633536 classifier_utils.py:648] tokens: [CLS] ▁the ▁a mish ▁community ▁in ▁pennsylvania , ▁which ▁numbers ▁about ▁5 5,000 , ▁lives ▁an ▁agrarian ▁lifestyle , ▁shun ning ▁technological ▁advances ▁like ▁electricity ▁and ▁automobile s . ▁and ▁many ▁say ▁their ▁in s ular ▁lifestyle ▁gives ▁them ▁a ▁sense ▁that ▁they ▁are ▁protected ▁from ▁the ▁violence ▁of ▁american ▁society . ▁but ▁as ▁residents ▁gathered ▁near ▁the ▁school , ▁some ▁wearing ▁traditional ▁garb ▁and ▁arriving ▁in ▁horse - drawn ▁bug gies , ▁they ▁said ▁that ▁sense ▁of ▁safety ▁had ▁been ▁shattered . ▁ \" if ▁someone ▁snap s ▁and ▁wants ▁to ▁do ▁something ▁stupid , ▁there ' s ▁no ▁distance ▁that ' s ▁going ▁to ▁stop ▁them , \" ▁said ▁jake ▁king , ▁56 , ▁an ▁a mish ▁lantern ▁maker ▁who ▁knew ▁several ▁families ▁whose ▁children ▁had ▁been ▁shot . [SEP] ▁pennsylvania ▁has ▁the ▁biggest ▁a mish ▁community ▁in ▁the ▁u . s . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 14 21 10758 514 19 1806 15 56 2116 88 331 5157 15 1551 40 24463 8937 15 15800 2981 10381 10592 101 5592 17 8199 18 9 17 151 395 66 19 18 7451 8937 2352 105 21 1259 30 59 50 3803 37 14 3300 16 189 641 9 47 28 2175 4744 424 14 116 15 109 2466 1361 19646 17 6426 19 1729 8 19950 6256 19008 15 59 87 30 1259 16 2108 41 74 11915 9 13 7 821 737 6877 18 17 2846 20 107 301 3553 15 80 22 18 90 1583 30 22 18 228 20 747 105 15 7 87 3777 437 15 6171 15 40 21 10758 11585 11767 72 404 238 1250 1196 391 41 74 999 9 3 1806 63 14 3835 21 10758 514 19 14 287 9 18 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:15:28.057059 140581979633536 classifier_utils.py:649] input_ids: 2 14 21 10758 514 19 1806 15 56 2116 88 331 5157 15 1551 40 24463 8937 15 15800 2981 10381 10592 101 5592 17 8199 18 9 17 151 395 66 19 18 7451 8937 2352 105 21 1259 30 59 50 3803 37 14 3300 16 189 641 9 47 28 2175 4744 424 14 116 15 109 2466 1361 19646 17 6426 19 1729 8 19950 6256 19008 15 59 87 30 1259 16 2108 41 74 11915 9 13 7 821 737 6877 18 17 2846 20 107 301 3553 15 80 22 18 90 1583 30 22 18 228 20 747 105 15 7 87 3777 437 15 6171 15 40 21 10758 11585 11767 72 404 238 1250 1196 391 41 74 999 9 3 1806 63 14 3835 21 10758 514 19 14 287 9 18 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:15:28.057359 140581979633536 classifier_utils.py:650] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:15:28.057673 140581979633536 classifier_utils.py:651] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: not_entailment (id = 1)\n",
            "I0109 12:15:28.057792 140581979633536 classifier_utils.py:652] label: not_entailment (id = 1)\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.058676 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0109 12:15:28.059170 140581979633536 classifier_utils.py:645] *** Example ***\n",
            "INFO:tensorflow:guid: 4\n",
            "I0109 12:15:28.059292 140581979633536 classifier_utils.py:646] guid: 4\n",
            "INFO:tensorflow:tokens: [CLS] ▁security ▁forces ▁were ▁on ▁high ▁alert ▁after ▁an ▁election ▁campaign ▁in ▁which ▁more ▁than ▁1,000 ▁people , ▁including ▁seven ▁election ▁candidates , ▁have ▁been ▁killed . [SEP] ▁security ▁forces ▁were ▁on ▁high ▁alert ▁after ▁a ▁campaign ▁marred ▁by ▁violence . [SEP]\n",
            "I0109 12:15:28.059408 140581979633536 classifier_utils.py:648] tokens: [CLS] ▁security ▁forces ▁were ▁on ▁high ▁alert ▁after ▁an ▁election ▁campaign ▁in ▁which ▁more ▁than ▁1,000 ▁people , ▁including ▁seven ▁election ▁candidates , ▁have ▁been ▁killed . [SEP] ▁security ▁forces ▁were ▁on ▁high ▁alert ▁after ▁a ▁campaign ▁marred ▁by ▁violence . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 1221 879 46 27 183 7863 75 40 776 1150 19 56 91 119 5925 148 15 215 810 776 4074 15 57 74 841 9 3 1221 879 46 27 183 7863 75 21 1150 26479 34 3300 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:15:28.059632 140581979633536 classifier_utils.py:649] input_ids: 2 1221 879 46 27 183 7863 75 40 776 1150 19 56 91 119 5925 148 15 215 810 776 4074 15 57 74 841 9 3 1221 879 46 27 183 7863 75 21 1150 26479 34 3300 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:15:28.059851 140581979633536 classifier_utils.py:650] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:15:28.060060 140581979633536 classifier_utils.py:651] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: entailment (id = 0)\n",
            "I0109 12:15:28.156028 140581979633536 classifier_utils.py:652] label: entailment (id = 0)\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.158151 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.160096 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.161778 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.162784 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.163699 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.164723 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.165587 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.166475 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.167418 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.168339 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.169221 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.170046 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.171014 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.171935 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.172932 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.174093 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.175170 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.176379 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.177521 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.178669 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.179569 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.180441 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.181395 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.182251 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.183193 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.184069 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.185114 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.186399 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.187502 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.188390 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.189231 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.190123 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.191040 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.191887 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.192738 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.193573 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.194485 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.195528 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.196452 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.197397 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.198436 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.199365 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.200194 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.201026 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.201930 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.202841 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.203871 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.204854 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.205735 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.206572 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.207427 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.208467 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.209407 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.210230 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.211099 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.211968 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.213098 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.214044 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.215081 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.216081 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.217007 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.218234 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.219717 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.220664 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.221763 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.222755 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.224022 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.225043 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.226070 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.227102 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.228090 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.229038 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.229956 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.231040 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.232082 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.232981 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.233765 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.234573 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.235491 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.236374 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.237388 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.238312 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.239241 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.240148 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.241279 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.242439 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.243337 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.244331 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.245246 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.246121 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.247167 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.248196 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.249067 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.249937 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.251050 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.252324 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.253330 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.254178 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.255723 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.257181 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.258698 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.260369 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.261921 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.263334 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.266744 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.268790 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.270548 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.272064 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.273548 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.275328 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.277008 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.278423 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.280084 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.281513 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.282974 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.284399 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.285795 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.287139 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.288874 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.290382 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.292193 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.295526 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.297260 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.298214 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.299426 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.300573 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.301710 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.302718 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.303657 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.304724 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.305634 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.306583 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.307538 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.308440 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.309515 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.310479 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.311426 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.312497 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.313422 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.314292 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.315146 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.316032 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.316988 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.317911 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.318912 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.319815 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.320737 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.321789 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.322947 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.324001 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.325107 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.326167 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.327269 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.328281 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.329168 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.330086 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.331035 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.331946 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.332825 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.333801 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.334739 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.335707 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.336645 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.337543 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.338432 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.339347 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.340267 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.341238 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.342375 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.343383 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.344526 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.345621 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.346523 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.347445 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.348328 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.349387 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.350509 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.351638 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.352705 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.353628 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.354513 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.355497 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.356415 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.357432 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.358474 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.359344 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.360237 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.361178 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.363092 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.364260 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.365433 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.366435 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.367279 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.368140 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.369141 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.370128 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.371031 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.371905 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.372781 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.373691 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.374583 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.375683 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.376893 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.377843 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.378789 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.379834 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.381011 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.381977 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.383178 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.384283 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.385344 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.386296 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.387519 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.388821 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.389804 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.390674 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.391571 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.392524 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.393499 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.394536 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.395565 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.396522 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.397742 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.398872 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.399848 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.400791 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.401731 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.402642 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.403543 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.404436 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.405334 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.406449 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.407423 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.408308 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.409475 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.410499 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.411386 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.412276 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.413190 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.415748 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.416955 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.417835 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.418744 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.419665 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.420531 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.421536 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.422473 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.423351 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.424225 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.425122 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.425965 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.427005 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.427985 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.428883 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.429775 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.430638 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.431525 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.432442 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.433346 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.434274 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.435343 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.436309 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.437446 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.438511 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.439410 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.440235 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.441155 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.442009 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.442934 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.443941 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.444868 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:15:28.445973 140581979633536 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:***** Running evaluation *****\n",
            "I0109 12:15:28.924804 140581979633536 run_classifier.py:350] ***** Running evaluation *****\n",
            "INFO:tensorflow:  Num examples = 280 (277 actual, 3 padding)\n",
            "I0109 12:15:28.925075 140581979633536 run_classifier.py:353]   Num examples = 280 (277 actual, 3 padding)\n",
            "INFO:tensorflow:  Batch size = 8\n",
            "I0109 12:15:28.925209 140581979633536 run_classifier.py:354]   Batch size = 8\n",
            "INFO:tensorflow:Best trial info: Step: -1, Best Value Step: -1, Best Value: -1\n",
            "I0109 12:15:29.192020 140581979633536 run_classifier.py:391] Best trial info: Step: -1, Best Value Step: -1, Best Value: -1\n",
            "INFO:tensorflow:Add gs://luanps/albert-tfhub/models/RTE/09be5328/model.ckpt-0 to eval list.\n",
            "I0109 12:15:29.324913 140581979633536 run_classifier.py:433] Add gs://luanps/albert-tfhub/models/RTE/09be5328/model.ckpt-0 to eval list.\n",
            "INFO:tensorflow:Add gs://luanps/albert-tfhub/models/RTE/09be5328/model.ckpt-50 to eval list.\n",
            "I0109 12:15:29.325195 140581979633536 run_classifier.py:433] Add gs://luanps/albert-tfhub/models/RTE/09be5328/model.ckpt-50 to eval list.\n",
            "INFO:tensorflow:found 2 files.\n",
            "I0109 12:15:29.325297 140581979633536 run_classifier.py:435] found 2 files.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0109 12:15:29.332452 140581979633536 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fdb57782290> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "W0109 12:15:29.354035 140581979633536 ag_logging.py:146] Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fdb57782290> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "INFO:tensorflow:*** Features ***\n",
            "I0109 12:15:29.437320 140581979633536 classifier_utils.py:824] *** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (1, 512)\n",
            "I0109 12:15:29.437629 140581979633536 classifier_utils.py:826]   name = input_ids, shape = (1, 512)\n",
            "INFO:tensorflow:  name = input_mask, shape = (1, 512)\n",
            "I0109 12:15:29.437755 140581979633536 classifier_utils.py:826]   name = input_mask, shape = (1, 512)\n",
            "INFO:tensorflow:  name = is_real_example, shape = (1,)\n",
            "I0109 12:15:29.437859 140581979633536 classifier_utils.py:826]   name = is_real_example, shape = (1,)\n",
            "INFO:tensorflow:  name = label_ids, shape = (1,)\n",
            "I0109 12:15:29.437978 140581979633536 classifier_utils.py:826]   name = label_ids, shape = (1,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (1, 512)\n",
            "I0109 12:15:29.438073 140581979633536 classifier_utils.py:826]   name = segment_ids, shape = (1, 512)\n",
            "INFO:tensorflow:creating model from hub_module: https://tfhub.dev/google/albert_base/3\n",
            "I0109 12:15:29.439028 140581979633536 fine_tuning_utils.py:65] creating model from hub_module: https://tfhub.dev/google/albert_base/3\n",
            "E0109 12:15:33.424093 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/input_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:33.424742 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/input_mask) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:33.425118 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/segment_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:33.425454 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/mlm_positions) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:33.428852 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/word_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:33.434940 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/token_type_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:33.440980 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/position_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:33.443903 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:33.445841 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:33.453858 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/embedding_hidden_mapping_in/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:33.455073 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/embedding_hidden_mapping_in/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:33.465965 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:33.467837 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:33.477361 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:33.479567 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:33.489401 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:33.491200 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:33.509554 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:33.511399 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:33.517377 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:33.518635 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:33.524927 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:33.526505 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:33.536843 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:33.538247 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:33.543721 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:33.544962 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:34.650443 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:34.651684 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:34.658784 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:34.659975 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:34.663918 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:34.665077 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:15:34.669227 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/output_bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "I0109 12:15:34.770240 140581979633536 saver.py:1503] Saver not created because there are no variables in the graph to restore\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "I0109 12:15:34.927480 140581979633536 classifier_utils.py:861] **** Trainable Variables ****\n",
            "INFO:tensorflow:  name = module/bert/embeddings/word_embeddings:0, shape = (30000, 128)\n",
            "I0109 12:15:34.927774 140581979633536 classifier_utils.py:867]   name = module/bert/embeddings/word_embeddings:0, shape = (30000, 128)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/token_type_embeddings:0, shape = (2, 128)\n",
            "I0109 12:15:34.927897 140581979633536 classifier_utils.py:867]   name = module/bert/embeddings/token_type_embeddings:0, shape = (2, 128)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/position_embeddings:0, shape = (512, 128)\n",
            "I0109 12:15:34.927978 140581979633536 classifier_utils.py:867]   name = module/bert/embeddings/position_embeddings:0, shape = (512, 128)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/LayerNorm/beta:0, shape = (128,)\n",
            "I0109 12:15:34.928051 140581979633536 classifier_utils.py:867]   name = module/bert/embeddings/LayerNorm/beta:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/LayerNorm/gamma:0, shape = (128,)\n",
            "I0109 12:15:34.928119 140581979633536 classifier_utils.py:867]   name = module/bert/embeddings/LayerNorm/gamma:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/embedding_hidden_mapping_in/kernel:0, shape = (128, 768)\n",
            "I0109 12:15:34.928184 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/embedding_hidden_mapping_in/kernel:0, shape = (128, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/embedding_hidden_mapping_in/bias:0, shape = (768,)\n",
            "I0109 12:15:34.928253 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/embedding_hidden_mapping_in/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel:0, shape = (768, 768)\n",
            "I0109 12:15:34.928318 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias:0, shape = (768,)\n",
            "I0109 12:15:34.928392 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel:0, shape = (768, 768)\n",
            "I0109 12:15:34.928457 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias:0, shape = (768,)\n",
            "I0109 12:15:34.928524 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel:0, shape = (768, 768)\n",
            "I0109 12:15:34.928587 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias:0, shape = (768,)\n",
            "I0109 12:15:34.928669 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel:0, shape = (768, 768)\n",
            "I0109 12:15:34.928733 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias:0, shape = (768,)\n",
            "I0109 12:15:34.928815 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta:0, shape = (768,)\n",
            "I0109 12:15:34.928880 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma:0, shape = (768,)\n",
            "I0109 12:15:34.928943 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0109 12:15:34.929006 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0109 12:15:34.929073 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0109 12:15:34.929135 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias:0, shape = (768,)\n",
            "I0109 12:15:34.929201 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta:0, shape = (768,)\n",
            "I0109 12:15:34.929263 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma:0, shape = (768,)\n",
            "I0109 12:15:34.929325 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "I0109 12:15:34.929393 140581979633536 classifier_utils.py:867]   name = module/bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/pooler/dense/bias:0, shape = (768,)\n",
            "I0109 12:15:34.929461 140581979633536 classifier_utils.py:867]   name = module/bert/pooler/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/dense/kernel:0, shape = (768, 128)\n",
            "I0109 12:15:34.929523 140581979633536 classifier_utils.py:867]   name = module/cls/predictions/transform/dense/kernel:0, shape = (768, 128)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/dense/bias:0, shape = (128,)\n",
            "I0109 12:15:34.929588 140581979633536 classifier_utils.py:867]   name = module/cls/predictions/transform/dense/bias:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/LayerNorm/beta:0, shape = (128,)\n",
            "I0109 12:15:34.929663 140581979633536 classifier_utils.py:867]   name = module/cls/predictions/transform/LayerNorm/beta:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/LayerNorm/gamma:0, shape = (128,)\n",
            "I0109 12:15:34.929725 140581979633536 classifier_utils.py:867]   name = module/cls/predictions/transform/LayerNorm/gamma:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/output_bias:0, shape = (30000,)\n",
            "I0109 12:15:34.929793 140581979633536 classifier_utils.py:867]   name = module/cls/predictions/output_bias:0, shape = (30000,)\n",
            "INFO:tensorflow:  name = output_weights:0, shape = (2, 768)\n",
            "I0109 12:15:34.929857 140581979633536 classifier_utils.py:867]   name = output_weights:0, shape = (2, 768)\n",
            "INFO:tensorflow:  name = output_bias:0, shape = (2,)\n",
            "I0109 12:15:34.929926 140581979633536 classifier_utils.py:867]   name = output_bias:0, shape = (2,)\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:3322: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0109 12:15:34.941902 140581979633536 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:3322: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0109 12:15:36.042314 140581979633536 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2022-01-09T12:15:36Z\n",
            "I0109 12:15:36.059612 140581979633536 evaluation.py:255] Starting evaluation at 2022-01-09T12:15:36Z\n",
            "INFO:tensorflow:TPU job name worker\n",
            "I0109 12:15:36.059915 140581979633536 tpu_estimator.py:506] TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0109 12:15:36.182427 140581979633536 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://luanps/albert-tfhub/models/RTE/09be5328/model.ckpt-0\n",
            "I0109 12:15:36.317399 140581979633536 saver.py:1284] Restoring parameters from gs://luanps/albert-tfhub/models/RTE/09be5328/model.ckpt-0\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0109 12:15:43.219710 140581979633536 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0109 12:15:43.501244 140581979633536 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Init TPU system\n",
            "I0109 12:15:44.066486 140581979633536 tpu_estimator.py:567] Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 23 seconds\n",
            "I0109 12:16:07.801438 140581979633536 tpu_estimator.py:576] Initialized TPU in 23 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "I0109 12:16:07.802356 140579828393728 tpu_estimator.py:521] Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "I0109 12:16:07.802757 140579820001024 tpu_estimator.py:540] Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "I0109 12:16:08.106954 140581979633536 util.py:98] Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Enqueue next (35) batch(es) of data to infeed.\n",
            "I0109 12:16:08.366097 140581979633536 tpu_estimator.py:600] Enqueue next (35) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (35) batch(es) of data from outfeed.\n",
            "I0109 12:16:08.366452 140581979633536 tpu_estimator.py:604] Dequeue next (35) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "I0109 12:16:13.434247 140579820001024 tpu_estimator.py:279] Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:Evaluation [35/35]\n",
            "I0109 12:16:14.023802 140581979633536 evaluation.py:167] Evaluation [35/35]\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "I0109 12:16:14.024138 140581979633536 tpu_estimator.py:608] Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "I0109 12:16:14.024219 140581979633536 tpu_estimator.py:434] Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "I0109 12:16:14.024346 140579828393728 tpu_estimator.py:429] InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "I0109 12:16:14.024411 140579828393728 tpu_estimator.py:537] Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "I0109 12:16:14.024635 140581979633536 error_handling.py:101] infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "I0109 12:16:14.024732 140581979633536 tpu_estimator.py:612] Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "I0109 12:16:14.024793 140581979633536 tpu_estimator.py:434] Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "I0109 12:16:14.024882 140579820001024 tpu_estimator.py:429] OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "I0109 12:16:14.024939 140579820001024 tpu_estimator.py:551] Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "I0109 12:16:14.025022 140581979633536 error_handling.py:101] outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "I0109 12:16:14.025079 140581979633536 tpu_estimator.py:616] Shutdown TPU system.\n",
            "INFO:tensorflow:Finished evaluation at 2022-01-09-12:16:14\n",
            "I0109 12:16:14.743133 140581979633536 evaluation.py:275] Finished evaluation at 2022-01-09-12:16:14\n",
            "INFO:tensorflow:Saving dict for global step 0: eval_accuracy = 0.4368231, eval_loss = 0.7561272, global_step = 0, loss = 0.76525134\n",
            "I0109 12:16:14.743518 140581979633536 estimator.py:2049] Saving dict for global step 0: eval_accuracy = 0.4368231, eval_loss = 0.7561272, global_step = 0, loss = 0.76525134\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 0: gs://luanps/albert-tfhub/models/RTE/09be5328/model.ckpt-0\n",
            "I0109 12:16:19.595704 140581979633536 estimator.py:2109] Saving 'checkpoint_path' summary for global step 0: gs://luanps/albert-tfhub/models/RTE/09be5328/model.ckpt-0\n",
            "INFO:tensorflow:evaluation_loop marked as finished\n",
            "I0109 12:16:20.388538 140581979633536 error_handling.py:101] evaluation_loop marked as finished\n",
            "INFO:tensorflow:***** Eval results *****\n",
            "I0109 12:16:20.388928 140581979633536 run_classifier.py:453] ***** Eval results *****\n",
            "INFO:tensorflow:  eval_accuracy = 0.4368231\n",
            "I0109 12:16:20.389049 140581979633536 run_classifier.py:455]   eval_accuracy = 0.4368231\n",
            "INFO:tensorflow:  eval_loss = 0.7561272\n",
            "I0109 12:16:20.389368 140581979633536 run_classifier.py:455]   eval_loss = 0.7561272\n",
            "INFO:tensorflow:  global_step = 0\n",
            "I0109 12:16:20.389523 140581979633536 run_classifier.py:455]   global_step = 0\n",
            "INFO:tensorflow:  loss = 0.76525134\n",
            "I0109 12:16:20.389655 140581979633536 run_classifier.py:455]   loss = 0.76525134\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0109 12:16:21.356091 140581979633536 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fdb4e15d8c0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "W0109 12:16:21.375486 140581979633536 ag_logging.py:146] Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7fdb4e15d8c0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "INFO:tensorflow:*** Features ***\n",
            "I0109 12:16:21.459988 140581979633536 classifier_utils.py:824] *** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (1, 512)\n",
            "I0109 12:16:21.460309 140581979633536 classifier_utils.py:826]   name = input_ids, shape = (1, 512)\n",
            "INFO:tensorflow:  name = input_mask, shape = (1, 512)\n",
            "I0109 12:16:21.460436 140581979633536 classifier_utils.py:826]   name = input_mask, shape = (1, 512)\n",
            "INFO:tensorflow:  name = is_real_example, shape = (1,)\n",
            "I0109 12:16:21.460550 140581979633536 classifier_utils.py:826]   name = is_real_example, shape = (1,)\n",
            "INFO:tensorflow:  name = label_ids, shape = (1,)\n",
            "I0109 12:16:21.460679 140581979633536 classifier_utils.py:826]   name = label_ids, shape = (1,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (1, 512)\n",
            "I0109 12:16:21.460789 140581979633536 classifier_utils.py:826]   name = segment_ids, shape = (1, 512)\n",
            "INFO:tensorflow:creating model from hub_module: https://tfhub.dev/google/albert_base/3\n",
            "I0109 12:16:21.461830 140581979633536 fine_tuning_utils.py:65] creating model from hub_module: https://tfhub.dev/google/albert_base/3\n",
            "E0109 12:16:25.857716 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/input_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:25.858362 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/input_mask) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:25.858719 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/segment_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:25.859017 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/mlm_positions) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:25.862324 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/word_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:25.868502 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/token_type_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:25.874348 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/position_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:25.877172 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:25.878325 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:25.886451 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/embedding_hidden_mapping_in/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:25.887575 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/embedding_hidden_mapping_in/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:25.897919 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:25.899627 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:25.908444 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:25.910132 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:25.919510 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:25.921272 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:25.940473 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:25.942320 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:25.948447 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:25.949698 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:25.956169 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:25.957780 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:25.968068 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:25.969305 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:25.974485 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:25.975703 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:26.840763 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:26.842028 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:26.849262 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:26.850464 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:26.854530 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:26.855701 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:16:26.860028 140581979633536 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/output_bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "I0109 12:16:26.950105 140581979633536 saver.py:1503] Saver not created because there are no variables in the graph to restore\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "I0109 12:16:27.093461 140581979633536 classifier_utils.py:861] **** Trainable Variables ****\n",
            "INFO:tensorflow:  name = module/bert/embeddings/word_embeddings:0, shape = (30000, 128)\n",
            "I0109 12:16:27.093754 140581979633536 classifier_utils.py:867]   name = module/bert/embeddings/word_embeddings:0, shape = (30000, 128)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/token_type_embeddings:0, shape = (2, 128)\n",
            "I0109 12:16:27.093921 140581979633536 classifier_utils.py:867]   name = module/bert/embeddings/token_type_embeddings:0, shape = (2, 128)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/position_embeddings:0, shape = (512, 128)\n",
            "I0109 12:16:27.094047 140581979633536 classifier_utils.py:867]   name = module/bert/embeddings/position_embeddings:0, shape = (512, 128)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/LayerNorm/beta:0, shape = (128,)\n",
            "I0109 12:16:27.094163 140581979633536 classifier_utils.py:867]   name = module/bert/embeddings/LayerNorm/beta:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/LayerNorm/gamma:0, shape = (128,)\n",
            "I0109 12:16:27.094281 140581979633536 classifier_utils.py:867]   name = module/bert/embeddings/LayerNorm/gamma:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/embedding_hidden_mapping_in/kernel:0, shape = (128, 768)\n",
            "I0109 12:16:27.094390 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/embedding_hidden_mapping_in/kernel:0, shape = (128, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/embedding_hidden_mapping_in/bias:0, shape = (768,)\n",
            "I0109 12:16:27.094503 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/embedding_hidden_mapping_in/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel:0, shape = (768, 768)\n",
            "I0109 12:16:27.094615 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias:0, shape = (768,)\n",
            "I0109 12:16:27.094728 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel:0, shape = (768, 768)\n",
            "I0109 12:16:27.094828 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias:0, shape = (768,)\n",
            "I0109 12:16:27.094942 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel:0, shape = (768, 768)\n",
            "I0109 12:16:27.095041 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias:0, shape = (768,)\n",
            "I0109 12:16:27.095144 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel:0, shape = (768, 768)\n",
            "I0109 12:16:27.095240 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias:0, shape = (768,)\n",
            "I0109 12:16:27.095357 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta:0, shape = (768,)\n",
            "I0109 12:16:27.095457 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma:0, shape = (768,)\n",
            "I0109 12:16:27.095554 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0109 12:16:27.095662 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0109 12:16:27.095777 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0109 12:16:27.095878 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias:0, shape = (768,)\n",
            "I0109 12:16:27.095984 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta:0, shape = (768,)\n",
            "I0109 12:16:27.096082 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma:0, shape = (768,)\n",
            "I0109 12:16:27.096180 140581979633536 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "I0109 12:16:27.096280 140581979633536 classifier_utils.py:867]   name = module/bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/pooler/dense/bias:0, shape = (768,)\n",
            "I0109 12:16:27.096389 140581979633536 classifier_utils.py:867]   name = module/bert/pooler/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/dense/kernel:0, shape = (768, 128)\n",
            "I0109 12:16:27.096488 140581979633536 classifier_utils.py:867]   name = module/cls/predictions/transform/dense/kernel:0, shape = (768, 128)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/dense/bias:0, shape = (128,)\n",
            "I0109 12:16:27.096602 140581979633536 classifier_utils.py:867]   name = module/cls/predictions/transform/dense/bias:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/LayerNorm/beta:0, shape = (128,)\n",
            "I0109 12:16:27.096711 140581979633536 classifier_utils.py:867]   name = module/cls/predictions/transform/LayerNorm/beta:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/LayerNorm/gamma:0, shape = (128,)\n",
            "I0109 12:16:27.096820 140581979633536 classifier_utils.py:867]   name = module/cls/predictions/transform/LayerNorm/gamma:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/output_bias:0, shape = (30000,)\n",
            "I0109 12:16:27.096926 140581979633536 classifier_utils.py:867]   name = module/cls/predictions/output_bias:0, shape = (30000,)\n",
            "INFO:tensorflow:  name = output_weights:0, shape = (2, 768)\n",
            "I0109 12:16:27.097026 140581979633536 classifier_utils.py:867]   name = output_weights:0, shape = (2, 768)\n",
            "INFO:tensorflow:  name = output_bias:0, shape = (2,)\n",
            "I0109 12:16:27.097140 140581979633536 classifier_utils.py:867]   name = output_bias:0, shape = (2,)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0109 12:16:28.218560 140581979633536 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2022-01-09T12:16:28Z\n",
            "I0109 12:16:28.235803 140581979633536 evaluation.py:255] Starting evaluation at 2022-01-09T12:16:28Z\n",
            "INFO:tensorflow:TPU job name worker\n",
            "I0109 12:16:28.236092 140581979633536 tpu_estimator.py:506] TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0109 12:16:28.360891 140581979633536 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://luanps/albert-tfhub/models/RTE/09be5328/model.ckpt-50\n",
            "I0109 12:16:28.507260 140581979633536 saver.py:1284] Restoring parameters from gs://luanps/albert-tfhub/models/RTE/09be5328/model.ckpt-50\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0109 12:16:34.037513 140581979633536 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0109 12:16:34.325898 140581979633536 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Init TPU system\n",
            "I0109 12:16:34.912873 140581979633536 tpu_estimator.py:567] Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 20 seconds\n",
            "I0109 12:16:55.909682 140581979633536 tpu_estimator.py:576] Initialized TPU in 20 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "I0109 12:16:55.910481 140579820001024 tpu_estimator.py:521] Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "I0109 12:16:55.910734 140579811608320 tpu_estimator.py:540] Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "I0109 12:16:56.234032 140581979633536 util.py:98] Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Enqueue next (35) batch(es) of data to infeed.\n",
            "I0109 12:16:56.533838 140581979633536 tpu_estimator.py:600] Enqueue next (35) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (35) batch(es) of data from outfeed.\n",
            "I0109 12:16:56.534164 140581979633536 tpu_estimator.py:604] Dequeue next (35) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "I0109 12:17:01.649230 140579811608320 tpu_estimator.py:279] Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:Evaluation [35/35]\n",
            "I0109 12:17:02.236334 140581979633536 evaluation.py:167] Evaluation [35/35]\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "I0109 12:17:02.236680 140581979633536 tpu_estimator.py:608] Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "I0109 12:17:02.236767 140581979633536 tpu_estimator.py:434] Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "I0109 12:17:02.236896 140579820001024 tpu_estimator.py:429] InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "I0109 12:17:02.236975 140579820001024 tpu_estimator.py:537] Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "I0109 12:17:02.237204 140581979633536 error_handling.py:101] infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "I0109 12:17:02.237367 140581979633536 tpu_estimator.py:612] Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "I0109 12:17:02.237461 140581979633536 tpu_estimator.py:434] Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "I0109 12:17:02.237639 140579811608320 tpu_estimator.py:429] OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "I0109 12:17:02.237733 140579811608320 tpu_estimator.py:551] Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "I0109 12:17:02.237844 140581979633536 error_handling.py:101] outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "I0109 12:17:02.237990 140581979633536 tpu_estimator.py:616] Shutdown TPU system.\n",
            "INFO:tensorflow:Finished evaluation at 2022-01-09-12:17:02\n",
            "I0109 12:17:02.978539 140581979633536 evaluation.py:275] Finished evaluation at 2022-01-09-12:17:02\n",
            "INFO:tensorflow:Saving dict for global step 50: eval_accuracy = 0.64620936, eval_loss = 0.63770306, global_step = 50, loss = 0.61881024\n",
            "I0109 12:17:02.978997 140581979633536 estimator.py:2049] Saving dict for global step 50: eval_accuracy = 0.64620936, eval_loss = 0.63770306, global_step = 50, loss = 0.61881024\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 50: gs://luanps/albert-tfhub/models/RTE/09be5328/model.ckpt-50\n",
            "I0109 12:17:03.773294 140581979633536 estimator.py:2109] Saving 'checkpoint_path' summary for global step 50: gs://luanps/albert-tfhub/models/RTE/09be5328/model.ckpt-50\n",
            "INFO:tensorflow:evaluation_loop marked as finished\n",
            "I0109 12:17:04.468710 140581979633536 error_handling.py:101] evaluation_loop marked as finished\n",
            "INFO:tensorflow:***** Eval results *****\n",
            "I0109 12:17:04.468992 140581979633536 run_classifier.py:453] ***** Eval results *****\n",
            "INFO:tensorflow:  eval_accuracy = 0.64620936\n",
            "I0109 12:17:04.469071 140581979633536 run_classifier.py:455]   eval_accuracy = 0.64620936\n",
            "INFO:tensorflow:  eval_loss = 0.63770306\n",
            "I0109 12:17:04.469168 140581979633536 run_classifier.py:455]   eval_loss = 0.63770306\n",
            "INFO:tensorflow:  global_step = 50\n",
            "I0109 12:17:04.469244 140581979633536 run_classifier.py:455]   global_step = 50\n",
            "INFO:tensorflow:  loss = 0.61881024\n",
            "I0109 12:17:04.469319 140581979633536 run_classifier.py:455]   loss = 0.61881024\n",
            "INFO:tensorflow:saving model.ckpt-50.meta to model.ckpt-best.meta\n",
            "I0109 12:17:05.488966 140581979633536 run_classifier.py:473] saving model.ckpt-50.meta to model.ckpt-best.meta\n",
            "INFO:tensorflow:saving model.ckpt-50.data-00000-of-00001 to model.ckpt-best.data-00000-of-00001\n",
            "I0109 12:17:06.268298 140581979633536 run_classifier.py:473] saving model.ckpt-50.data-00000-of-00001 to model.ckpt-best.data-00000-of-00001\n",
            "INFO:tensorflow:saving model.ckpt-50.index to model.ckpt-best.index\n",
            "I0109 12:17:07.088886 140581979633536 run_classifier.py:473] saving model.ckpt-50.index to model.ckpt-best.index\n",
            "Copying gs://luanps/albert-tfhub/models/RTE/09be5328/eval_results.txt...\n",
            "/ [1 files][  305.0 B/  305.0 B]                                                \n",
            "Operation completed over 1 objects/305.0 B.                                      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-01-09 12:17:11,418]\u001b[0m Trial 0 finished with value: 0.64620936 and parameters: {'warmup_steps': 5, 'train_steps': 50, 'learning_rate': 1.6257088422613002e-05, 'batch_size': 128}. Best is trial 0 with value: 0.64620936.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mA saída de streaming foi truncada nas últimas 5000 linhas.\u001b[0m\n",
            "I0109 12:17:45.123569 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.124635 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.125571 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.126680 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.127771 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.128929 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.131003 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.132950 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.134506 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.135873 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.137713 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.140106 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.142075 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.143578 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.145067 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.146791 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.148358 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.149810 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.151239 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.153125 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.155200 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.156237 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.157102 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.158084 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.159010 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.160089 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.161241 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.162251 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.163201 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.164102 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.165018 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.165925 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.167070 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.168184 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.169277 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.170201 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.171093 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.172149 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.173088 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.173963 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.174868 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.175740 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.176651 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.177585 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.178624 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.179671 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.180816 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.181959 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.183012 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.183981 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.184947 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.185854 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.186738 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.187581 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.188451 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.189349 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.190243 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.191245 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.192229 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.193134 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.194053 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.195072 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.196227 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.197237 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.198157 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.199066 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.199949 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.200923 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.201803 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.202830 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.203834 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.204733 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.205881 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.206928 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.207798 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.208664 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.209564 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.210574 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.211655 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.212734 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.213710 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.214710 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.215678 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.216550 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.217430 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.218327 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.219249 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.220326 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.221297 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.222185 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.223115 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.223966 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.224897 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.225839 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.226726 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.227866 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.228902 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.229826 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.230700 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.231563 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.233071 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.234875 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.236171 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.237787 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.239153 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.240389 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.242047 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.243732 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.244638 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.245620 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.246464 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.247482 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.248400 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.249392 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.250322 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.251365 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.252431 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.253531 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.254565 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.255740 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.256761 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.257860 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.258939 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.259963 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.260846 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.261701 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.262531 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.263423 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.264308 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.265168 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.266275 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.267272 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.268224 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.269327 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.270279 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.271132 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.272115 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.273020 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.273861 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.274718 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.276207 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.278183 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.279466 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.280449 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.281587 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.282641 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.283612 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.284667 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.285840 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.287009 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.287955 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.288971 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.289950 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.290987 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.292128 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.293147 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.294159 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.295013 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.295931 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.296791 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.297614 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.298504 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.299412 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.300360 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.301342 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.302214 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.303068 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.303956 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.304906 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.305792 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.306661 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.307502 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.308389 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.309578 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.310484 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.311382 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.312544 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.313582 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.314728 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.315747 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.316613 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.317499 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.318415 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.319469 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.320395 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.321290 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.322136 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.323002 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.324101 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.325120 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.325961 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.326821 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.327832 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.328841 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.329702 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.330540 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.331394 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.332279 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.333424 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.335881 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.337520 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.338883 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.342997 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.344952 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.346455 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.348199 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.349585 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.351284 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.352977 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.354684 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.356363 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.357739 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.359166 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.360123 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.361082 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.362044 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.363176 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.364150 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.365435 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.366609 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.367616 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.368718 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.369712 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.370601 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.371608 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.372843 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.374191 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.375269 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.376355 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.377356 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.378255 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.379292 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.380443 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.381568 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.382897 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.383994 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.384897 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.386016 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.387018 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.387847 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.388689 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.389726 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.390978 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.391970 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.392888 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.393810 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.394698 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.395614 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.396519 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.397403 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.398454 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.399432 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.400311 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.401401 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.402456 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.403291 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.404109 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.405013 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.405920 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.407018 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.408189 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.409118 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.410040 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.411063 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.411990 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.412880 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.413932 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.414849 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.415737 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.416647 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.417579 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.418511 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.419736 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.420805 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.421730 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.422739 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.423820 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.425244 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.426365 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.427320 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.428318 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.429247 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.430105 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.431090 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.432120 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.433081 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.433987 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.435863 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.437086 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.438207 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.439157 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.440235 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.441343 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.442730 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.444275 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.445457 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.446572 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.447497 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.448446 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.449498 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.450493 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.451440 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.452536 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.453493 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.454773 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.455992 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.457087 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.458343 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.459358 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.460566 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.461634 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.462798 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.464057 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.465089 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.466006 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.467105 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.468409 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.469418 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.470268 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.471188 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.472130 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.473219 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.474157 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.475260 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.476274 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.477126 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.478140 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.479192 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.480452 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.481903 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.483109 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.484094 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.485170 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.486331 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.488126 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.489757 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.491221 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.492638 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.494276 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.496168 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.497748 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.499277 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.500944 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.502476 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.503887 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.505204 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.506334 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.507391 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.508443 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.509421 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.510523 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.511516 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.512461 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.513403 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.514370 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.515348 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.516272 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.517188 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.518133 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.519014 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.519931 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.520947 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.521924 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.522863 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.523763 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.524684 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.525553 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.526478 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.527318 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.528224 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.529107 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.530256 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.531327 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.532319 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.533374 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.534330 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.535532 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.537406 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.539107 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.543806 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.545540 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.547150 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.548933 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.550417 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.552206 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.553949 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.555513 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.556900 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.558572 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.560117 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.561604 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.563099 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.564536 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.566151 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.567728 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.569754 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.570740 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.571659 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.572704 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.573726 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.574686 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.575569 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.576476 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.577367 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.578315 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.579174 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.580238 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.581217 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.582150 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.583126 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.584174 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.585189 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.586354 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.587322 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.588255 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.589302 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.590272 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.591156 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.592142 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.593086 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.593937 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.594804 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.595876 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.596892 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.597831 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.598788 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.599867 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.601058 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.602097 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.603018 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.603861 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.604788 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.605916 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.606951 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.607838 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.608700 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.609611 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.610696 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.611989 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.613273 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.614283 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.615162 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.616035 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.616916 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.617798 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.618698 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.619571 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.620546 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.621823 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.622896 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.623789 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.624792 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.625745 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.626665 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.627622 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.628844 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.629950 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.630916 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.631919 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.632808 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.633845 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.634880 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.635954 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.636932 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.637990 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.639093 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.640422 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.641323 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.642156 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.643285 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.644456 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.645501 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.646513 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.647469 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.648480 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.649417 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.650486 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.651795 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.652868 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.653830 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.654718 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.656007 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.657123 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.658011 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.658849 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.659699 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.660822 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.661799 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.662930 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.663945 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.664895 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.665863 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.666727 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.667833 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.668827 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.669946 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.671174 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.672189 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.673264 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.674414 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.675362 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.676288 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.677368 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.678411 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.679358 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.680317 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.681435 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.682444 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.683337 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.684306 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.685286 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.686202 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.687052 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.687892 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.688800 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.689898 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.690937 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.691905 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.692852 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.693738 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.694579 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.695494 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.696427 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.697524 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.698571 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.699510 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.700571 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.701558 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.702578 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.703485 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.704318 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.705191 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.706127 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.707065 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.708029 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.709135 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.710335 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.711346 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.712223 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.713129 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.714210 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.715184 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.716105 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.716979 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.717920 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.719071 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.720103 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.720968 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.721862 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.722888 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.724137 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.725154 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.726219 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.727166 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.728049 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.728972 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.729880 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.730855 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.731981 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.733119 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.734119 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.734980 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.735849 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.736723 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.737812 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.738705 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.739692 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.741096 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.742485 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.744305 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.746056 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.747453 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.748929 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.750744 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.752747 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.754647 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.756147 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.757340 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.758831 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.760288 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.761722 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.763279 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.765025 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.766702 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.768217 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.769678 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.771430 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.772490 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.773351 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.774344 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.775942 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.777663 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.778686 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.781276 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.782989 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.784257 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.785772 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.786906 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.787831 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.788741 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.789669 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.790583 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.791458 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.792326 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.793361 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.794352 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.795233 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.796076 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.797174 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.798341 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.799301 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.800218 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.801184 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.802188 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.803106 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.804144 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.805235 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.806222 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.807135 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.808055 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.809000 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.809982 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.810897 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.811749 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.812650 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.813532 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.814379 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.815267 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.816214 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.817163 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.818110 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.819355 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.820432 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.821304 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.822537 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.823810 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.824962 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.826231 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.827355 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.828483 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.829421 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.830474 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.831558 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.832478 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.833395 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.834290 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.835386 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.836569 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.837608 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.838578 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.839690 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.840762 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.841681 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.842576 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.843471 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.844325 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.845299 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.846239 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.847154 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.848104 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.848994 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.849881 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.851792 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.853244 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.854200 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.855144 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.856109 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.856995 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.858063 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.859016 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.859937 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.860884 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.861876 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.862854 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.863798 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.865112 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.866397 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.867680 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.868957 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.869997 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.871110 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.872097 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.873015 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.873935 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.874881 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.875814 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.876714 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.877579 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.878502 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.879478 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.880480 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.881522 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.882606 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.883545 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.884455 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.885339 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.886172 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.887021 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.887921 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.888832 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.889715 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.890587 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.891507 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.892451 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.893370 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.894276 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.895327 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.896432 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.897666 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.898965 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.900003 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.900929 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.901826 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.902689 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.903537 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.904393 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.905276 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.906169 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.907241 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.908340 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.909306 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.910210 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.911160 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.912154 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.913302 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.914345 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.915545 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.916587 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.917663 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.918631 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.919533 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.920390 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.921230 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.922221 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.923322 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.924300 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.925294 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.926475 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.927482 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.928342 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.929236 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.930095 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.931082 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.932043 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.933043 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.934308 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.935414 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.936376 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.937466 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.938509 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.939407 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.940729 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.942010 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.943506 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.944930 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.946570 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.948131 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.949544 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.951042 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.952798 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.954437 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.956083 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.957632 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.959113 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.960572 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.961914 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.963253 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.964747 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.966576 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.968290 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.969833 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.971563 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.973173 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.975357 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.976912 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.978456 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.979443 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.980396 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.981383 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.982372 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.983381 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.984323 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.985308 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.986655 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.987731 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.988705 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.989637 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.990530 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.991479 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.992423 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.993404 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.994347 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.995246 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.996305 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.997218 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.998345 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:45.999409 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.000391 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.001321 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.002277 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.003212 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.004112 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.005034 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.005918 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.006854 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.007811 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.008673 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.009604 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.010524 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.011630 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.012624 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.013536 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.014463 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.015305 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.016266 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.017413 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.018602 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.019606 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.020560 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.021534 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.022465 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.023383 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.024369 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.025283 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.026184 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.027168 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.028285 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.029263 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.030118 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.031156 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.032307 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.033273 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.034177 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.035068 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.035907 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.036795 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.037713 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.038617 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.039547 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.040459 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.041470 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.042434 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.043349 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.044477 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.045602 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.046648 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.047747 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.049813 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.051360 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.052675 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.054326 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.055988 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.057745 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.058891 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.059823 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.060696 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.061886 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.063094 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.064114 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.065064 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.066027 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.066926 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.068064 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.069081 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.070010 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.070884 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.071947 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.072912 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.073877 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.074859 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.075759 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.076676 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.077820 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.078920 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.079858 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.081013 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.082064 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.082948 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.083894 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.085019 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.086174 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.087229 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.088161 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.089125 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.090097 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.091009 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.091927 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.093111 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.094215 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.095147 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.096280 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.097349 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.098427 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.099527 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.100633 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.101647 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.102576 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.103482 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.104509 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.105405 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.106348 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.107259 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.108242 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.109389 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.110399 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.111334 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.112260 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.113164 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.114148 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.115153 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.116113 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.117039 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.118008 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.118901 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.119878 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.120835 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.121747 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.122902 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.123965 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.124887 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.125799 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.126757 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.127685 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.128729 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.129718 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.130665 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.131551 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.132815 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.133942 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.134950 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.135849 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.136780 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.137753 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.138759 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.139797 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.140951 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.142151 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.143180 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.144110 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.145030 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.146278 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.147583 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.148657 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.149623 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.150569 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.151492 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.152491 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.153485 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.154661 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.156002 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.157373 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.158799 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.160277 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.162470 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.164612 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.166413 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.168401 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.170242 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.171795 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.173131 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.174538 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.175971 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.177407 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.178905 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.180986 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.182829 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.184884 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.187052 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.188205 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.189175 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.190289 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.191341 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.192266 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.193173 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.194427 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.195578 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.196505 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.197360 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.198286 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.199203 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.200145 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.201107 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.202021 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.202913 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.203865 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.204766 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.205684 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.206799 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.207845 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.208758 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.209633 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.210505 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.211438 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.212374 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.213286 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.214207 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.215245 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.216168 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.217080 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.217980 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.219056 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.220211 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.221155 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.222104 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.223151 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.224397 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.225404 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.226420 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.227454 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.228345 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.229261 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.230281 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.231544 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.232547 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.233417 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.234333 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.235363 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.236337 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.237425 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.238531 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.239505 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.240364 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.241765 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.242868 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.243869 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.244770 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.245666 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.246579 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.247499 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.248376 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.249243 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.250165 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.251084 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.251965 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.253005 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.253993 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.255212 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.256495 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.257739 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.258832 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.259813 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.261139 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.262151 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.263134 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.264100 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.265088 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.266029 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.266955 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.268042 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.269002 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.269887 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.270757 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.271641 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.272547 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.273524 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.274461 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.275343 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.276224 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.277149 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.278134 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.279078 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.279935 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.280799 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.281745 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.282631 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.283537 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.284447 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.285356 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.286860 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.288673 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.290578 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.292146 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.293666 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.295039 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.296468 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.297990 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.299167 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.300230 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.301110 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.302152 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.303169 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.304101 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.305181 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.306176 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.307143 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.308088 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.309100 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.310022 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.310948 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.312169 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.313260 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.314221 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.315298 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.316332 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.317264 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.318350 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.319339 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.320516 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.321505 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.322556 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.323469 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.324414 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.325439 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.326369 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.327341 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.328469 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.329632 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.330781 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.331810 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.332700 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.333674 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.334681 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.335555 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.336410 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.337343 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.338339 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.339588 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.340685 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.341624 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.342520 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.343430 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.344324 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.345223 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.346147 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.347079 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.348150 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.349063 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.350004 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.350984 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.351899 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.352817 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.353707 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.354950 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.355964 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.357222 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.358557 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.359992 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.361415 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.362758 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.364638 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.366120 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.367670 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.369337 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.370888 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.372529 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.374359 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.375952 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.377388 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.379013 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.380537 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.381947 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.383366 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.385007 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.385948 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.386941 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.388055 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.389036 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.389954 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.390899 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.391872 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.392773 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.393655 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.394494 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.395573 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.396564 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.397490 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.398422 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.399276 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.400439 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.401480 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.402573 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.403570 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.404586 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.405926 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.407018 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.408172 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.409195 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.410114 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.411011 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.411902 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.412889 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.413743 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.414565 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.415427 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.416409 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.417403 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.418338 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.419357 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.420429 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.421400 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.422400 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.423357 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.424289 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.425204 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.426129 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.427050 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.428032 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.429001 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.429844 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.430722 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.431636 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.432649 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.433585 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.434515 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.435634 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.436755 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.437692 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.438617 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.439496 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.440403 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.441329 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.442268 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.443289 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.444209 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.445544 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.446766 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.447730 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.449039 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.450105 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.451282 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.452237 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.453275 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.454313 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.455301 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.456187 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.457103 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.458184 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.459189 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.460374 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.461327 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.462257 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.463614 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.465286 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.466248 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.467196 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.468201 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.469156 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.470193 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.471459 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.472533 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.473473 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.474377 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.475345 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.476502 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.477524 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.478412 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.479347 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.480345 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.481456 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.482789 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.483843 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.484685 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.485539 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.486405 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.487552 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.488440 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.489349 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.490260 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.491120 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.492212 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.493251 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.494352 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.495348 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.496257 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.497146 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.498051 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.498997 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.499943 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.500834 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.501822 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.502759 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.503680 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.504726 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.506093 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.507836 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.509384 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.510797 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.512476 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.514235 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.515765 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.517250 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.518712 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.520230 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.521691 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.523075 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.524519 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.525929 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.527060 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.528096 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.529047 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.530040 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.531116 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.532051 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.532878 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.533765 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.534681 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.535582 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.536490 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.537433 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.538402 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.539288 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.540182 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.541054 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.542138 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.544368 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.546038 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.547577 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.548677 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.549799 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.551032 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.552428 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.553680 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.554681 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.555620 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.556468 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.557579 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.558979 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.560036 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.561107 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.562286 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.563652 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.565308 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.566872 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.568391 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.570352 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.572095 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.573726 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.575214 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.576680 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.578135 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.579886 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.581564 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.583193 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.584679 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.586084 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.587522 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.590184 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.592243 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.594067 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.595716 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.597067 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.598824 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.600023 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.601286 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.602660 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.603771 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.604965 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.606027 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.607007 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.607954 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.608855 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.609876 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.610953 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.611929 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.612873 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.613791 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.615132 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.616265 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.617181 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.618176 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.619111 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.620187 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.621273 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.622228 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.623154 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.624288 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.625270 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.626352 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.627323 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.628277 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.629222 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.630355 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.631612 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.632757 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.633735 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.634605 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.635529 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.636468 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.637347 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.638250 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.639184 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.640068 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.640907 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.642043 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.643087 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.644084 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.645034 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.646002 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.646958 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.647876 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.648769 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.649795 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.650733 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.651804 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.652856 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.654068 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.655171 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.656039 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.656957 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.657870 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.658951 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.659954 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.660864 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.661856 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.662826 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.663962 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.665032 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.665899 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.667117 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.668051 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.668939 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.669813 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.670701 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.671587 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.672490 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.673696 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.674742 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.675674 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.676568 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.677661 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.678654 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.679526 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.680476 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.681471 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.682377 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.683295 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.684221 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.685135 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.686039 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.687114 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.688153 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.689083 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.690017 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.690924 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.691784 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.692700 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.693834 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.694873 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.696053 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.697001 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.697927 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.698823 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.699979 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.701056 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.702050 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.702973 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.703821 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.704987 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.706073 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.707020 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.707984 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.709274 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.710572 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.711733 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.712713 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.713612 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.714708 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.715764 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.716895 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.717938 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.718847 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.719759 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.720679 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.721612 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.722589 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.723575 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.724496 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.725405 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.726421 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.727330 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.728211 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.729070 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.729978 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.730830 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.731775 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.732707 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.733635 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.734680 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.735653 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.736702 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.737654 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.738530 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.739560 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.740479 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.741420 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.742406 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.743370 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.744332 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.745414 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.746536 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.747728 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.748668 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.749779 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.751379 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.752436 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.753550 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.754655 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.755934 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.757022 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.758322 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.759540 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.760768 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.761762 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.762819 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.763874 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.764946 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.765961 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.767076 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.768494 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.770292 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.771799 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.773436 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.774798 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.776167 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.777917 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.779937 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.781548 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.783452 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.784814 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.786109 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.787528 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.788912 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.790310 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.791765 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.793208 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.794713 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.796208 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.797631 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.799125 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.800992 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.802892 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.804290 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.805410 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.806505 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.807588 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.808587 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.809570 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.810504 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.811452 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.812365 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.813266 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.814149 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.815093 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.816072 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.817013 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.817912 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.818810 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.819678 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.820557 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.821485 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.822410 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.823873 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.825185 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.826587 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.828100 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.829333 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.830368 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.831383 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.832355 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.833940 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.835778 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.837507 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.838915 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.839960 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.840914 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.841836 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.842753 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.843940 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.845144 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.846294 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.847256 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.848155 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.849063 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.850502 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.851683 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.852885 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.853873 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.854894 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.856014 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.857169 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.858188 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.859124 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.860065 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.860949 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.861867 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.862936 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.863927 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.864846 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.865921 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.867228 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.868513 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.869780 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.870860 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.871800 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.872884 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.873892 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.874818 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.875784 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.876998 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.878427 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.879688 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.880781 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.881814 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.882715 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.883556 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.884408 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.885570 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.886617 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.887556 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.888481 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.889387 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.890347 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.891317 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.892270 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.893236 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.894146 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.895307 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.896331 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.897247 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.898190 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.899067 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.899945 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.900831 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.901757 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.902755 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.903781 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.904713 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.905653 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.906583 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.907736 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.909069 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.910220 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.911308 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.912256 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.913121 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.914117 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.915038 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.916019 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.917080 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.918171 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.919369 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.920436 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.921437 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.922473 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.923415 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.924320 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.925496 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.926557 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.927512 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.928486 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.929371 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.930268 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.931170 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.932067 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.932939 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.933779 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.934671 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.935651 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.936729 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.938075 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.939619 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.940676 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.941906 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.942877 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.944138 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.945299 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.946275 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.947382 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.948405 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.949320 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.950268 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.951253 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.952226 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.953452 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.954534 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.955691 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.956802 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.957781 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.958709 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.959620 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.960743 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.961805 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.962740 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.963656 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.964630 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.965628 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.966672 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.967628 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.968496 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.969411 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.970612 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.971922 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.973299 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.975525 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.977152 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.978514 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.979964 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.981492 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.983077 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.984548 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.986295 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.987856 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.989211 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.990433 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.991773 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.993211 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.994703 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.996311 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.997832 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:46.999395 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.001214 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.002839 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.004168 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.006756 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.007846 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.008763 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.009671 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.010538 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.011572 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.012501 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.013355 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.014243 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.015131 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.016057 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.017103 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.018069 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.019101 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.020169 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.021118 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.022276 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.023449 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.024430 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.025338 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.026328 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.027372 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.028297 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.029211 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.030107 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.031021 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.031962 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.032841 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.033746 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.034621 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.036012 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.037186 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.038206 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.039322 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.040371 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.041297 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.042179 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.043075 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.044016 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.045175 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.046198 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.047085 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.048110 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.049177 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.050116 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.051046 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.051932 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.053051 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.054018 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.054915 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.055819 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.056750 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.057837 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.058837 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.059710 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.060607 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.061488 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.062801 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.064319 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.065825 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.067024 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.068153 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.069821 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.071384 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.072764 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.073749 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.074756 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.075678 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.076614 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.077777 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.078867 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.080076 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.081410 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.082376 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.083266 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.084379 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.085467 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.086392 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.087332 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.088470 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.089483 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.090453 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.091381 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.092537 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.093765 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.095084 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.096090 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.097001 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.097949 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.098811 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.099736 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.101071 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.102415 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.103541 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.104732 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.105711 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.106780 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.107771 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.108675 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.109871 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.111161 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.112332 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.113285 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.114161 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.115246 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.116188 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.117420 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.118609 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.119553 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.120571 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.121693 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.122721 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.123656 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.124730 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.125806 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.126892 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.127897 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.128914 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.129863 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.130733 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.131885 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.132938 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.134054 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:17:47.135062 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:***** Running training *****\n",
            "I0109 12:17:47.880885 139668939859840 run_classifier.py:315] ***** Running training *****\n",
            "INFO:tensorflow:  Num examples = 2490\n",
            "I0109 12:17:47.881154 139668939859840 run_classifier.py:316]   Num examples = 2490\n",
            "INFO:tensorflow:  Batch size = 112\n",
            "I0109 12:17:47.881293 139668939859840 run_classifier.py:317]   Batch size = 112\n",
            "INFO:tensorflow:  Num steps = 90\n",
            "I0109 12:17:47.881393 139668939859840 run_classifier.py:318]   Num steps = 90\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.109.125.66:8470) for TPU system metadata.\n",
            "I0109 12:17:48.135537 139668939859840 tpu_system_metadata.py:78] Querying Tensorflow master (grpc://10.109.125.66:8470) for TPU system metadata.\n",
            "2022-01-09 12:17:48.136866: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:370] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "I0109 12:17:48.148663 139668939859840 tpu_system_metadata.py:148] Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "I0109 12:17:48.148891 139668939859840 tpu_system_metadata.py:149] *** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "I0109 12:17:48.148971 139668939859840 tpu_system_metadata.py:150] *** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "I0109 12:17:48.149029 139668939859840 tpu_system_metadata.py:152] *** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2409099261969407911)\n",
            "I0109 12:17:48.149085 139668939859840 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2409099261969407911)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 5510839357321454835)\n",
            "I0109 12:17:48.149317 139668939859840 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 5510839357321454835)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 873393571816079649)\n",
            "I0109 12:17:48.149376 139668939859840 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 873393571816079649)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 9117514880373904260)\n",
            "I0109 12:17:48.149431 139668939859840 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 9117514880373904260)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 12704941682957268373)\n",
            "I0109 12:17:48.149493 139668939859840 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 12704941682957268373)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 10623130967391006998)\n",
            "I0109 12:17:48.149549 139668939859840 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 10623130967391006998)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 17893873024629234993)\n",
            "I0109 12:17:48.149650 139668939859840 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 17893873024629234993)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 9214549767924212172)\n",
            "I0109 12:17:48.149718 139668939859840 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 9214549767924212172)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 6427061617775819593)\n",
            "I0109 12:17:48.149771 139668939859840 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 6427061617775819593)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 2138631231408532535)\n",
            "I0109 12:17:48.149823 139668939859840 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 2138631231408532535)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 1549954337002144741)\n",
            "I0109 12:17:48.149877 139668939859840 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 1549954337002144741)\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "W0109 12:17:48.155177 139668939859840 deprecation.py:506] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0109 12:17:48.155873 139668939859840 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0109 12:17:48.165075 139668939859840 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /content/albert/classifier_utils.py:744: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "W0109 12:17:48.184706 139668939859840 deprecation.py:323] From /content/albert/classifier_utils.py:744: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "W0109 12:17:48.184955 139668939859840 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "WARNING:tensorflow:Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f06bb290050> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "W0109 12:17:48.198969 139668939859840 ag_logging.py:146] Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f06bb290050> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:From /content/albert/classifier_utils.py:721: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0109 12:17:48.202893 139668939859840 deprecation.py:323] From /content/albert/classifier_utils.py:721: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:*** Features ***\n",
            "I0109 12:17:48.277143 139668939859840 classifier_utils.py:824] *** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (14, 512)\n",
            "I0109 12:17:48.277421 139668939859840 classifier_utils.py:826]   name = input_ids, shape = (14, 512)\n",
            "INFO:tensorflow:  name = input_mask, shape = (14, 512)\n",
            "I0109 12:17:48.277506 139668939859840 classifier_utils.py:826]   name = input_mask, shape = (14, 512)\n",
            "INFO:tensorflow:  name = is_real_example, shape = (14,)\n",
            "I0109 12:17:48.277570 139668939859840 classifier_utils.py:826]   name = is_real_example, shape = (14,)\n",
            "INFO:tensorflow:  name = label_ids, shape = (14,)\n",
            "I0109 12:17:48.277646 139668939859840 classifier_utils.py:826]   name = label_ids, shape = (14,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (14, 512)\n",
            "I0109 12:17:48.277706 139668939859840 classifier_utils.py:826]   name = segment_ids, shape = (14, 512)\n",
            "INFO:tensorflow:creating model from hub_module: https://tfhub.dev/google/albert_base/3\n",
            "I0109 12:17:48.278729 139668939859840 fine_tuning_utils.py:65] creating model from hub_module: https://tfhub.dev/google/albert_base/3\n",
            "E0109 12:17:52.432828 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/input_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:52.433484 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/input_mask) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:52.434538 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/segment_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:52.434919 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/mlm_positions) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:52.438390 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/word_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:52.444646 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/token_type_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:52.450516 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/position_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:52.453416 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:52.454608 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:52.463840 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/embedding_hidden_mapping_in/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:52.465035 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/embedding_hidden_mapping_in/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:52.475662 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:52.477368 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:52.486024 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:52.487702 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:52.496262 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:52.497992 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:52.525326 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:52.527135 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:52.533148 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:52.534280 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:52.540766 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:52.542252 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:52.552162 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:52.553353 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:52.558550 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:52.560700 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:53.264535 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:53.265753 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:53.272727 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:53.273888 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:53.277851 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:53.279080 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:17:53.283369 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/output_bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "I0109 12:17:53.383186 139668939859840 saver.py:1503] Saver not created because there are no variables in the graph to restore\n",
            "WARNING:tensorflow:From /content/albert/classifier_utils.py:794: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0109 12:17:53.506696 139668939859840 deprecation.py:506] From /content/albert/classifier_utils.py:794: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "I0109 12:17:53.544482 139668939859840 classifier_utils.py:861] **** Trainable Variables ****\n",
            "INFO:tensorflow:  name = module/bert/embeddings/word_embeddings:0, shape = (30000, 128)\n",
            "I0109 12:17:53.544752 139668939859840 classifier_utils.py:867]   name = module/bert/embeddings/word_embeddings:0, shape = (30000, 128)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/token_type_embeddings:0, shape = (2, 128)\n",
            "I0109 12:17:53.544876 139668939859840 classifier_utils.py:867]   name = module/bert/embeddings/token_type_embeddings:0, shape = (2, 128)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/position_embeddings:0, shape = (512, 128)\n",
            "I0109 12:17:53.544956 139668939859840 classifier_utils.py:867]   name = module/bert/embeddings/position_embeddings:0, shape = (512, 128)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/LayerNorm/beta:0, shape = (128,)\n",
            "I0109 12:17:53.545029 139668939859840 classifier_utils.py:867]   name = module/bert/embeddings/LayerNorm/beta:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/LayerNorm/gamma:0, shape = (128,)\n",
            "I0109 12:17:53.545097 139668939859840 classifier_utils.py:867]   name = module/bert/embeddings/LayerNorm/gamma:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/embedding_hidden_mapping_in/kernel:0, shape = (128, 768)\n",
            "I0109 12:17:53.545162 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/embedding_hidden_mapping_in/kernel:0, shape = (128, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/embedding_hidden_mapping_in/bias:0, shape = (768,)\n",
            "I0109 12:17:53.545242 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/embedding_hidden_mapping_in/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel:0, shape = (768, 768)\n",
            "I0109 12:17:53.545306 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias:0, shape = (768,)\n",
            "I0109 12:17:53.545376 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel:0, shape = (768, 768)\n",
            "I0109 12:17:53.545439 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias:0, shape = (768,)\n",
            "I0109 12:17:53.545507 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel:0, shape = (768, 768)\n",
            "I0109 12:17:53.545570 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias:0, shape = (768,)\n",
            "I0109 12:17:53.545653 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel:0, shape = (768, 768)\n",
            "I0109 12:17:53.545717 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias:0, shape = (768,)\n",
            "I0109 12:17:53.545784 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta:0, shape = (768,)\n",
            "I0109 12:17:53.545848 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma:0, shape = (768,)\n",
            "I0109 12:17:53.545910 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0109 12:17:53.545971 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0109 12:17:53.546037 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0109 12:17:53.546099 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias:0, shape = (768,)\n",
            "I0109 12:17:53.546165 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta:0, shape = (768,)\n",
            "I0109 12:17:53.546236 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma:0, shape = (768,)\n",
            "I0109 12:17:53.546298 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "I0109 12:17:53.546360 139668939859840 classifier_utils.py:867]   name = module/bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/pooler/dense/bias:0, shape = (768,)\n",
            "I0109 12:17:53.546426 139668939859840 classifier_utils.py:867]   name = module/bert/pooler/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/dense/kernel:0, shape = (768, 128)\n",
            "I0109 12:17:53.546488 139668939859840 classifier_utils.py:867]   name = module/cls/predictions/transform/dense/kernel:0, shape = (768, 128)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/dense/bias:0, shape = (128,)\n",
            "I0109 12:17:53.546554 139668939859840 classifier_utils.py:867]   name = module/cls/predictions/transform/dense/bias:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/LayerNorm/beta:0, shape = (128,)\n",
            "I0109 12:17:53.546626 139668939859840 classifier_utils.py:867]   name = module/cls/predictions/transform/LayerNorm/beta:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/LayerNorm/gamma:0, shape = (128,)\n",
            "I0109 12:17:53.546689 139668939859840 classifier_utils.py:867]   name = module/cls/predictions/transform/LayerNorm/gamma:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/output_bias:0, shape = (30000,)\n",
            "I0109 12:17:53.546750 139668939859840 classifier_utils.py:867]   name = module/cls/predictions/output_bias:0, shape = (30000,)\n",
            "INFO:tensorflow:  name = output_weights:0, shape = (2, 768)\n",
            "I0109 12:17:53.546813 139668939859840 classifier_utils.py:867]   name = output_weights:0, shape = (2, 768)\n",
            "INFO:tensorflow:  name = output_bias:0, shape = (2,)\n",
            "I0109 12:17:53.546881 139668939859840 classifier_utils.py:867]   name = output_bias:0, shape = (2,)\n",
            "INFO:tensorflow:++++++ warmup starts at step 0, for 15 steps ++++++\n",
            "I0109 12:17:53.559113 139668939859840 optimization.py:51] ++++++ warmup starts at step 0, for 15 steps ++++++\n",
            "INFO:tensorflow:using adamw\n",
            "I0109 12:17:53.571648 139668939859840 optimization.py:75] using adamw\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0109 12:17:53.805883 139668939859840 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0109 12:17:59.117503 139668939859840 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0109 12:17:59.186262 139668939859840 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "I0109 12:18:02.273559 139668939859840 tpu_estimator.py:506] TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0109 12:18:02.510972 139668939859840 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0109 12:18:10.703238 139668939859840 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0109 12:18:11.221529 139668939859840 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into gs://luanps/albert-tfhub/models/RTE/c755eca2/model.ckpt.\n",
            "I0109 12:18:19.463847 139668939859840 basic_session_run_hooks.py:606] Saving checkpoints for 0 into gs://luanps/albert-tfhub/models/RTE/c755eca2/model.ckpt.\n",
            "INFO:tensorflow:gs://luanps/albert-tfhub/models/RTE/c755eca2/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.\n",
            "I0109 12:18:28.519796 139668939859840 checkpoint_management.py:95] gs://luanps/albert-tfhub/models/RTE/c755eca2/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:751: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "W0109 12:18:32.819194 139668939859840 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:751: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "I0109 12:18:33.877228 139668939859840 util.py:98] Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "I0109 12:18:33.877776 139668939859840 session_support.py:332] Installing graceful shutdown hook.\n",
            "2022-01-09 12:18:33.878274: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:370] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "I0109 12:18:33.882682 139668939859840 session_support.py:82] Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "I0109 12:18:33.884829 139668939859840 session_support.py:105] Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Init TPU system\n",
            "I0109 12:18:33.888622 139668939859840 tpu_estimator.py:567] Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 14 seconds\n",
            "I0109 12:18:48.769945 139668939859840 tpu_estimator.py:576] Initialized TPU in 14 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "I0109 12:18:48.770781 139666808547072 tpu_estimator.py:521] Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "I0109 12:18:48.771207 139666800154368 tpu_estimator.py:540] Starting outfeed thread controller.\n",
            "INFO:tensorflow:Enqueue next (90) batch(es) of data to infeed.\n",
            "I0109 12:18:49.257965 139668939859840 tpu_estimator.py:600] Enqueue next (90) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (90) batch(es) of data from outfeed.\n",
            "I0109 12:18:49.258282 139668939859840 tpu_estimator.py:604] Dequeue next (90) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "I0109 12:19:05.828757 139666800154368 tpu_estimator.py:279] Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:loss = 0.52341986, step = 90\n",
            "I0109 12:19:45.330635 139668939859840 basic_session_run_hooks.py:262] loss = 0.52341986, step = 90\n",
            "INFO:tensorflow:Saving checkpoints for 90 into gs://luanps/albert-tfhub/models/RTE/c755eca2/model.ckpt.\n",
            "I0109 12:19:45.332616 139668939859840 basic_session_run_hooks.py:606] Saving checkpoints for 90 into gs://luanps/albert-tfhub/models/RTE/c755eca2/model.ckpt.\n",
            "INFO:tensorflow:gs://luanps/albert-tfhub/models/RTE/c755eca2/model.ckpt-90 is not in all_model_checkpoint_paths. Manually adding it.\n",
            "I0109 12:19:55.328424 139668939859840 checkpoint_management.py:95] gs://luanps/albert-tfhub/models/RTE/c755eca2/model.ckpt-90 is not in all_model_checkpoint_paths. Manually adding it.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "I0109 12:20:00.209478 139668939859840 tpu_estimator.py:608] Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "I0109 12:20:00.209790 139668939859840 tpu_estimator.py:434] Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "I0109 12:20:00.210050 139666808547072 tpu_estimator.py:429] InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "I0109 12:20:00.210155 139666808547072 tpu_estimator.py:537] Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "I0109 12:20:00.210304 139668939859840 error_handling.py:101] infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "I0109 12:20:00.210425 139668939859840 tpu_estimator.py:612] Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "I0109 12:20:00.210540 139668939859840 tpu_estimator.py:434] Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "I0109 12:20:00.210718 139666800154368 tpu_estimator.py:429] OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "I0109 12:20:00.210800 139666800154368 tpu_estimator.py:551] Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "I0109 12:20:00.210928 139668939859840 error_handling.py:101] outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "I0109 12:20:00.211041 139668939859840 tpu_estimator.py:616] Shutdown TPU system.\n",
            "INFO:tensorflow:Loss for final step: 0.52341986.\n",
            "I0109 12:20:01.009554 139668939859840 estimator.py:371] Loss for final step: 0.52341986.\n",
            "INFO:tensorflow:training_loop marked as finished\n",
            "I0109 12:20:01.010102 139668939859840 error_handling.py:101] training_loop marked as finished\n",
            "INFO:tensorflow:Writing example 0 of 280\n",
            "I0109 12:20:01.292983 139668939859840 classifier_utils.py:671] Writing example 0 of 280\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.293774 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0109 12:20:01.294324 139668939859840 classifier_utils.py:645] *** Example ***\n",
            "INFO:tensorflow:guid: 0\n",
            "I0109 12:20:01.294453 139668939859840 classifier_utils.py:646] guid: 0\n",
            "INFO:tensorflow:tokens: [CLS] ▁dana ▁reeve , ▁the ▁widow ▁of ▁the ▁actor ▁christopher ▁reeve , ▁has ▁died ▁of ▁lung ▁cancer ▁at ▁age ▁44 , ▁according ▁to ▁the ▁christopher ▁reeve ▁foundation . [SEP] ▁christopher ▁reeve ▁had ▁an ▁accident . [SEP]\n",
            "I0109 12:20:01.294610 139668939859840 classifier_utils.py:648] tokens: [CLS] ▁dana ▁reeve , ▁the ▁widow ▁of ▁the ▁actor ▁christopher ▁reeve , ▁has ▁died ▁of ▁lung ▁cancer ▁at ▁age ▁44 , ▁according ▁to ▁the ▁christopher ▁reeve ▁foundation . [SEP] ▁christopher ▁reeve ▁had ▁an ▁accident . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 11478 24604 15 14 5151 16 14 1574 4479 24604 15 63 440 16 9223 2637 35 348 4576 15 496 20 14 4479 24604 1304 9 3 4479 24604 41 40 3351 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:20:01.294933 139668939859840 classifier_utils.py:649] input_ids: 2 11478 24604 15 14 5151 16 14 1574 4479 24604 15 63 440 16 9223 2637 35 348 4576 15 496 20 14 4479 24604 1304 9 3 4479 24604 41 40 3351 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:20:01.295246 139668939859840 classifier_utils.py:650] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:20:01.295561 139668939859840 classifier_utils.py:651] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: not_entailment (id = 1)\n",
            "I0109 12:20:01.295682 139668939859840 classifier_utils.py:652] label: not_entailment (id = 1)\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.297070 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0109 12:20:01.297610 139668939859840 classifier_utils.py:645] *** Example ***\n",
            "INFO:tensorflow:guid: 1\n",
            "I0109 12:20:01.297739 139668939859840 classifier_utils.py:646] guid: 1\n",
            "INFO:tensorflow:tokens: [CLS] ▁yet , ▁we ▁now ▁are ▁discovering ▁that ▁antibiotic s ▁are ▁losing ▁their ▁effectiveness ▁against ▁illness . ▁disease - ca using ▁bacteria ▁are ▁muta ting ▁faster ▁than ▁we ▁can ▁come ▁up ▁with ▁new ▁antibiotic s ▁to ▁fight ▁the ▁new ▁variations . [SEP] ▁bacteria ▁is ▁winning ▁the ▁war ▁against ▁antibiotic s . [SEP]\n",
            "I0109 12:20:01.297870 139668939859840 classifier_utils.py:648] tokens: [CLS] ▁yet , ▁we ▁now ▁are ▁discovering ▁that ▁antibiotic s ▁are ▁losing ▁their ▁effectiveness ▁against ▁illness . ▁disease - ca using ▁bacteria ▁are ▁muta ting ▁faster ▁than ▁we ▁can ▁come ▁up ▁with ▁new ▁antibiotic s ▁to ▁fight ▁the ▁new ▁variations . [SEP] ▁bacteria ▁is ▁winning ▁the ▁war ▁against ▁antibiotic s . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 768 15 95 130 50 15799 30 20017 18 50 2281 66 14115 149 6761 9 2515 8 793 12655 10955 50 22673 1203 4233 119 95 92 340 71 29 78 20017 18 20 1074 14 78 8194 9 3 10955 25 1414 14 176 149 20017 18 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:20:01.298198 139668939859840 classifier_utils.py:649] input_ids: 2 768 15 95 130 50 15799 30 20017 18 50 2281 66 14115 149 6761 9 2515 8 793 12655 10955 50 22673 1203 4233 119 95 92 340 71 29 78 20017 18 20 1074 14 78 8194 9 3 10955 25 1414 14 176 149 20017 18 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:20:01.298528 139668939859840 classifier_utils.py:650] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:20:01.298889 139668939859840 classifier_utils.py:651] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: entailment (id = 0)\n",
            "I0109 12:20:01.299013 139668939859840 classifier_utils.py:652] label: entailment (id = 0)\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.300904 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0109 12:20:01.301755 139668939859840 classifier_utils.py:645] *** Example ***\n",
            "INFO:tensorflow:guid: 2\n",
            "I0109 12:20:01.301897 139668939859840 classifier_utils.py:646] guid: 2\n",
            "INFO:tensorflow:tokens: [CLS] ▁cairo ▁is ▁now ▁home ▁to ▁some ▁15 ▁million ▁people ▁ - ▁a ▁burgeoning ▁population ▁that ▁produces ▁approximately ▁10,000 ▁tonnes ▁of ▁rubbish ▁per ▁day , ▁putting ▁an ▁enormous ▁strain ▁on ▁public ▁services . ▁in ▁the ▁past ▁10 ▁years , ▁the ▁government ▁has ▁tried ▁hard ▁to ▁encourage ▁private ▁investment ▁in ▁the ▁refuse ▁sector , ▁but ▁some ▁estimate ▁4,000 ▁tonnes ▁of ▁waste ▁is ▁left ▁behind ▁every ▁day , ▁fest ering ▁in ▁the ▁heat ▁as ▁it ▁wait s ▁for ▁someone ▁to ▁clear ▁it ▁up . ▁it ▁is ▁often ▁the ▁people ▁in ▁the ▁poor est ▁neighbourhood s ▁that ▁are ▁worst ▁affected . ▁but ▁in ▁some ▁areas ▁they ▁are ▁fighting ▁back . ▁in ▁shu bra , ▁one ▁of ▁the ▁northern ▁districts ▁of ▁the ▁city , ▁the ▁residents ▁have ▁taken ▁to ▁the ▁streets ▁armed ▁with ▁dust pan s ▁and ▁brushes ▁to ▁clean ▁up ▁public ▁areas ▁which ▁have ▁been ▁used ▁as ▁public ▁dump s . [SEP] ▁15 ▁million ▁tonnes ▁of ▁rubbish ▁are ▁produced ▁daily ▁in ▁cairo . [SEP]\n",
            "I0109 12:20:01.302092 139668939859840 classifier_utils.py:648] tokens: [CLS] ▁cairo ▁is ▁now ▁home ▁to ▁some ▁15 ▁million ▁people ▁ - ▁a ▁burgeoning ▁population ▁that ▁produces ▁approximately ▁10,000 ▁tonnes ▁of ▁rubbish ▁per ▁day , ▁putting ▁an ▁enormous ▁strain ▁on ▁public ▁services . ▁in ▁the ▁past ▁10 ▁years , ▁the ▁government ▁has ▁tried ▁hard ▁to ▁encourage ▁private ▁investment ▁in ▁the ▁refuse ▁sector , ▁but ▁some ▁estimate ▁4,000 ▁tonnes ▁of ▁waste ▁is ▁left ▁behind ▁every ▁day , ▁fest ering ▁in ▁the ▁heat ▁as ▁it ▁wait s ▁for ▁someone ▁to ▁clear ▁it ▁up . ▁it ▁is ▁often ▁the ▁people ▁in ▁the ▁poor est ▁neighbourhood s ▁that ▁are ▁worst ▁affected . ▁but ▁in ▁some ▁areas ▁they ▁are ▁fighting ▁back . ▁in ▁shu bra , ▁one ▁of ▁the ▁northern ▁districts ▁of ▁the ▁city , ▁the ▁residents ▁have ▁taken ▁to ▁the ▁streets ▁armed ▁with ▁dust pan s ▁and ▁brushes ▁to ▁clean ▁up ▁public ▁areas ▁which ▁have ▁been ▁used ▁as ▁public ▁dump s . [SEP] ▁15 ▁million ▁tonnes ▁of ▁rubbish ▁are ▁produced ▁daily ▁in ▁cairo . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 11772 25 130 213 20 109 357 507 148 13 8 21 29936 350 30 6700 1357 6693 11485 16 28898 416 208 15 3873 40 7135 8302 27 317 687 9 19 14 640 332 122 15 14 283 63 794 552 20 8333 932 3709 19 14 10198 3172 15 47 109 10243 13845 11485 16 4600 25 225 439 352 208 15 11837 7882 19 14 1737 28 32 1760 18 26 737 20 1207 32 71 9 32 25 478 14 148 19 14 1696 1430 9876 18 30 50 4126 4114 9 47 19 109 924 59 50 1849 97 9 19 5728 2559 15 53 16 14 743 3872 16 14 136 15 14 2175 57 658 20 14 3240 2799 29 4346 3206 18 17 25079 20 2745 71 317 924 56 57 74 147 28 317 11424 18 9 3 357 507 11485 16 28898 50 671 1954 19 11772 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:20:01.389211 139668939859840 classifier_utils.py:649] input_ids: 2 11772 25 130 213 20 109 357 507 148 13 8 21 29936 350 30 6700 1357 6693 11485 16 28898 416 208 15 3873 40 7135 8302 27 317 687 9 19 14 640 332 122 15 14 283 63 794 552 20 8333 932 3709 19 14 10198 3172 15 47 109 10243 13845 11485 16 4600 25 225 439 352 208 15 11837 7882 19 14 1737 28 32 1760 18 26 737 20 1207 32 71 9 32 25 478 14 148 19 14 1696 1430 9876 18 30 50 4126 4114 9 47 19 109 924 59 50 1849 97 9 19 5728 2559 15 53 16 14 743 3872 16 14 136 15 14 2175 57 658 20 14 3240 2799 29 4346 3206 18 17 25079 20 2745 71 317 924 56 57 74 147 28 317 11424 18 9 3 357 507 11485 16 28898 50 671 1954 19 11772 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:20:01.391065 139668939859840 classifier_utils.py:650] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:20:01.391940 139668939859840 classifier_utils.py:651] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: not_entailment (id = 1)\n",
            "I0109 12:20:01.392336 139668939859840 classifier_utils.py:652] label: not_entailment (id = 1)\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.393585 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0109 12:20:01.394040 139668939859840 classifier_utils.py:645] *** Example ***\n",
            "INFO:tensorflow:guid: 3\n",
            "I0109 12:20:01.394142 139668939859840 classifier_utils.py:646] guid: 3\n",
            "INFO:tensorflow:tokens: [CLS] ▁the ▁a mish ▁community ▁in ▁pennsylvania , ▁which ▁numbers ▁about ▁5 5,000 , ▁lives ▁an ▁agrarian ▁lifestyle , ▁shun ning ▁technological ▁advances ▁like ▁electricity ▁and ▁automobile s . ▁and ▁many ▁say ▁their ▁in s ular ▁lifestyle ▁gives ▁them ▁a ▁sense ▁that ▁they ▁are ▁protected ▁from ▁the ▁violence ▁of ▁american ▁society . ▁but ▁as ▁residents ▁gathered ▁near ▁the ▁school , ▁some ▁wearing ▁traditional ▁garb ▁and ▁arriving ▁in ▁horse - drawn ▁bug gies , ▁they ▁said ▁that ▁sense ▁of ▁safety ▁had ▁been ▁shattered . ▁ \" if ▁someone ▁snap s ▁and ▁wants ▁to ▁do ▁something ▁stupid , ▁there ' s ▁no ▁distance ▁that ' s ▁going ▁to ▁stop ▁them , \" ▁said ▁jake ▁king , ▁56 , ▁an ▁a mish ▁lantern ▁maker ▁who ▁knew ▁several ▁families ▁whose ▁children ▁had ▁been ▁shot . [SEP] ▁pennsylvania ▁has ▁the ▁biggest ▁a mish ▁community ▁in ▁the ▁u . s . [SEP]\n",
            "I0109 12:20:01.394291 139668939859840 classifier_utils.py:648] tokens: [CLS] ▁the ▁a mish ▁community ▁in ▁pennsylvania , ▁which ▁numbers ▁about ▁5 5,000 , ▁lives ▁an ▁agrarian ▁lifestyle , ▁shun ning ▁technological ▁advances ▁like ▁electricity ▁and ▁automobile s . ▁and ▁many ▁say ▁their ▁in s ular ▁lifestyle ▁gives ▁them ▁a ▁sense ▁that ▁they ▁are ▁protected ▁from ▁the ▁violence ▁of ▁american ▁society . ▁but ▁as ▁residents ▁gathered ▁near ▁the ▁school , ▁some ▁wearing ▁traditional ▁garb ▁and ▁arriving ▁in ▁horse - drawn ▁bug gies , ▁they ▁said ▁that ▁sense ▁of ▁safety ▁had ▁been ▁shattered . ▁ \" if ▁someone ▁snap s ▁and ▁wants ▁to ▁do ▁something ▁stupid , ▁there ' s ▁no ▁distance ▁that ' s ▁going ▁to ▁stop ▁them , \" ▁said ▁jake ▁king , ▁56 , ▁an ▁a mish ▁lantern ▁maker ▁who ▁knew ▁several ▁families ▁whose ▁children ▁had ▁been ▁shot . [SEP] ▁pennsylvania ▁has ▁the ▁biggest ▁a mish ▁community ▁in ▁the ▁u . s . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 14 21 10758 514 19 1806 15 56 2116 88 331 5157 15 1551 40 24463 8937 15 15800 2981 10381 10592 101 5592 17 8199 18 9 17 151 395 66 19 18 7451 8937 2352 105 21 1259 30 59 50 3803 37 14 3300 16 189 641 9 47 28 2175 4744 424 14 116 15 109 2466 1361 19646 17 6426 19 1729 8 19950 6256 19008 15 59 87 30 1259 16 2108 41 74 11915 9 13 7 821 737 6877 18 17 2846 20 107 301 3553 15 80 22 18 90 1583 30 22 18 228 20 747 105 15 7 87 3777 437 15 6171 15 40 21 10758 11585 11767 72 404 238 1250 1196 391 41 74 999 9 3 1806 63 14 3835 21 10758 514 19 14 287 9 18 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:20:01.394522 139668939859840 classifier_utils.py:649] input_ids: 2 14 21 10758 514 19 1806 15 56 2116 88 331 5157 15 1551 40 24463 8937 15 15800 2981 10381 10592 101 5592 17 8199 18 9 17 151 395 66 19 18 7451 8937 2352 105 21 1259 30 59 50 3803 37 14 3300 16 189 641 9 47 28 2175 4744 424 14 116 15 109 2466 1361 19646 17 6426 19 1729 8 19950 6256 19008 15 59 87 30 1259 16 2108 41 74 11915 9 13 7 821 737 6877 18 17 2846 20 107 301 3553 15 80 22 18 90 1583 30 22 18 228 20 747 105 15 7 87 3777 437 15 6171 15 40 21 10758 11585 11767 72 404 238 1250 1196 391 41 74 999 9 3 1806 63 14 3835 21 10758 514 19 14 287 9 18 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:20:01.394749 139668939859840 classifier_utils.py:650] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:20:01.394960 139668939859840 classifier_utils.py:651] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: not_entailment (id = 1)\n",
            "I0109 12:20:01.395050 139668939859840 classifier_utils.py:652] label: not_entailment (id = 1)\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.396080 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0109 12:20:01.396451 139668939859840 classifier_utils.py:645] *** Example ***\n",
            "INFO:tensorflow:guid: 4\n",
            "I0109 12:20:01.396559 139668939859840 classifier_utils.py:646] guid: 4\n",
            "INFO:tensorflow:tokens: [CLS] ▁security ▁forces ▁were ▁on ▁high ▁alert ▁after ▁an ▁election ▁campaign ▁in ▁which ▁more ▁than ▁1,000 ▁people , ▁including ▁seven ▁election ▁candidates , ▁have ▁been ▁killed . [SEP] ▁security ▁forces ▁were ▁on ▁high ▁alert ▁after ▁a ▁campaign ▁marred ▁by ▁violence . [SEP]\n",
            "I0109 12:20:01.396692 139668939859840 classifier_utils.py:648] tokens: [CLS] ▁security ▁forces ▁were ▁on ▁high ▁alert ▁after ▁an ▁election ▁campaign ▁in ▁which ▁more ▁than ▁1,000 ▁people , ▁including ▁seven ▁election ▁candidates , ▁have ▁been ▁killed . [SEP] ▁security ▁forces ▁were ▁on ▁high ▁alert ▁after ▁a ▁campaign ▁marred ▁by ▁violence . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 1221 879 46 27 183 7863 75 40 776 1150 19 56 91 119 5925 148 15 215 810 776 4074 15 57 74 841 9 3 1221 879 46 27 183 7863 75 21 1150 26479 34 3300 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:20:01.396919 139668939859840 classifier_utils.py:649] input_ids: 2 1221 879 46 27 183 7863 75 40 776 1150 19 56 91 119 5925 148 15 215 810 776 4074 15 57 74 841 9 3 1221 879 46 27 183 7863 75 21 1150 26479 34 3300 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:20:01.397144 139668939859840 classifier_utils.py:650] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0109 12:20:01.494153 139668939859840 classifier_utils.py:651] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: entailment (id = 0)\n",
            "I0109 12:20:01.494335 139668939859840 classifier_utils.py:652] label: entailment (id = 0)\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.495347 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.496516 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.497522 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.498469 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.499790 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.500730 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.501557 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.502421 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.503329 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.504221 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.505084 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.505894 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.506784 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.507678 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.508650 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.509686 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.510775 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.511965 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.513097 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.514209 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.515118 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.515962 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.516813 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.517665 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.518642 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.519516 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.520581 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.521870 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.523002 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.523906 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.524750 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.525637 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.526540 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.527387 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.528228 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.529083 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.529988 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.531022 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.531950 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.532846 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.533838 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.534753 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.535567 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.536393 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.537301 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.538210 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.539243 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.540226 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.541110 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.541961 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.542811 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.543854 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.544892 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.545885 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.546826 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.547727 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.548662 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.549519 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.550521 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.551504 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.552395 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.553243 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.554120 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.554979 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.555975 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.556912 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.557948 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.558906 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.560014 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.561055 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.562077 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.563035 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.563962 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.565126 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.566214 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.567126 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.567958 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.568789 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.569622 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.570441 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.571291 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.572132 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.573040 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.573923 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.575013 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.576132 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.577039 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.578076 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.579031 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.579931 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.581012 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.582118 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.583019 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.583896 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.585032 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.586305 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.587326 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.588209 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.589190 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.590272 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.591755 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.593472 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.595204 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.596544 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.598127 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.600060 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.601778 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.603281 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.604772 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.606555 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.608252 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.609898 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.611384 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.612623 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.614143 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.615741 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.617306 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.618961 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.620909 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.622618 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.624961 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.626819 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.628307 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.629702 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.631254 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.632713 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.634090 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.635618 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.637500 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.639288 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.640977 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.642676 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.644296 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.645291 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.646424 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.647369 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.648327 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.649409 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.650336 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.651207 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.652067 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.652942 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.653925 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.654849 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.655892 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.656831 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.657765 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.658757 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.659914 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.660965 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.662338 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.663418 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.664536 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.665551 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.666437 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.667382 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.668742 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.670040 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.670946 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.671904 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.672906 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.673893 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.674849 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.675751 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.676625 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.677533 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.678492 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.679470 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.680611 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.681612 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.682553 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.683618 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.684521 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.685403 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.686282 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.687267 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.688187 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.689271 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.690314 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.691229 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.692109 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.693081 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.693975 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.694980 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.695976 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.696974 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.697972 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.698930 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.699853 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.701011 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.702744 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.703763 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.704685 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.705558 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.706524 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.707512 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.708417 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.709277 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.710241 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.711142 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.712079 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.713142 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.714354 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.715307 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.716202 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.717225 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.718194 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.719087 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.720254 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.721333 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.722289 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.723215 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.724255 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.725385 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.726314 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.727176 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.728081 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.729030 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.730006 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.731047 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.732067 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.732986 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.734038 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.735055 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.736018 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.736948 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.737882 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.738833 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.739741 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.740899 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.741845 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.743008 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.744040 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.744974 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.746162 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.747242 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.748153 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.749074 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.750090 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.751472 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.752681 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.753583 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.754466 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.755428 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.756334 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.757358 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.758346 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.759248 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.760141 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.761065 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.761922 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.763069 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.764079 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.765006 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.765923 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.766804 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.767727 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.768662 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.769567 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.770532 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.771628 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.772609 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.773764 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.774831 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.775741 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.776562 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.777407 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.778316 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.779657 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.781142 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.782588 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:using sentence piece tokenzier.\n",
            "I0109 12:20:01.783783 139668939859840 tokenization.py:237] using sentence piece tokenzier.\n",
            "INFO:tensorflow:***** Running evaluation *****\n",
            "I0109 12:20:02.266073 139668939859840 run_classifier.py:350] ***** Running evaluation *****\n",
            "INFO:tensorflow:  Num examples = 280 (277 actual, 3 padding)\n",
            "I0109 12:20:02.266371 139668939859840 run_classifier.py:353]   Num examples = 280 (277 actual, 3 padding)\n",
            "INFO:tensorflow:  Batch size = 8\n",
            "I0109 12:20:02.266509 139668939859840 run_classifier.py:354]   Batch size = 8\n",
            "INFO:tensorflow:Best trial info: Step: -1, Best Value Step: -1, Best Value: -1\n",
            "I0109 12:20:02.527147 139668939859840 run_classifier.py:391] Best trial info: Step: -1, Best Value Step: -1, Best Value: -1\n",
            "INFO:tensorflow:Add gs://luanps/albert-tfhub/models/RTE/c755eca2/model.ckpt-0 to eval list.\n",
            "I0109 12:20:02.656710 139668939859840 run_classifier.py:433] Add gs://luanps/albert-tfhub/models/RTE/c755eca2/model.ckpt-0 to eval list.\n",
            "INFO:tensorflow:Add gs://luanps/albert-tfhub/models/RTE/c755eca2/model.ckpt-90 to eval list.\n",
            "I0109 12:20:02.656955 139668939859840 run_classifier.py:433] Add gs://luanps/albert-tfhub/models/RTE/c755eca2/model.ckpt-90 to eval list.\n",
            "INFO:tensorflow:found 2 files.\n",
            "I0109 12:20:02.657027 139668939859840 run_classifier.py:435] found 2 files.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0109 12:20:02.663072 139668939859840 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f06b8b9ccb0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "W0109 12:20:02.683683 139668939859840 ag_logging.py:146] Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f06b8b9ccb0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "INFO:tensorflow:*** Features ***\n",
            "I0109 12:20:02.760333 139668939859840 classifier_utils.py:824] *** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (1, 512)\n",
            "I0109 12:20:02.760642 139668939859840 classifier_utils.py:826]   name = input_ids, shape = (1, 512)\n",
            "INFO:tensorflow:  name = input_mask, shape = (1, 512)\n",
            "I0109 12:20:02.760807 139668939859840 classifier_utils.py:826]   name = input_mask, shape = (1, 512)\n",
            "INFO:tensorflow:  name = is_real_example, shape = (1,)\n",
            "I0109 12:20:02.760925 139668939859840 classifier_utils.py:826]   name = is_real_example, shape = (1,)\n",
            "INFO:tensorflow:  name = label_ids, shape = (1,)\n",
            "I0109 12:20:02.761029 139668939859840 classifier_utils.py:826]   name = label_ids, shape = (1,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (1, 512)\n",
            "I0109 12:20:02.761145 139668939859840 classifier_utils.py:826]   name = segment_ids, shape = (1, 512)\n",
            "INFO:tensorflow:creating model from hub_module: https://tfhub.dev/google/albert_base/3\n",
            "I0109 12:20:02.762517 139668939859840 fine_tuning_utils.py:65] creating model from hub_module: https://tfhub.dev/google/albert_base/3\n",
            "E0109 12:20:06.832247 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/input_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:06.832906 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/input_mask) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:06.833310 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/segment_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:06.833664 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/mlm_positions) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:06.837103 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/word_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:06.843252 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/token_type_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:06.849397 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/position_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:06.852371 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:06.854284 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:06.862140 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/embedding_hidden_mapping_in/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:06.863359 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/embedding_hidden_mapping_in/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:06.874152 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:06.875907 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:06.885032 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:06.886806 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:06.895573 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:06.897345 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:06.915284 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:06.917107 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:06.923851 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:06.925907 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:06.932480 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:06.934093 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:06.944039 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:06.945242 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:06.950761 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:06.951948 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:08.043850 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:08.045124 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:08.052250 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:08.053483 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:08.057482 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:08.058713 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:08.063581 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/output_bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "I0109 12:20:08.153716 139668939859840 saver.py:1503] Saver not created because there are no variables in the graph to restore\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "I0109 12:20:08.300826 139668939859840 classifier_utils.py:861] **** Trainable Variables ****\n",
            "INFO:tensorflow:  name = module/bert/embeddings/word_embeddings:0, shape = (30000, 128)\n",
            "I0109 12:20:08.301103 139668939859840 classifier_utils.py:867]   name = module/bert/embeddings/word_embeddings:0, shape = (30000, 128)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/token_type_embeddings:0, shape = (2, 128)\n",
            "I0109 12:20:08.301271 139668939859840 classifier_utils.py:867]   name = module/bert/embeddings/token_type_embeddings:0, shape = (2, 128)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/position_embeddings:0, shape = (512, 128)\n",
            "I0109 12:20:08.301399 139668939859840 classifier_utils.py:867]   name = module/bert/embeddings/position_embeddings:0, shape = (512, 128)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/LayerNorm/beta:0, shape = (128,)\n",
            "I0109 12:20:08.301519 139668939859840 classifier_utils.py:867]   name = module/bert/embeddings/LayerNorm/beta:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/LayerNorm/gamma:0, shape = (128,)\n",
            "I0109 12:20:08.301643 139668939859840 classifier_utils.py:867]   name = module/bert/embeddings/LayerNorm/gamma:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/embedding_hidden_mapping_in/kernel:0, shape = (128, 768)\n",
            "I0109 12:20:08.301745 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/embedding_hidden_mapping_in/kernel:0, shape = (128, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/embedding_hidden_mapping_in/bias:0, shape = (768,)\n",
            "I0109 12:20:08.301863 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/embedding_hidden_mapping_in/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel:0, shape = (768, 768)\n",
            "I0109 12:20:08.301964 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias:0, shape = (768,)\n",
            "I0109 12:20:08.302069 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel:0, shape = (768, 768)\n",
            "I0109 12:20:08.302169 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias:0, shape = (768,)\n",
            "I0109 12:20:08.302285 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel:0, shape = (768, 768)\n",
            "I0109 12:20:08.302385 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias:0, shape = (768,)\n",
            "I0109 12:20:08.302490 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel:0, shape = (768, 768)\n",
            "I0109 12:20:08.302598 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias:0, shape = (768,)\n",
            "I0109 12:20:08.302713 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta:0, shape = (768,)\n",
            "I0109 12:20:08.302815 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma:0, shape = (768,)\n",
            "I0109 12:20:08.302912 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0109 12:20:08.303009 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0109 12:20:08.303114 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0109 12:20:08.303219 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias:0, shape = (768,)\n",
            "I0109 12:20:08.303330 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta:0, shape = (768,)\n",
            "I0109 12:20:08.303428 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma:0, shape = (768,)\n",
            "I0109 12:20:08.303525 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "I0109 12:20:08.303634 139668939859840 classifier_utils.py:867]   name = module/bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/pooler/dense/bias:0, shape = (768,)\n",
            "I0109 12:20:08.303742 139668939859840 classifier_utils.py:867]   name = module/bert/pooler/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/dense/kernel:0, shape = (768, 128)\n",
            "I0109 12:20:08.303843 139668939859840 classifier_utils.py:867]   name = module/cls/predictions/transform/dense/kernel:0, shape = (768, 128)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/dense/bias:0, shape = (128,)\n",
            "I0109 12:20:08.303946 139668939859840 classifier_utils.py:867]   name = module/cls/predictions/transform/dense/bias:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/LayerNorm/beta:0, shape = (128,)\n",
            "I0109 12:20:08.304044 139668939859840 classifier_utils.py:867]   name = module/cls/predictions/transform/LayerNorm/beta:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/LayerNorm/gamma:0, shape = (128,)\n",
            "I0109 12:20:08.304141 139668939859840 classifier_utils.py:867]   name = module/cls/predictions/transform/LayerNorm/gamma:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/output_bias:0, shape = (30000,)\n",
            "I0109 12:20:08.304244 139668939859840 classifier_utils.py:867]   name = module/cls/predictions/output_bias:0, shape = (30000,)\n",
            "INFO:tensorflow:  name = output_weights:0, shape = (2, 768)\n",
            "I0109 12:20:08.304341 139668939859840 classifier_utils.py:867]   name = output_weights:0, shape = (2, 768)\n",
            "INFO:tensorflow:  name = output_bias:0, shape = (2,)\n",
            "I0109 12:20:08.304447 139668939859840 classifier_utils.py:867]   name = output_bias:0, shape = (2,)\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:3322: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0109 12:20:08.316567 139668939859840 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:3322: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0109 12:20:09.427768 139668939859840 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2022-01-09T12:20:09Z\n",
            "I0109 12:20:09.445634 139668939859840 evaluation.py:255] Starting evaluation at 2022-01-09T12:20:09Z\n",
            "INFO:tensorflow:TPU job name worker\n",
            "I0109 12:20:09.445916 139668939859840 tpu_estimator.py:506] TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0109 12:20:09.568584 139668939859840 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://luanps/albert-tfhub/models/RTE/c755eca2/model.ckpt-0\n",
            "I0109 12:20:09.699563 139668939859840 saver.py:1284] Restoring parameters from gs://luanps/albert-tfhub/models/RTE/c755eca2/model.ckpt-0\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0109 12:20:14.974914 139668939859840 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0109 12:20:15.290256 139668939859840 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Init TPU system\n",
            "I0109 12:20:15.914756 139668939859840 tpu_estimator.py:567] Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 20 seconds\n",
            "I0109 12:20:36.816206 139668939859840 tpu_estimator.py:576] Initialized TPU in 20 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "I0109 12:20:36.817097 139666788620032 tpu_estimator.py:521] Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "I0109 12:20:36.817484 139666780227328 tpu_estimator.py:540] Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "I0109 12:20:37.134859 139668939859840 util.py:98] Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Enqueue next (35) batch(es) of data to infeed.\n",
            "I0109 12:20:37.462926 139668939859840 tpu_estimator.py:600] Enqueue next (35) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (35) batch(es) of data from outfeed.\n",
            "I0109 12:20:37.463416 139668939859840 tpu_estimator.py:604] Dequeue next (35) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "I0109 12:20:42.925198 139666780227328 tpu_estimator.py:279] Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:Evaluation [35/35]\n",
            "I0109 12:20:43.512559 139668939859840 evaluation.py:167] Evaluation [35/35]\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "I0109 12:20:43.512933 139668939859840 tpu_estimator.py:608] Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "I0109 12:20:43.513014 139668939859840 tpu_estimator.py:434] Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "I0109 12:20:43.513143 139666788620032 tpu_estimator.py:429] InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "I0109 12:20:43.513255 139666788620032 tpu_estimator.py:537] Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "I0109 12:20:43.513467 139668939859840 error_handling.py:101] infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "I0109 12:20:43.513555 139668939859840 tpu_estimator.py:612] Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "I0109 12:20:43.513628 139668939859840 tpu_estimator.py:434] Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "I0109 12:20:43.513716 139666780227328 tpu_estimator.py:429] OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "I0109 12:20:43.513781 139666780227328 tpu_estimator.py:551] Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "I0109 12:20:43.513866 139668939859840 error_handling.py:101] outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "I0109 12:20:43.513922 139668939859840 tpu_estimator.py:616] Shutdown TPU system.\n",
            "INFO:tensorflow:Finished evaluation at 2022-01-09-12:20:44\n",
            "I0109 12:20:44.253963 139668939859840 evaluation.py:275] Finished evaluation at 2022-01-09-12:20:44\n",
            "INFO:tensorflow:Saving dict for global step 0: eval_accuracy = 0.40433213, eval_loss = 0.7403862, global_step = 0, loss = 0.7784961\n",
            "I0109 12:20:44.254273 139668939859840 estimator.py:2049] Saving dict for global step 0: eval_accuracy = 0.40433213, eval_loss = 0.7403862, global_step = 0, loss = 0.7784961\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 0: gs://luanps/albert-tfhub/models/RTE/c755eca2/model.ckpt-0\n",
            "I0109 12:20:48.848753 139668939859840 estimator.py:2109] Saving 'checkpoint_path' summary for global step 0: gs://luanps/albert-tfhub/models/RTE/c755eca2/model.ckpt-0\n",
            "INFO:tensorflow:evaluation_loop marked as finished\n",
            "I0109 12:20:49.973675 139668939859840 error_handling.py:101] evaluation_loop marked as finished\n",
            "INFO:tensorflow:***** Eval results *****\n",
            "I0109 12:20:49.974008 139668939859840 run_classifier.py:453] ***** Eval results *****\n",
            "INFO:tensorflow:  eval_accuracy = 0.40433213\n",
            "I0109 12:20:49.974144 139668939859840 run_classifier.py:455]   eval_accuracy = 0.40433213\n",
            "INFO:tensorflow:  eval_loss = 0.7403862\n",
            "I0109 12:20:49.974466 139668939859840 run_classifier.py:455]   eval_loss = 0.7403862\n",
            "INFO:tensorflow:  global_step = 0\n",
            "I0109 12:20:49.974650 139668939859840 run_classifier.py:455]   global_step = 0\n",
            "INFO:tensorflow:  loss = 0.7784961\n",
            "I0109 12:20:49.974771 139668939859840 run_classifier.py:455]   loss = 0.7784961\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0109 12:20:50.930009 139668939859840 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f06b8b4f9e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "W0109 12:20:50.949396 139668939859840 ag_logging.py:146] Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f06b8b4f9e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "INFO:tensorflow:*** Features ***\n",
            "I0109 12:20:51.023736 139668939859840 classifier_utils.py:824] *** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (1, 512)\n",
            "I0109 12:20:51.024034 139668939859840 classifier_utils.py:826]   name = input_ids, shape = (1, 512)\n",
            "INFO:tensorflow:  name = input_mask, shape = (1, 512)\n",
            "I0109 12:20:51.024157 139668939859840 classifier_utils.py:826]   name = input_mask, shape = (1, 512)\n",
            "INFO:tensorflow:  name = is_real_example, shape = (1,)\n",
            "I0109 12:20:51.024260 139668939859840 classifier_utils.py:826]   name = is_real_example, shape = (1,)\n",
            "INFO:tensorflow:  name = label_ids, shape = (1,)\n",
            "I0109 12:20:51.024357 139668939859840 classifier_utils.py:826]   name = label_ids, shape = (1,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (1, 512)\n",
            "I0109 12:20:51.024454 139668939859840 classifier_utils.py:826]   name = segment_ids, shape = (1, 512)\n",
            "INFO:tensorflow:creating model from hub_module: https://tfhub.dev/google/albert_base/3\n",
            "I0109 12:20:51.025397 139668939859840 fine_tuning_utils.py:65] creating model from hub_module: https://tfhub.dev/google/albert_base/3\n",
            "E0109 12:20:55.537256 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/input_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:55.537910 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/input_mask) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:55.538264 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/segment_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:55.538555 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/mlm_positions) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:55.541982 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/word_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:55.548444 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/token_type_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:55.555213 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/position_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:55.558156 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:55.559324 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:55.568156 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/embedding_hidden_mapping_in/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:55.569379 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/embedding_hidden_mapping_in/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:55.580126 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:55.581837 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:55.590588 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:55.592303 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:55.601028 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:55.602788 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:55.620640 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:55.622423 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:55.628565 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:55.629760 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:55.635977 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:55.637534 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:55.648039 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:55.649289 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:55.655160 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:55.656380 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:56.515548 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:56.516853 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:56.524698 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:56.525947 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:56.530105 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:56.531281 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "E0109 12:20:56.535482 139668939859840 tpu.py:425] Operation of type Placeholder (module_apply_tokens/cls/predictions/output_bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "I0109 12:20:56.626405 139668939859840 saver.py:1503] Saver not created because there are no variables in the graph to restore\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "I0109 12:20:56.777276 139668939859840 classifier_utils.py:861] **** Trainable Variables ****\n",
            "INFO:tensorflow:  name = module/bert/embeddings/word_embeddings:0, shape = (30000, 128)\n",
            "I0109 12:20:56.777621 139668939859840 classifier_utils.py:867]   name = module/bert/embeddings/word_embeddings:0, shape = (30000, 128)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/token_type_embeddings:0, shape = (2, 128)\n",
            "I0109 12:20:56.777825 139668939859840 classifier_utils.py:867]   name = module/bert/embeddings/token_type_embeddings:0, shape = (2, 128)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/position_embeddings:0, shape = (512, 128)\n",
            "I0109 12:20:56.777973 139668939859840 classifier_utils.py:867]   name = module/bert/embeddings/position_embeddings:0, shape = (512, 128)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/LayerNorm/beta:0, shape = (128,)\n",
            "I0109 12:20:56.778093 139668939859840 classifier_utils.py:867]   name = module/bert/embeddings/LayerNorm/beta:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/bert/embeddings/LayerNorm/gamma:0, shape = (128,)\n",
            "I0109 12:20:56.778197 139668939859840 classifier_utils.py:867]   name = module/bert/embeddings/LayerNorm/gamma:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/embedding_hidden_mapping_in/kernel:0, shape = (128, 768)\n",
            "I0109 12:20:56.778296 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/embedding_hidden_mapping_in/kernel:0, shape = (128, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/embedding_hidden_mapping_in/bias:0, shape = (768,)\n",
            "I0109 12:20:56.778419 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/embedding_hidden_mapping_in/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel:0, shape = (768, 768)\n",
            "I0109 12:20:56.778527 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias:0, shape = (768,)\n",
            "I0109 12:20:56.778653 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel:0, shape = (768, 768)\n",
            "I0109 12:20:56.778762 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias:0, shape = (768,)\n",
            "I0109 12:20:56.778892 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel:0, shape = (768, 768)\n",
            "I0109 12:20:56.779009 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias:0, shape = (768,)\n",
            "I0109 12:20:56.779142 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel:0, shape = (768, 768)\n",
            "I0109 12:20:56.779265 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias:0, shape = (768,)\n",
            "I0109 12:20:56.779406 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta:0, shape = (768,)\n",
            "I0109 12:20:56.779523 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma:0, shape = (768,)\n",
            "I0109 12:20:56.779662 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0109 12:20:56.779787 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0109 12:20:56.779908 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0109 12:20:56.780016 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias:0, shape = (768,)\n",
            "I0109 12:20:56.780136 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta:0, shape = (768,)\n",
            "I0109 12:20:56.780260 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma:0, shape = (768,)\n",
            "I0109 12:20:56.780455 139668939859840 classifier_utils.py:867]   name = module/bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "I0109 12:20:56.780582 139668939859840 classifier_utils.py:867]   name = module/bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = module/bert/pooler/dense/bias:0, shape = (768,)\n",
            "I0109 12:20:56.780737 139668939859840 classifier_utils.py:867]   name = module/bert/pooler/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/dense/kernel:0, shape = (768, 128)\n",
            "I0109 12:20:56.780860 139668939859840 classifier_utils.py:867]   name = module/cls/predictions/transform/dense/kernel:0, shape = (768, 128)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/dense/bias:0, shape = (128,)\n",
            "I0109 12:20:56.780993 139668939859840 classifier_utils.py:867]   name = module/cls/predictions/transform/dense/bias:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/LayerNorm/beta:0, shape = (128,)\n",
            "I0109 12:20:56.781124 139668939859840 classifier_utils.py:867]   name = module/cls/predictions/transform/LayerNorm/beta:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/transform/LayerNorm/gamma:0, shape = (128,)\n",
            "I0109 12:20:56.781248 139668939859840 classifier_utils.py:867]   name = module/cls/predictions/transform/LayerNorm/gamma:0, shape = (128,)\n",
            "INFO:tensorflow:  name = module/cls/predictions/output_bias:0, shape = (30000,)\n",
            "I0109 12:20:56.781389 139668939859840 classifier_utils.py:867]   name = module/cls/predictions/output_bias:0, shape = (30000,)\n",
            "INFO:tensorflow:  name = output_weights:0, shape = (2, 768)\n",
            "I0109 12:20:56.781509 139668939859840 classifier_utils.py:867]   name = output_weights:0, shape = (2, 768)\n",
            "INFO:tensorflow:  name = output_bias:0, shape = (2,)\n",
            "I0109 12:20:56.781658 139668939859840 classifier_utils.py:867]   name = output_bias:0, shape = (2,)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0109 12:20:57.902844 139668939859840 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2022-01-09T12:20:57Z\n",
            "I0109 12:20:57.919552 139668939859840 evaluation.py:255] Starting evaluation at 2022-01-09T12:20:57Z\n",
            "INFO:tensorflow:TPU job name worker\n",
            "I0109 12:20:57.919861 139668939859840 tpu_estimator.py:506] TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0109 12:20:58.040022 139668939859840 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://luanps/albert-tfhub/models/RTE/c755eca2/model.ckpt-90\n",
            "I0109 12:20:58.171329 139668939859840 saver.py:1284] Restoring parameters from gs://luanps/albert-tfhub/models/RTE/c755eca2/model.ckpt-90\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0109 12:21:04.468085 139668939859840 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0109 12:21:04.757549 139668939859840 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Init TPU system\n",
            "I0109 12:21:05.384668 139668939859840 tpu_estimator.py:567] Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 27 seconds\n",
            "I0109 12:21:33.368852 139668939859840 tpu_estimator.py:576] Initialized TPU in 27 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "I0109 12:21:33.369684 139666788620032 tpu_estimator.py:521] Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "I0109 12:21:33.370087 139666780227328 tpu_estimator.py:540] Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "I0109 12:21:33.702873 139668939859840 util.py:98] Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Enqueue next (35) batch(es) of data to infeed.\n",
            "I0109 12:21:34.006966 139668939859840 tpu_estimator.py:600] Enqueue next (35) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (35) batch(es) of data from outfeed.\n",
            "I0109 12:21:34.007285 139668939859840 tpu_estimator.py:604] Dequeue next (35) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "I0109 12:21:39.206053 139666780227328 tpu_estimator.py:279] Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:Evaluation [35/35]\n",
            "I0109 12:21:39.795052 139668939859840 evaluation.py:167] Evaluation [35/35]\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "I0109 12:21:39.795454 139668939859840 tpu_estimator.py:608] Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "I0109 12:21:39.795577 139668939859840 tpu_estimator.py:434] Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "I0109 12:21:39.795794 139666788620032 tpu_estimator.py:429] InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "I0109 12:21:39.795890 139666788620032 tpu_estimator.py:537] Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "I0109 12:21:39.796021 139668939859840 error_handling.py:101] infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "I0109 12:21:39.796163 139668939859840 tpu_estimator.py:612] Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "I0109 12:21:39.796260 139668939859840 tpu_estimator.py:434] Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "I0109 12:21:39.796427 139666780227328 tpu_estimator.py:429] OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "I0109 12:21:39.796512 139666780227328 tpu_estimator.py:551] Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "I0109 12:21:39.796640 139668939859840 error_handling.py:101] outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "I0109 12:21:39.796783 139668939859840 tpu_estimator.py:616] Shutdown TPU system.\n",
            "INFO:tensorflow:Finished evaluation at 2022-01-09-12:21:40\n",
            "I0109 12:21:40.548139 139668939859840 evaluation.py:275] Finished evaluation at 2022-01-09-12:21:40\n",
            "INFO:tensorflow:Saving dict for global step 90: eval_accuracy = 0.700361, eval_loss = 0.6377483, global_step = 90, loss = 0.48213756\n",
            "I0109 12:21:40.548463 139668939859840 estimator.py:2049] Saving dict for global step 90: eval_accuracy = 0.700361, eval_loss = 0.6377483, global_step = 90, loss = 0.48213756\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 90: gs://luanps/albert-tfhub/models/RTE/c755eca2/model.ckpt-90\n",
            "I0109 12:21:41.378564 139668939859840 estimator.py:2109] Saving 'checkpoint_path' summary for global step 90: gs://luanps/albert-tfhub/models/RTE/c755eca2/model.ckpt-90\n",
            "INFO:tensorflow:evaluation_loop marked as finished\n",
            "I0109 12:21:42.213461 139668939859840 error_handling.py:101] evaluation_loop marked as finished\n",
            "INFO:tensorflow:***** Eval results *****\n",
            "I0109 12:21:42.213834 139668939859840 run_classifier.py:453] ***** Eval results *****\n",
            "INFO:tensorflow:  eval_accuracy = 0.700361\n",
            "I0109 12:21:42.213965 139668939859840 run_classifier.py:455]   eval_accuracy = 0.700361\n",
            "INFO:tensorflow:  eval_loss = 0.6377483\n",
            "I0109 12:21:42.214108 139668939859840 run_classifier.py:455]   eval_loss = 0.6377483\n",
            "INFO:tensorflow:  global_step = 90\n",
            "I0109 12:21:42.214222 139668939859840 run_classifier.py:455]   global_step = 90\n",
            "INFO:tensorflow:  loss = 0.48213756\n",
            "I0109 12:21:42.214339 139668939859840 run_classifier.py:455]   loss = 0.48213756\n",
            "INFO:tensorflow:saving model.ckpt-90.meta to model.ckpt-best.meta\n",
            "I0109 12:21:43.312483 139668939859840 run_classifier.py:473] saving model.ckpt-90.meta to model.ckpt-best.meta\n",
            "INFO:tensorflow:saving model.ckpt-90.data-00000-of-00001 to model.ckpt-best.data-00000-of-00001\n",
            "I0109 12:21:44.111714 139668939859840 run_classifier.py:473] saving model.ckpt-90.data-00000-of-00001 to model.ckpt-best.data-00000-of-00001\n",
            "INFO:tensorflow:saving model.ckpt-90.index to model.ckpt-best.index\n",
            "I0109 12:21:44.910531 139668939859840 run_classifier.py:473] saving model.ckpt-90.index to model.ckpt-best.index\n",
            "Copying gs://luanps/albert-tfhub/models/RTE/c755eca2/eval_results.txt...\n",
            "/ [1 files][  303.0 B/  303.0 B]                                                \n",
            "Operation completed over 1 objects/303.0 B.                                      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-01-09 12:21:48,651]\u001b[0m Trial 1 finished with value: 0.700361 and parameters: {'warmup_steps': 15, 'train_steps': 90, 'learning_rate': 1.0773897832818495e-05, 'batch_size': 112}. Best is trial 1 with value: 0.700361.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pack Optuna results and save to Bucket\n",
        "import joblib\n",
        "\n",
        "study_file = f'{TASK}_study.pkl'\n",
        "!rm $study_file\n",
        "joblib.dump(study, study_file)\n",
        "!gsutil cp $study_file $OUTPUT_DIR"
      ],
      "metadata": {
        "id": "CQP8EZcJw7xc",
        "outputId": "6f72977a-e434-442b-f254-fbf7f63337b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying file://RTE_study.pkl [Content-Type=application/octet-stream]...\n",
            "/ [1 files][  7.8 KiB/  7.8 KiB]                                                \n",
            "Operation completed over 1 objects/7.8 KiB.                                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study.trials_dataframe()"
      ],
      "metadata": {
        "id": "5251IgGlwiH5",
        "outputId": "9895c1ae-d320-4c52-eefa-19dcff26414d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-529b689a-ca42-44a9-86c2-1cebefaed1b5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number</th>\n",
              "      <th>value</th>\n",
              "      <th>datetime_start</th>\n",
              "      <th>datetime_complete</th>\n",
              "      <th>duration</th>\n",
              "      <th>params_batch_size</th>\n",
              "      <th>params_learning_rate</th>\n",
              "      <th>params_train_steps</th>\n",
              "      <th>params_warmup_steps</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.646209</td>\n",
              "      <td>2022-01-09 12:12:54.678610</td>\n",
              "      <td>2022-01-09 12:17:11.417451</td>\n",
              "      <td>0 days 00:04:16.738841</td>\n",
              "      <td>128</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>50</td>\n",
              "      <td>5</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.700361</td>\n",
              "      <td>2022-01-09 12:17:11.422998</td>\n",
              "      <td>2022-01-09 12:21:48.651075</td>\n",
              "      <td>0 days 00:04:37.228077</td>\n",
              "      <td>112</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>90</td>\n",
              "      <td>15</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-529b689a-ca42-44a9-86c2-1cebefaed1b5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-529b689a-ca42-44a9-86c2-1cebefaed1b5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-529b689a-ca42-44a9-86c2-1cebefaed1b5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   number     value  ... params_warmup_steps     state\n",
              "0       0  0.646209  ...                   5  COMPLETE\n",
              "1       1  0.700361  ...                  15  COMPLETE\n",
              "\n",
              "[2 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyzing Optimization Results"
      ],
      "metadata": {
        "id": "-wh7njh8tRoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Download pkl file from GCP\n",
        "import joblib\n",
        "\n",
        "study_file = f'{TASK}_study.pkl'\n",
        "!gsutil cp $OUTPUT_DIR/$study_file .\n",
        "\n",
        "study = joblib.load(study_file)\n"
      ],
      "metadata": {
        "id": "KX9BZ_zWtUtf",
        "outputId": "0a87dba0-c738-4738-9cb7-8cfbc3adcec1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://luanps/albert-tfhub/models/RTE/RTE_study.pkl...\n",
            "/ [1 files][  7.8 KiB/  7.8 KiB]                                                \n",
            "Operation completed over 1 objects/7.8 KiB.                                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study.trials_dataframe()"
      ],
      "metadata": {
        "id": "1Y7s0Vwmuc2q",
        "outputId": "f37a25e9-ecdb-4d50-fe36-c2ada4d97f49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-68f7f610-335f-40b5-af82-bd637f1e18d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number</th>\n",
              "      <th>value</th>\n",
              "      <th>datetime_start</th>\n",
              "      <th>datetime_complete</th>\n",
              "      <th>duration</th>\n",
              "      <th>params_batch_size</th>\n",
              "      <th>params_learning_rate</th>\n",
              "      <th>params_train_steps</th>\n",
              "      <th>params_warmup_steps</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.646209</td>\n",
              "      <td>2022-01-09 12:12:54.678610</td>\n",
              "      <td>2022-01-09 12:17:11.417451</td>\n",
              "      <td>0 days 00:04:16.738841</td>\n",
              "      <td>128</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>50</td>\n",
              "      <td>5</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.700361</td>\n",
              "      <td>2022-01-09 12:17:11.422998</td>\n",
              "      <td>2022-01-09 12:21:48.651075</td>\n",
              "      <td>0 days 00:04:37.228077</td>\n",
              "      <td>112</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>90</td>\n",
              "      <td>15</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68f7f610-335f-40b5-af82-bd637f1e18d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-68f7f610-335f-40b5-af82-bd637f1e18d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-68f7f610-335f-40b5-af82-bd637f1e18d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   number     value  ... params_warmup_steps     state\n",
              "0       0  0.646209  ...                   5  COMPLETE\n",
              "1       1  0.700361  ...                  15  COMPLETE\n",
              "\n",
              "[2 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}